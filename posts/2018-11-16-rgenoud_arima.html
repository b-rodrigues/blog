<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2018-11-16">

<title>Using a genetic algorithm for the hyperparameter optimization of a SARIMA model – Econometrics and Free Software</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../assets/img/favicon-32x32.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-3fe3df12cb322cd60d4f50ab5ce79ec8.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-4d8bc8792aaca1724876db735330692e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
@import url('https://fonts.bunny.net/css2?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=IBM+Plex+Serif:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap');
</style>
</head><body><table width="100%" height="100%" style="text-align: center;">
    <tbody><tr><td>
      <a href="https://b-rodrigues.github.io/blog/">Website</a> - 
      <a href="https://www.youtube.com/@brodriguesco">Youtube</a> - 
      <a href="https://b-rodrigues.github.io/blog/about.html">About</a> - 
      <a href="https://b-rodrigues.github.io/blog/talks.html">Talks</a> -
      <a href="https://b-rodrigues.github.io/blog/books.html">Books</a> - 
      <a href="https://b-rodrigues.github.io/blog/packages.html">Packages</a> -
      <a href="https://b-rodrigues.github.io/blog/index.xml">RSS</a>
    </td>
</tr></tbody></table>


<link rel="stylesheet" href="../styles.css">




<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Using a genetic algorithm for the hyperparameter optimization of a SARIMA model</h1>
  <div class="quarto-categories">
    <div class="quarto-category">R</div>
    <div class="quarto-category">econometrics</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 16, 2018</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div style="text-align:center;">
<p>
<a href="https://keiwan.itch.io/evolution"> <img width="400" src="../assets/img/tap-walker.gif" title="Nietzsche's Übermensch" height="auto"></a>
</p>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">
Introduction
</h2>
<p>
In this blog post, I’ll use the data that I cleaned in a previous <a href="../posts/2018-11-14-luxairport.html">blog post</a>, which you can download <a href="https://github.com/b-rodrigues/avia_par_lu/tree/master">here</a>. If you want to follow along, download the monthly data. In my <a href="../posts/2018-11-15-tidy_gridsearch.html">last blog post</a> I showed how to perform a grid search the “tidy” way. As an example, I looked for the right hyperparameters of a SARIMA model. However, the goal of the post was not hyperparameter optimization per se, so I did not bother with tuning the hyperparameters on a validation set, and used the test set for both validation of the hyperparameters and testing the forecast. Of course, this is not great because doing this might lead to overfitting the hyperparameters to the test set. So in this blog post I split my data into trainig, validation and testing sets and use a genetic algorithm to look for the hyperparameters. Again, this is not the most optimal way to go about this problem, since the <code>{forecast}</code> package contains the very useful <code>auto.arima()</code> function. I just wanted to see what kind of solution a genetic algorithm would return, and also try different cost functions. If you’re interested, read on!
</p>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">
Setup
</h2>
<p>
Let’s first load some libraries and define some helper functions (the helper functions were explained in the previous blog posts):
</p>
<pre class="r"><code>library(tidyverse)
library(forecast)
library(rgenoud)
library(parallel)
library(lubridate)
library(furrr)
library(tsibble)
library(brotools)

ihs &lt;- function(x){
    log(x + sqrt(x**2 + 1))
}

to_tibble &lt;- function(forecast_object){
    point_estimate &lt;- forecast_object$mean %&gt;%
        as_tsibble() %&gt;%
        rename(point_estimate = value,
               date = index)

    upper &lt;- forecast_object$upper %&gt;%
        as_tsibble() %&gt;%
        spread(key, value) %&gt;%
        rename(date = index,
               upper80 = `80%`,
               upper95 = `95%`)

    lower &lt;- forecast_object$lower %&gt;%
        as_tsibble() %&gt;%
        spread(key, value) %&gt;%
        rename(date = index,
               lower80 = `80%`,
               lower95 = `95%`)

    reduce(list(point_estimate, upper, lower), full_join)
}</code></pre>
<p>
Now, let’s load the data:
</p>
<pre class="r"><code>avia_clean_monthly &lt;- read_csv("https://raw.githubusercontent.com/b-rodrigues/avia_par_lu/master/avia_clean_monthy.csv")</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   destination = col_character(),
##   date = col_date(format = ""),
##   passengers = col_double()
## )</code></pre>
<p>
Let’s split the data into a train set, a validation set and a test set:
</p>
<pre class="r"><code>avia_clean_train &lt;- avia_clean_monthly %&gt;%
    select(date, passengers) %&gt;%
    filter(year(date) &lt; 2013) %&gt;%
    group_by(date) %&gt;%
    summarise(total_passengers = sum(passengers)) %&gt;%
    pull(total_passengers) %&gt;%
    ts(., frequency = 12, start = c(2005, 1))

avia_clean_validation &lt;- avia_clean_monthly %&gt;%
    select(date, passengers) %&gt;%
    filter(between(year(date), 2013, 2016)) %&gt;%
    group_by(date) %&gt;%
    summarise(total_passengers = sum(passengers)) %&gt;%
    pull(total_passengers) %&gt;%
    ts(., frequency = 12, start = c(2013, 1))

avia_clean_test &lt;- avia_clean_monthly %&gt;%
    select(date, passengers) %&gt;%
    filter(year(date) &gt;= 2016) %&gt;%
    group_by(date) %&gt;%
    summarise(total_passengers = sum(passengers)) %&gt;%
    pull(total_passengers) %&gt;%
    ts(., frequency = 12, start = c(2016, 1))

logged_test_data &lt;- ihs(avia_clean_test)

logged_validation_data &lt;- ihs(avia_clean_validation)

logged_train_data &lt;- ihs(avia_clean_train)</code></pre>
<p>
I will train the models on data from 2005 to 2012, look for the hyperparameters on data from 2013 to 2016 and test the accuracy on data from 2016 to March 2018. For this kind of exercise, the ideal situation would be to perform cross-validation. Doing this with time-series data is not obvious because of the autocorrelation between observations, which would be broken by sampling independently which is required by CV. Also, if for example you do leave-one-out CV, you would end up trying to predict a point in, say, 2017, with data from 2018, which does not make sense. So you should be careful about that. <code>{forecast}</code> is able to perform <a href="https://robjhyndman.com/hyndsight/tscv/">CV for time series</a> and <code>scikit-learn</code>, the Python package, is able to perform <a href="https://scikit-learn.org/stable/modules/cross_validation.html#time-series-split">cross-validation of time series data</a> too. I will not do it in this blog post and simply focus on the genetic algorithm part.
</p>
<p>
Let’s start by defining the cost function to minimize. I’ll try several, in the first one I&nbsp;will minimize the RMSE:
</p>
<pre class="r"><code>cost_function_rmse &lt;- function(param, train_data, validation_data, forecast_periods){
    order &lt;- param[1:3]
    season &lt;- c(param[4:6], 12)
    model &lt;- purrr::possibly(arima, otherwise = NULL)(x = train_data, order = order, 
                                                      seasonal = season,
                                                      method = "ML")
    if(is.null(model)){
        return(9999999)
    } else {
      forecast_model &lt;- forecast::forecast(model, h = forecast_periods)
      point_forecast &lt;- forecast_model$mean
      sqrt(mean(point_forecast - validation_data) ** 2)
    }
}</code></pre>
<p>
If <code>arima()</code> is not able to estimate a model for the given parameters, I force it to return <code>NULL</code>, and in that case force the cost function to return a very high cost. If a model was successfully estimated, then I compute the RMSE.
</p>
<p>
Let’s also take a look at what <code>auto.arima()</code> says:
</p>
<pre class="r"><code>starting_model &lt;- auto.arima(logged_train_data)
summary(starting_model)</code></pre>
<pre><code>## Series: logged_train_data 
## ARIMA(3,0,0)(0,1,1)[12] with drift 
## 
## Coefficients:
##          ar1     ar2     ar3     sma1   drift
##       0.2318  0.2292  0.3661  -0.8498  0.0029
## s.e.  0.1016  0.1026  0.1031   0.2101  0.0010
## 
## sigma^2 estimated as 0.004009:  log likelihood=107.98
## AIC=-203.97   AICc=-202.88   BIC=-189.38
## 
## Training set error measures:
##                        ME       RMSE        MAE         MPE      MAPE
## Training set 0.0009924108 0.05743719 0.03577996 0.006323241 0.3080978
##                   MASE        ACF1
## Training set 0.4078581 -0.02707016</code></pre>
<p>
Let’s compute the cost at this vector of parameters:
</p>
<pre class="r"><code>cost_function_rmse(c(1, 0, 2, 2, 1, 0),
              train_data = logged_train_data,
              validation_data = logged_validation_data,
              forecast_periods = 65)</code></pre>
<pre><code>## [1] 0.1731473</code></pre>
<p>
Ok, now let’s start with optimizing the hyperparameters. Let’s help the genetic algorithm a little bit by defining where it should perform the search:
</p>
<pre class="r"><code>domains &lt;- matrix(c(0, 3, 0, 2, 0, 3, 0, 3, 0, 2, 0, 3), byrow = TRUE, ncol = 2)</code></pre>
<p>
This matrix constraints the first parameter to lie between 0 and 3, the second one between 0 and 2, and so on.
</p>
<p>
Let’s call the <code>genoud()</code> function from the <code>{rgenoud}</code> package, and use 8 cores:
</p>
<pre class="r"><code>cl &lt;- makePSOCKcluster(8)
clusterExport(cl, c('logged_train_data', 'logged_validation_data'))

tic &lt;- Sys.time()

auto_arima_rmse &lt;- genoud(cost_function_rmse,
                     nvars = 6,
                     data.type.int = TRUE,
                     starting.values = c(1, 0, 2, 2, 1, 0), # &lt;- from auto.arima
                     Domains = domains,
                     cluster = cl,
                     train_data = logged_train_data,
                     validation_data = logged_validation_data,
                     forecast_periods = length(logged_validation_data),
                     hard.generation.limit = TRUE)
toc_rmse &lt;- Sys.time() - tic</code></pre>
<p>
<code>makePSOCKcluster()</code> is a function from the <code>{parallel}</code> package. I must also <em>export</em> the global variables <code>logged_train_data</code> or <code>logged_validation_data</code>. If I don’t do that, the workers called by <code>genoud()</code> will not <em>know</em> about these variables and an error will be returned. The option <code>data.type.int = TRUE</code> force the algorithm to look only for integers, and <code>hard.generation.limit =&nbsp;TRUE</code> forces the algorithm to stop after 100 generations.
</p>
<p>
The process took 7 minutes, which is faster than doing the grid search. What was the solution found?
</p>
<pre class="r"><code>auto_arima_rmse</code></pre>
<pre><code>## $value
## [1] 0.0001863039
## 
## $par
## [1] 3 2 1 1 2 1
## 
## $gradients
## [1] NA NA NA NA NA NA
## 
## $generations
## [1] 11
## 
## $peakgeneration
## [1] 1
## 
## $popsize
## [1] 1000
## 
## $operators
## [1] 122 125 125 125 125 126 125 126   0</code></pre>
<p>
Let’s train the model using the <code>arima()</code> function at these parameters:
</p>
<pre class="r"><code>best_model_rmse &lt;- arima(logged_train_data, order = auto_arima_rmse$par[1:3], 
                         season = list(order = auto_arima_rmse$par[4:6], period = 12),
                         method = "ML")

summary(best_model_rmse)</code></pre>
<pre><code>## 
## Call:
## arima(x = logged_train_data, order = auto_arima_rmse$par[1:3], seasonal = list(order = auto_arima_rmse$par[4:6], 
##     period = 12), method = "ML")
## 
## Coefficients:
##           ar1      ar2      ar3      ma1     sar1     sma1
##       -0.6999  -0.4541  -0.0476  -0.9454  -0.4996  -0.9846
## s.e.   0.1421   0.1612   0.1405   0.1554   0.1140   0.2193
## 
## sigma^2 estimated as 0.006247:  log likelihood = 57.34,  aic = -100.67
## 
## Training set error measures:
##                         ME       RMSE        MAE          MPE      MAPE
## Training set -0.0006142355 0.06759545 0.04198561 -0.005408262 0.3600483
##                   MASE         ACF1
## Training set 0.4386693 -0.008298546</code></pre>
<p>
Let’s extract the forecasts:
</p>
<pre class="r"><code>best_model_rmse_forecast &lt;- forecast::forecast(best_model_rmse, h = 65)

best_model_rmse_forecast &lt;- to_tibble(best_model_rmse_forecast)</code></pre>
<pre><code>## Joining, by = "date"
## Joining, by = "date"</code></pre>
<pre class="r"><code>starting_model_forecast &lt;- forecast(starting_model, h = 65)

starting_model_forecast &lt;- to_tibble(starting_model_forecast)</code></pre>
<pre><code>## Joining, by = "date"
## Joining, by = "date"</code></pre>
<p>
and plot the forecast to see how it looks:
</p>
<pre class="r"><code>avia_clean_monthly %&gt;%
    group_by(date) %&gt;%
    summarise(total = sum(passengers)) %&gt;%
    mutate(total_ihs = ihs(total)) %&gt;%
    ggplot() +
    ggtitle("Minimization of RMSE") +
    geom_line(aes(y = total_ihs, x = date), colour = "#82518c") +
    scale_x_date(date_breaks = "1 year", date_labels = "%m-%Y") +
    geom_ribbon(data = best_model_rmse_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = "#666018", alpha = 0.2) +
    geom_line(data = best_model_rmse_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = "#8e9d98") +
    geom_ribbon(data = starting_model_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = "#98431e", alpha = 0.2) +
    geom_line(data = starting_model_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = "#a53031") +
    theme_blog()</code></pre>
<div style="text-align: center;">
<img src="../assets/img/rgenoud_arima-14-1.png" width="80%" height="auto">
</div>
<p>
The yellowish line and confidence intervals come from minimizing the genetic algorithm, and the redish from <code>auto.arima()</code>. Interesting; the point estimate is very precise, but the confidence intervals are very wide. Low bias, high variance.
</p>
<p>
Now, let’s try with another cost function, where I minimize the BIC, similar to the <code>auto.arima()</code> function:
</p>
<pre class="r"><code>cost_function_bic &lt;- function(param, train_data, validation_data, forecast_periods){
    order &lt;- param[1:3]
    season &lt;- c(param[4:6], 12)
    model &lt;- purrr::possibly(arima, otherwise = NULL)(x = train_data, order = order, 
                                                      seasonal = season,
                                                      method = "ML")
    if(is.null(model)){
        return(9999999)
    } else {
        BIC(model)
    }
}</code></pre>
<p>
Let’s take a look at the cost at the parameter values returned by <code>auto.arima()</code>:
</p>
<pre class="r"><code>cost_function_bic(c(1, 0, 2, 2, 1, 0),
              train_data = logged_train_data,
              validation_data = logged_validation_data,
              forecast_periods = 65)</code></pre>
<pre><code>## [1] -184.6397</code></pre>
<p>
Let the genetic algorithm run again:
</p>
<pre class="r"><code>cl &lt;- makePSOCKcluster(8)
clusterExport(cl, c('logged_train_data', 'logged_validation_data'))

tic &lt;- Sys.time()

auto_arima_bic &lt;- genoud(cost_function_bic,
                     nvars = 6,
                     data.type.int = TRUE,
                     starting.values = c(1, 0, 2, 2, 1, 0), # &lt;- from auto.arima
                     Domains = domains,
                     cluster = cl,
                     train_data = logged_train_data,
                     validation_data = logged_validation_data,
                     forecast_periods = length(logged_validation_data),
                     hard.generation.limit = TRUE)
toc_bic &lt;- Sys.time() - tic</code></pre>
<p>
This time, it took 6 minutes, a bit slower than before. Let’s take a look at the solution:
</p>
<pre class="r"><code>auto_arima_bic</code></pre>
<pre><code>## $value
## [1] -201.0656
## 
## $par
## [1] 0 1 1 1 0 1
## 
## $gradients
## [1] NA NA NA NA NA NA
## 
## $generations
## [1] 12
## 
## $peakgeneration
## [1] 1
## 
## $popsize
## [1] 1000
## 
## $operators
## [1] 122 125 125 125 125 126 125 126   0</code></pre>
<p>
Let’s train the model at these parameters:
</p>
<pre class="r"><code>best_model_bic &lt;- arima(logged_train_data, order = auto_arima_bic$par[1:3], 
                        season = list(order = auto_arima_bic$par[4:6], period = 12),
                        method = "ML")

summary(best_model_bic)</code></pre>
<pre><code>## 
## Call:
## arima(x = logged_train_data, order = auto_arima_bic$par[1:3], seasonal = list(order = auto_arima_bic$par[4:6], 
##     period = 12), method = "ML")
## 
## Coefficients:
##           ma1    sar1    sma1
##       -0.6225  0.9968  -0.832
## s.e.   0.0835  0.0075   0.187
## 
## sigma^2 estimated as 0.004145:  log likelihood = 109.64,  aic = -211.28
## 
## Training set error measures:
##                       ME       RMSE        MAE        MPE      MAPE
## Training set 0.003710982 0.06405303 0.04358164 0.02873561 0.3753513
##                   MASE        ACF1
## Training set 0.4553447 -0.03450603</code></pre>
<p>
And let’s plot the results:
</p>
<pre class="r"><code>best_model_bic_forecast &lt;- forecast::forecast(best_model_bic, h = 65)

best_model_bic_forecast &lt;- to_tibble(best_model_bic_forecast)</code></pre>
<pre><code>## Joining, by = "date"
## Joining, by = "date"</code></pre>
<pre class="r"><code>avia_clean_monthly %&gt;%
    group_by(date) %&gt;%
    summarise(total = sum(passengers)) %&gt;%
    mutate(total_ihs = ihs(total)) %&gt;%
    ggplot() +
    ggtitle("Minimization of BIC") +
    geom_line(aes(y = total_ihs, x = date), colour = "#82518c") +
    scale_x_date(date_breaks = "1 year", date_labels = "%m-%Y") +
    geom_ribbon(data = best_model_bic_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = "#5160a0", alpha = 0.2) +
    geom_line(data = best_model_bic_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = "#208480") +
    geom_ribbon(data = starting_model_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = "#98431e", alpha = 0.2) +
    geom_line(data = starting_model_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = "#a53031") +
    theme_blog()</code></pre>
<div style="text-align: center;">
<img src="../assets/img/rgenoud_arima-21-1.png" width="80%" height="auto">
</div>
<p>
The solutions are very close, both in terms of point estimates and confidence intervals. Bias increased, but variance lowered… This gives me an idea! What if I minimize the RMSE, while keeping the number of parameters low, as a kind of regularization? This is somewhat what minimising BIC does, but let’s try to do it a more “naive” approach:
</p>
<pre class="r"><code>cost_function_rmse_low_k &lt;- function(param, train_data, validation_data, forecast_periods, max.order){
    order &lt;- param[1:3]
    season &lt;- c(param[4:6], 12)
    if(param[1] + param[3] + param[4] + param[6] &gt; max.order){
        return(9999999)
    } else {
        model &lt;- purrr::possibly(arima, otherwise = NULL)(x = train_data, 
                                                          order = order, 
                                                          seasonal = season,
                                                          method = "ML")
    }
    if(is.null(model)){
        return(9999999)
    } else {
        forecast_model &lt;- forecast::forecast(model, h = forecast_periods)
        point_forecast &lt;- forecast_model$mean
        sqrt(mean(point_forecast - validation_data) ** 2)
    }
}</code></pre>
<p>
This is also similar to what <code>auto.arima()</code> does; by default, the <code>max.order</code> argument in <code>auto.arima()</code> is set to 5, and is the sum of <code>p + q + P + Q</code>. So I’ll try something similar.
</p>
<p>
Let’s take a look at the cost at the parameter values returned by <code>auto.arima()</code>:
</p>
<pre class="r"><code>cost_function_rmse_low_k(c(1, 0, 2, 2, 1, 0),
              train_data = logged_train_data,
              validation_data = logged_validation_data,
              forecast_periods = 65,
              max.order = 5)</code></pre>
<pre><code>## [1] 0.1731473</code></pre>
<p>
Let’s see what will happen:
</p>
<pre class="r"><code>cl &lt;- makePSOCKcluster(8)
clusterExport(cl, c('logged_train_data', 'logged_validation_data'))

tic &lt;- Sys.time()

auto_arima_rmse_low_k &lt;- genoud(cost_function_rmse_low_k,
                         nvars = 6,
                         data.type.int = TRUE,
                         starting.values = c(1, 0, 2, 2, 1, 0), # &lt;- from auto.arima
                         max.order = 5,
                         Domains = domains,
                         cluster = cl,
                         train_data = logged_train_data,
                         validation_data = logged_validation_data,
                         forecast_periods = length(logged_validation_data),
                         hard.generation.limit = TRUE)
toc_rmse_low_k &lt;- Sys.time() - tic</code></pre>
<p>
It took 1 minute to train this one, quite fast! Let’s take a look:
</p>
<pre class="r"><code>auto_arima_rmse_low_k</code></pre>
<pre><code>## $value
## [1] 0.002503478
## 
## $par
## [1] 1 2 0 3 1 0
## 
## $gradients
## [1] NA NA NA NA NA NA
## 
## $generations
## [1] 11
## 
## $peakgeneration
## [1] 1
## 
## $popsize
## [1] 1000
## 
## $operators
## [1] 122 125 125 125 125 126 125 126   0</code></pre>
<p>
And let’s plot it:
</p>
<pre class="r"><code>best_model_rmse_low_k &lt;- arima(logged_train_data, order = auto_arima_rmse_low_k$par[1:3], 
                               season = list(order = auto_arima_rmse_low_k$par[4:6], period = 12),
                               method = "ML")

summary(best_model_rmse_low_k)</code></pre>
<pre><code>## 
## Call:
## arima(x = logged_train_data, order = auto_arima_rmse_low_k$par[1:3], seasonal = list(order = auto_arima_rmse_low_k$par[4:6], 
##     period = 12), method = "ML")
## 
## Coefficients:
##           ar1     sar1     sar2     sar3
##       -0.6468  -0.7478  -0.5263  -0.1143
## s.e.   0.0846   0.1171   0.1473   0.1446
## 
## sigma^2 estimated as 0.01186:  log likelihood = 57.88,  aic = -105.76
## 
## Training set error measures:
##                        ME      RMSE        MAE         MPE      MAPE
## Training set 0.0005953302 0.1006917 0.06165919 0.003720452 0.5291736
##                   MASE       ACF1
## Training set 0.6442205 -0.3706693</code></pre>
<pre class="r"><code>best_model_rmse_low_k_forecast &lt;- forecast::forecast(best_model_rmse_low_k, h = 65)

best_model_rmse_low_k_forecast &lt;- to_tibble(best_model_rmse_low_k_forecast)</code></pre>
<pre><code>## Joining, by = "date"
## Joining, by = "date"</code></pre>
<pre class="r"><code>avia_clean_monthly %&gt;%
    group_by(date) %&gt;%
    summarise(total = sum(passengers)) %&gt;%
    mutate(total_ihs = ihs(total)) %&gt;%
    ggplot() +
    ggtitle("Minimization of RMSE + low k") +
    geom_line(aes(y = total_ihs, x = date), colour = "#82518c") +
    scale_x_date(date_breaks = "1 year", date_labels = "%m-%Y") +
    geom_ribbon(data = best_model_rmse_low_k_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = "#5160a0", alpha = 0.2) +
    geom_line(data = best_model_rmse_low_k_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = "#208480") +
    geom_ribbon(data = starting_model_forecast, aes(x = date, ymin = lower95, ymax = upper95),
                fill = "#98431e", alpha = 0.2) +
    geom_line(data = starting_model_forecast, aes(x = date, y = point_estimate), 
              linetype = 2, colour = "#a53031") +
    theme_blog()</code></pre>
<div style="text-align: center;">
<img src="../assets/img/rgenoud_arima-28-1.png" width="80%" height="auto">
</div>
<p>
Looks like this was not the right strategy. There might be a better cost function than what I have tried, but looks like minimizing the BIC is the way to go.
</p>


</section>

</main> <!-- /main -->
<hr style="border: 1px solid #ccc; margin: 20px 0;">
<footer>
If you find the content in this blog useful, you might want to follow
me on <a href="https://fosstodon.org/@brodriguesco">Mastodon</a> or <a href="https://www.twitter.com/brodriguesco">twitter</a> for blog post updates or
<a href="https://www.buymeacoffee.com/brodriguesco">buy me an espresso</a> or <a href="https://www.paypal.me/brodriguesco">paypal.me</a>, or buy my <a href="../books.html">ebooks</a>.
You can also watch my videos on <a href="https://www.youtube.com/c/BrunoRodrigues1988/">youtube</a>.
So much content for you to consoom!
<p></p>
<style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Cookie', cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}</style>
<p>
<link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet"><a class="bmc-button" target="_blank" href="https://www.buymeacoffee.com/brodriguesco"><img src="https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg" alt="Buy me an Espresso"><span style="margin-left:5px">Buy me an Espresso</span></a>
</p>
  <div class="row">
    <div class="col-lg-12">
        <p>© <span id="year"></span>, content by Bruno Rodrigues, unless otherwise stated, every content of this blog is licensed under the <a href="http://www.wtfpl.net/txt/copying/" rel="nofollow">WTFPL</a>.</p>
        <p>Built with <a href="https://quarto.org/">Quarto</a> and <a href="https://nixos.org/explore/">Nix</a>, hosted on <a href="https://pages.github.com/">GitHub Pages</a>.</p>
      <p><a href="../index.html">Back to main page.</a></p>
    </div>
  </div>
</footer>
<script>
 document.getElementById('year').textContent = new Date().getFullYear();
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/b-rodrigues\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>