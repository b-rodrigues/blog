<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Econometrics and Free Software</title>
<link>https://b-rodrigues.github.io/</link>
<atom:link href="https://b-rodrigues.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.6.37</generator>
<lastBuildDate>Wed, 21 Dec 2022 00:00:00 GMT</lastBuildDate>
<item>
  <title>Code longevity of the R programming language</title>
  <link>https://b-rodrigues.github.io/posts/2022-12-21-longevity.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/spelunky.jpg" width="80%" height="auto">
</p>
</div>
<p>
I’ve been working on a way to evaluate how old R code runs on the current version of R, and am now ready to share some results. It all started with this tweet:
</p>
<div style="text-align:center;">
<p>
<a href="https://twitter.com/brodriguesco/status/1588088437655093250?s=20&amp;t=-8DPAVEpMEcAuxy8Q2sAQw"> <img src="https://b-rodrigues.github.io/assets/img/tweet_old_code.png" width="80%" height="auto"> </a>
</p>
</div>
<p>
The problem is that you have to find old code laying around. Some people have found old code they wrote a decade or more ago and tried to rerun it; there’s <a href="https://notstatschat.rbind.io/2022/10/14/code-archaeology-polynomial-distributed-lags/">this blog post</a> by Thomas Lumley and <a href="https://www.jumpingrivers.com/blog/r-from-the-turn-of-the-century/">this other one</a> by Colin Gillespie that I find fascinating, but ideally we’d have more than a handful of old scripts laying around. This is when Dirk Eddelbuettel suggested this:
</p>
<div style="text-align:center;">
<p>
<a href="https://twitter.com/eddelbuettel/status/1588149491772923907?s=20&amp;t=-8DPAVEpMEcAuxy8Q2sAQw"> <img src="https://b-rodrigues.github.io/assets/img/tweet_dirk.png" width="80%" height="auto"> </a>
</p>
</div>
<p>
And this is what I did. I wrote a lot of code to achieve this graph here:
</p>
<div style="text-align:center;">
<p>
<a href="https://github.com/b-rodrigues/code_longevity"> <img src="https://b-rodrigues.github.io/assets/img/r_longevity.png" width="80%" height="auto"> </a>
</p>
</div>
<p>
This graph shows the following: for each version of R, starting with R version 0.6.0 (released in 1997), how well the examples that came with a standard installation of R run on the current version of R (version 4.2.2 as of writing). These are the examples from the default packages like <code>{base}</code>, <code>{stats}</code>, <code>{stats4}</code>, and so on. Turns out that more than 75% of the example code from version 0.6.0 still works on the current version of R. A small fraction output a message (which doesn’t mean the code doesn’t work), some 5% raise a warning, which again doesn’t necessarily mean that the code doesn’t work, and finally around 20% or so errors. As you can see, the closer we get to the current release, the less errors get raised.
</p>
<p>
(But something important should be noted: just because some old piece of code runs without error, doesn’t mean that the result is exactly the same. There might be cases where the same function returns different results on different versions of R.)
</p>
<p>
Then, once I had this graph, I had to continue with packages. How well do old examples from any given package run on the current version of the same package?
</p>
<p>
What I came up with is a Docker image that runs this for you, and even starts a Shiny app to let you explore the results. All you have to do is edit one line in the Dockerfile. This Docker image uses a lot of code from other projects, and I even had to write a package for this, called <code>{wontrun}</code>.
</p>
<section id="the-wontrun-package" class="level2">
<h2 class="anchored" data-anchor-id="the-wontrun-package">
The {wontrun} package
</h2>
<p>
The problem I needed to solve was how to easily run examples from archived packages. So I needed to first have an easy way to download them, then extract the examples, and then run them. So to help me with this I wrote the <code>{wontrun}</code> package (thanks again to <a href="https://fediscience.org/@dmi3kno/109296599193965025">Deemah</a> for suggesting the name and making the hex logo!). To be honest, the quality of this package could be improved. Documentation is still lacking, and the package only seems to work on Linux (but that’s not an issue, since it really only makes sense to use it within Docker). In any case, this package has a function to download the archived source code for a given package, using the <code>get_archived_sources()</code> function. This function takes the name of a package as an input and returns a data frame with the archived sources and the download links to them. To actually download the source packages, the <code>get_examples()</code> function is used. This function extracts the examples from the <code>man/</code> folder included in source packages, and converts the examples into scripts. Remember that example files are in the <code>.Rd</code> format, which is some kind of markup language format. Thankfully, there’s a function called <code>Rd2ex()</code> from the <code>{tools}</code> package which I use to convert <code>.Rd</code> files into <code>.R</code> scripts.
</p>
<p>
Then, all that there is to do is to run these scripts. But that’s not as easy as one might think. This is becuse I first need to make sure that the latest version of the package is installed, and ideally, I don’t want to pollute my library with packages that I never use but only wanted to assess for their code longevity. I also need to make sure that I’m running all these scripts <em>all else being equal</em>: so same version of R, same version of the current packages and same operating system. That why I needed to use Docker for this. Also, all the required dependencies to run the examples should get installed as well. Sometimes, some examples load data from another package. So for this, I’m using the <code>renv::dependencies()</code> function which scans a file for calls to <code>library()</code> or <code>package::function()</code> to list the dependencies and then install them. This all happens automatically.
</p>
<p>
To conclude this section: I cannot stress how much I’m relying on work by other people for this. This is the NAMESPACE file of the <code>{wontrun}</code> package (I’m only showing the import statements):
</p>
<pre><code>importFrom(callr,r_vanilla)
importFrom(ctv,ctv)
importFrom(dplyr,filter)
importFrom(dplyr,group_by)
importFrom(dplyr,mutate)
importFrom(dplyr,rename)
importFrom(dplyr,select)
importFrom(dplyr,ungroup)
importFrom(furrr,future_map2)
importFrom(future,multisession)
importFrom(future,plan)
importFrom(janitor,clean_names)
importFrom(lubridate,year)
importFrom(lubridate,ymd)
importFrom(lubridate,ymd_hm)
importFrom(magrittr,"%&gt;%")
importFrom(pacman,p_load)
importFrom(pkgsearch,cran_package)
importFrom(purrr,keep)
importFrom(purrr,map)
importFrom(purrr,map_chr)
importFrom(purrr,map_lgl)
importFrom(purrr,pluck)
importFrom(purrr,pmap_chr)
importFrom(purrr,possibly)
importFrom(renv,dependencies)
importFrom(rlang,`!!`)
importFrom(rlang,cnd_message)
importFrom(rlang,quo)
importFrom(rlang,try_fetch)
importFrom(rvest,html_nodes)
importFrom(rvest,html_table)
importFrom(rvest,read_html)
importFrom(stringr,str_extract)
importFrom(stringr,str_remove_all)
importFrom(stringr,str_replace)
importFrom(stringr,str_trim)
importFrom(tibble,as_tibble)
importFrom(tidyr,unnest)
importFrom(tools,Rd2ex)
importFrom(withr,with_package)</code></pre>
<p>
That’s a lot of packages, most of them from Posit. What can I say, these packages are great! Even if I could reduce the number of dependencies from <code>{wontrun}</code>, I honestly cannot be bothered, I’ve been spoilt by the quality of Posit packages.
</p>
</section>
<section id="docker-for-reproducibility" class="level2">
<h2 class="anchored" data-anchor-id="docker-for-reproducibility">
Docker for reproducibility
</h2>
<p>
The Dockerfile I wrote is based on Ubuntu 22.04, compiles R 4.2.2 from source, and sets the repositories to <a href="https://packagemanager.rstudio.com/cran/__linux__/jammy/2022-11-21" class="uri">https://packagemanager.rstudio.com/cran/<strong>linux</strong>/jammy/2022-11-21</a> . This way, the packages get downloaded exactly as they were on November 21st 2022. This ensures that if readers of this blog post want to run this to assess the code longevity of some R packages, we can compare results and be certain that any conditions raised are not specific to any difference in R or package version. It should be noted that this Dockerfile is based on the work of the Rocker project, and more specifically their <a href="https://rocker-project.org/images/versioned/r-ver.html">versioned images</a> which are recommended when reproducibility is needed. Becuse the code runs inside Docker, it doesn’t matter if the <code>{wontrun}</code> package only runs on Linux (I think that this is the case because of the <code>untar()</code> function which I use to decompress the downloaded compressed archives from CRAN, and which seems to have a different behaviour on Linux vs Windows. No idea how this function behaves on macOS).
</p>
<p>
The image defined by this Dockerfile is quite heavy, because I also installed all possible dependencies required to run R packages smoothly. This is because even though the Posit repositories install compiled packages on Linux, shared libraries are still needed for the packages to run.
</p>
<p>
Here is what the Dockerfile looks like:
</p>
<pre><code>FROM brodriguesco/wontrun:r4.2.2

# This gets the shiny app
RUN git clone https://github.com/b-rodrigues/longevity_app.git

# These are needed for the Shiny app
RUN R -e "install.packages(c('dplyr', 'forcats', 'ggplot2', 'shiny', 'shinyWidgets', 'DT'))"

RUN mkdir /home/intermediary_output/
RUN mkdir /home/output/

COPY wontrun.R /home/wontrun.R

# Add one line per package you want to asses
RUN Rscript '/home/wontrun.R' dplyr 6
RUN Rscript '/home/wontrun.R' haven 6

CMD mv /home/intermediary_output/* /home/output/ &amp;&amp; R -e 'shiny::runApp("/longevity_app", port = 1506, host = "0.0.0.0")'</code></pre>
<p>
As you can see it starts by pulling an image from Docker Hub called <code>wontrun:r4.2.2</code>. This is the image based on Ubuntu 22.04 with R compiled from source and all dependencies pre-installed. (This Dockerfile is available <a href="https://github.com/b-rodrigues/code_longevity/tree/master/wontrun_dockerfile">here</a>.)
</p>
<p>
Then my Shiny app gets cloned, the required packages for the app to run get installed, and some needed directories get made. Now comes the interesting part; a script called <code>wontrun.R</code> gets copied. This is what the script looks like:
</p>
<pre class="r"><code>#!/usr/bin/env Rscript
args &lt;- commandArgs(trailingOnly = TRUE)

library(wontrun)

packages_sources &lt;- get_archived_sources(args[1])

out &lt;- wontrun(packages_sources ,
               ncpus = args[2],
               setup = TRUE,
               wontrun_lib = "/usr/local/lib/R/site-library/")

saveRDS(object = out,
        file = paste0("/home/intermediary_output/", args[1], ".rds"))</code></pre>
<p>
This script uses the <code>{wontrun}</code> package to get the archived sources of a package of interest, and the examples get executed and results tallied using the <code>wontrun()</code> function. The results then get saved into an <code>.rds</code> file.
</p>
<p>
Calling this script is done with this line in the Dockerfile:
</p>
<pre><code>RUN Rscript '/home/wontrun.R' dplyr 6</code></pre>
<p>
The <code>dplyr</code> and <code>6</code> get passed down to the <code>wontrun.R</code> script as a list called <code>args</code>. So <code>args[1]</code> is the “dplyr” string, and <code>args[2]</code> is 6. This means that the examples from archived versions of the <code>{dplyr}</code> package will get assessed on the current version of <code>{dplyr}</code> using 6 cores. You can add as many lines as you want and thus assess as many packages as you want. Once you’re done with editing the Dockerfile, you can build the image; this will actually run the code, so depending on how many packages you want to assess and the complexity of the examples, this may take some hours. To build the image run this in a console:
</p>
<pre><code>docker build -t code_longevity_packages .</code></pre>
<p>
Now, you still need to actually run a container based on this image. Running the container will move the <code>.rds</code> files from the container to your machine so you can actually get to the results, and it will also start a Shiny app in which you will be able to upload the <code>.rds</code> file and explore the results. Run the container with (and don’t forget to change <code>path/to/repository/</code> with the correct path on your machine):
</p>
<pre><code>docker run --rm --name code_longevity_packages_container -v /path/to/repository/code_longevity_packages/output:/home/output:rw -p 1506:1506 code_longevity_packages</code></pre>
<p>
Go over to <code>http://localhost:1506/</code> to start the Shiny app and explore the results:
</p>
<div style="text-align:center;">
<p>
<video width="640" height="480" controls="">
<source src="../assets/img/code_longevity.mp4" type="video/mp4">
</video>
</p>
</div>
</section> ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-12-21-longevity.html</guid>
  <pubDate>Wed, 21 Dec 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Functional programming explains why containerization is needed for reproducibility</title>
  <link>https://b-rodrigues.github.io/posts/2022-11-30-pipelines-as.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/dino.png" width="80%" height="auto">
</p>
</div>
<p>
I’ve had some discussions online and in the real world about <a href="../posts/2022-11-16-open_source_repro.html">this blog post</a> and I’d like to restate why containerization is needed for reproducibility, and do so from the lens of functional programming.
</p>
<p>
When setting up a pipeline, wether you’re a functional programming enthusiast or not, you’re aiming at setting it up in a way that this pipeline is the composition of (potentially) many referentially transparent and pure functions.
</p>
<p>
As a reminder:
</p>
<ul>
<li>
<p>
referentially transparent functions are functions that always return the same output for the same given input. So for example <code>f(x, y):=x+y</code> is referentially transparent, but <code>h(x):=x+y</code> is not. Because <code>y</code> is not an input of <code>h</code>, <code>h</code> will look for <code>y</code> in the global environment. Depending on the value of y, <code>h(1)</code> might equal 10 one day, but 100 the next. Let’s say that <code>f(1, 10)</code> is always equal to 11. Because this is true, you could replace <code>f(1, 10)</code> everywhere it appears with 11. But consider the following example of a function that is not referentially transparent, <code>rnorm()</code>. Try <code>rnorm(1)</code> several times… It will always give a different result! This is because <code>rnorm()</code> looks for the seed in the global environment and uses that to generate a random number.
</p>
</li>
<li>
<p>
pure functions are functions without side effects. So a function just does its thing, and does not interact with anything else; doesn’t change anything in the global environment, doesn’t print anything on screen, doesn’t write anything to disk. Basically, pure functions are functions that do nothing else but computing stuff. Now this may seem limiting, and to some extent it is, so we will need to relax this a bit: we’ll be ok with functions that output stuff, but only the very last function in the pipeline will be allowed to do it.
</p>
</li>
</ul>
<p>
To be pure, a function needs to be referentially transparent.
</p>
<p>
Ok so now that we know what referentially transparent and pure functions are, let’s explain why we want a pipeline to be a composition of such functions. Function composition is an operation that takes two functions <em>g</em> and <em>f</em> and returns a new function <em>h</em> such that <code>h(x) = g(f(x))</code>. Formally:
</p>
<pre><code>h = g ∘ f such that h(x) = g(f(x))</code></pre>
<p>
<code>∘</code> is the composition operator. You can read <code>g ∘ f</code> as <em>g after f</em>. In R, you can compose functions very easily, simply by using |&gt; or %&gt;%:
</p>
<pre><code>h &lt;- f |&gt; g</code></pre>
<p>
<code>f |&gt; g</code> can be read as <em>f then g</em>, which is equivalent to <em>g after f</em> (ok, using <code>|&gt;</code> is chaining rather than composing functions, but the net effect is the same).
</p>
<p>
So <code>h</code> would be our complete pipeline, which would be the composition, or chaining, of as many functions as needed:
</p>
<pre><code>h &lt;- a |&gt; b |&gt; c |&gt; d ... |&gt; z</code></pre>
<p>
If all the functions are pure (and referentially transparent) then we’re assured that <code>h</code> will always produce the same outputs for the same inputs. As stated above, <code>z</code> will be allowed to not be pure an actually output something (like a rendered Quarto document) to disk. Ok so that’s great, and all, but why does the title of this blog post say that containerization is needed?
</p>
<p>
The problem is that all the functions we use have “hidden” inputs, and are never truly referentially transparent. These inputs are the following:
</p>
<ul>
<li>
Version of R (or whatever programming language you’re using)
</li>
<li>
Versions of the packages you’re using
</li>
<li>
Operating system and its version (and all the different operating system dependencies that get used at run- or compile time)
</li>
</ul>
<p>
For example, let’s take a look at this function:
</p>
<pre class="r"><code>f &lt;- function(x){
  if (c(TRUE, FALSE)) x 
}</code></pre>
<p>
which will return the following on R 4.1 (which was released on May 2021):
</p>
<pre class="r"><code>f(1)</code></pre>
<pre class="r"><code>[1] 1
Warning message:
In if (c(TRUE, FALSE)) 1 :
  the condition has length &gt; 1 and only the first element will be used</code></pre>
<p>
So a result 1 and a warning. On R 4.2.2 (the current version as of writing), the exact same call returns:
</p>
<pre class="r"><code>Error in if (c(TRUE, FALSE)) 1 : the condition has length &gt; 1</code></pre>
<p>
These types of breaking changes are rare in R, at least to my knowledge (I’m actually looking into this in greater detail, 2023 will likely be the year I show my findings), but in this case it illustrates my point: code that was behaving in a certain way started behaving in another way, even though nothing changed. What changed was the version of R, even though the function itself was pure. This wouldn’t be so surprising if instead of <code>f(x)</code>, the function was something like <code>f(x, r_version)</code>. In this case, the calls above would be something like:
</p>
<pre class="r"><code>f(1, r_version = "4.1")</code></pre>
<p>
and this would always return:
</p>
<pre class="r"><code>[1] 1
Warning message:
In if (c(TRUE, FALSE)) 1 :
  the condition has length &gt; 1 and only the first element will be used</code></pre>
<p>
but changing the call to this:
</p>
<pre class="r"><code>f(1, r_version = "4.2.2")</code></pre>
<p>
would return the error:
</p>
<pre class="r"><code>Error in if (c(TRUE, FALSE)) 1 : the condition has length &gt; 1</code></pre>
<p>
regardless of the version of R we’re running, so our function would be referentially transparent.
</p>
<p>
Alas, this is not possible, at least not like this.
</p>
<p>
Hence why tools like Docker, Podman (a Docker alternative) or Guix (which I learned about recently but never used, yet, and as far as I know, not a containerization solution, but a solution actually based on functional programming) are crucial to ensure that your pipeline is truly reproducible. Basically, using Docker you turn the hidden inputs defined before (versions of tools and OS) explicit. Take a look at this Dockerfile:
</p>
<pre class="r"><code>FROM rocker/r-ver:4.1.0

RUN R -e "f &lt;- function(x){if (c(TRUE, FALSE)) x};f(1)"

CMD ["R"]</code></pre>
<p>
here’s what happens when you build it:
</p>
<pre><code>➤ docker build -t my_pipeline .</code></pre>
<pre><code>Sending build context to Docker daemon  2.048kB
Step 1/3 : FROM rocker/r-ver:4.1.0
4.1.0: Pulling from rocker/r-ver

eaead16dc43b: Already exists 
35eac095fa03: Pulling fs layer
c0088a79f8ab: Pulling fs layer
28e8d0ade0c0: Pulling fs layer
Digest: sha256:860c56970de1d37e9c376ca390617d50a127b58c56fbb807152c2e976ce02002
Status: Downloaded newer image for rocker/r-ver:4.1.0
 ---&gt; d83268fb6cda
Step 2/3 : RUN R -e "f &lt;- function(x){if (c(TRUE, FALSE)) x};f(1)"
 ---&gt; Running in a158e4ab474f

R version 4.1.0 (2021-05-18) -- "Camp Pontanezen"
Copyright (C) 2021 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

&gt; f &lt;- function(x){if (c(TRUE, FALSE)) x};f(1)
[1] 1
Warning message:
In if (c(TRUE, FALSE)) x :&gt; 
&gt; 

  the condition has length &gt; 1 and only the first element will be used
Removing intermediate container a158e4ab474f
 ---&gt; 49e2eb20a535
Step 3/3 : CMD ["R"]
 ---&gt; Running in ccda657c4d95
Removing intermediate container ccda657c4d95
 ---&gt; 5a432adbe6ff
Successfully built 5a432adbe6ff
Successfully tagged my_package:latest</code></pre>
<p>
as you can read from above, this starts the container with R version 4.1.0 and runs the code in it. We get back our result with the warning (it should be noted that in practice, you would structure your Dockerfile differently for running an actual pipeline).
</p>
<p>
This Dockerfile starts by using rocker/r-ver:4.1 as a basis. You can find this image in the <a href="https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/r-ver_4.1.0.Dockerfile">versioned</a> repository from the Rocker Project. This base image starts off from Ubuntu Focal Fossa so (Ubuntu version 20.04), uses R version 4.1.0 and even uses frozen CRAN repository as of 2021-08-09. It then runs our pipeline (or in this case, our simple function) in this, fixed environment. Our function essentially became <code>f(x, os_version, r_version, packages_version)</code> instead of just <code>f(x)</code>. By changing the first statement of the Dockerfile:
</p>
<pre class="r"><code>FROM rocker/r-ver:4.1.0</code></pre>
<p>
to this:
</p>
<pre class="r"><code>FROM rocker/r-ver:3.5.0</code></pre>
<p>
we can even do some archaeology and run the pipeline on R version 3.5.0! This has great potential and hopefully one day Docker or similar solution will become just another tool in scientists/analysts toolbox.
</p>
<p>
If you want to start using Docker for your projects, I’ve written this <a href="../posts/2022-11-19-raps.html">tutorial</a> and even a whole <a href="https://rap4mads.eu/">ebook</a>.
</p>



 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-11-30-pipelines-as.html</guid>
  <pubDate>Wed, 30 Nov 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducibility with Docker and Github Actions for the average R enjoyer</title>
  <link>https://b-rodrigues.github.io/posts/2022-11-19-raps.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/raps.png" width="80%" height="auto">
</p>
</div>
<p>
<em>This blog post is a summary of Chapters 9 and 10 of this <a href="https://rap4mads.eu/self-contained-raps-with-docker.html">ebook</a> I wrote for a course</em>
</p>
<p>
The goal is the following: we want to write a pipeline that produces some plots. We want the code to be executed inside a Docker container for reproducibility, and we want this container to get executed on Github Actions. Github Actions is a <em>Continuous Integration and Continuous Delivery</em> service from Github that allows you to execute arbitrary code on events (like pushing code to a repo). It’s pretty neat. For example, you could be writing a paper using Latex and get the pdf compiled on Github Actions each time you push, without needing to have to do it yourself. Or if you are developing an R package, unit tests could get executed each time you push code, so you don’t have to do it manually.
</p>
<p>
This blog post will assume that you are familiar with R and are comfortable with it, as well as Git and Github.
</p>
<p>
It will also assume that you’ve at least heard of Docker and have it already installed on your computer, but ideally, you’ve already played a bit around with Docker. If you’re a total Docker beginner, this tutorial might be a bit too esoteric.
</p>
<p>
Let’s start by writing a pipeline that works on our machines using the <code>{targets}</code> package.
</p>
<section id="getting-something-working-on-your-machine" class="level2">
<h2 class="anchored" data-anchor-id="getting-something-working-on-your-machine">
Getting something working on your machine
</h2>
<p>
So, let’s say that you got some nice code that you need to rerun every month, week, day, or even hour. Or let’s say that you’re a researcher that is concerned with reproducibility. Let’s also say that you want to make sure that this code always produces the same result (let’s say it’s some plots that need to get remade once some data is refreshed).
</p>
<p>
Ok, so first of all, you really want your workflow to be defined using the <code>{targets}</code> package. If you’re not familiar with <code>{targets}</code>, this will serve as a micro introduction, but you really should read the <code>{targets}</code> manual, at least the <a href="https://books.ropensci.org/targets/walkthrough.html">walkthrough</a> (watch the 4 minute video). <code>{targets}</code> is a build automation tool that you should definitely add to your toolbox.
</p>
<p>
Let’s define a workflow that does the following: data gets read, data gets filtered, data gets plotted. What’s the data about? Unemployment in Luxembourg. Luxembourg is a little Western European country that looks like a shoe and is <a href="https://raw.githubusercontent.com/rbind/b-rodrigues.github.com/master/static/img/rhode_island.png" width="80%" height="auto">about the size of .98 Rhode Islands</a> from which yours truly hails from. Did you know that Luxembourg was a monarchy, and the last Grand-Duchy in the World? I bet you did not know that. Also, what you should know to understand the script below is that the country of Luxembourg is divided into Cantons, and each Cantons into Communes. Basically, if Luxembourg was the USA, Cantons would be States and Communes would be Counties (or Parishes or Boroughs). What’s confusing is that “Luxembourg” is also the name of a Canton, and of a Commune (which also has the status of a city).
</p>
<p>
Anyways, here’s how my script looks like:
</p>
<pre class="r"><code>library(targets)
library(dplyr)
library(ggplot2)
source("functions.R")


list(
    tar_target(
        unemp_data,
        get_data()
    ),

    tar_target(
        lux_data,
        clean_unemp(unemp_data,
                    place_name_of_interest = "Luxembourg",
                    level_of_interest = "Country",
                    col_of_interest = active_population)
    ),

    tar_target(
        canton_data,
        clean_unemp(unemp_data,
                    level_of_interest = "Canton",
                    col_of_interest = active_population)
    ),

    tar_target(
        commune_data,
        clean_unemp(unemp_data,
                    place_name_of_interest = c("Luxembourg",
                                               "Dippach",
                                               "Wiltz",
                                               "Esch/Alzette",
                                               "Mersch"),
                    col_of_interest = active_population)
    ),

    tar_target(
        lux_plot,
        make_plot(lux_data)
    ),

    tar_target(
        canton_plot,
        make_plot(canton_data)
    ),

    tar_target(
        commune_plot,
        make_plot(commune_data)
    ),

    tar_target(
        luxembourg_saved_plot,
        save_plot("fig/luxembourg.png", lux_plot),
        format = "file"
    ),

    tar_target(
        canton_saved_plot,
        save_plot("fig/canton.png", canton_plot),
        format = "file"
    ),

    tar_target(
        commune_saved_plot,
        save_plot("fig/commune.png", commune_plot),
        format = "file"
    )


)</code></pre>
<p>
Because this is a <code>{targets}</code> script, this needs to be saved inside a file called <code>_targets.R</code>. Each <code>tar_target()</code> object defines a target that will get built once we run the pipeline. The first element of <code>tar_target()</code> is the name of the target, the second line a call to a function that returns the first element and in the last three targets <code>format = “file”</code> is used to indicate that this target saves an output to disk (as a file).
</p>
<p>
The fourth line of the script sources a script called <code>functions.R</code>. This script should be placed next to the <code>_targets.R</code> script and should look like this:
</p>
<pre><code># clean_unemp() is a function inside a package I made. Because I don't want you to install
# the package if you're following along, I'm simply sourcing it:

source("https://raw.githubusercontent.com/b-rodrigues/myPackage/main/R/functions.R")

# The cleaned data is also available in that same package. But again, because I don't want you
# to install a package just for a blog post, here is the script to clean it.
# Don't waste time trying to understand it, it's very specific to the data I'm using
# to illustrate the concept of reproducible analytical pipelines. Just accept this data 
# as given.

# This is a helper function to clean the data
clean_data &lt;- function(x){
  x %&gt;%
    janitor::clean_names() %&gt;%
    mutate(level = case_when(
             grepl("Grand-D.*", commune) ~ "Country",
             grepl("Canton", commune) ~ "Canton",
             !grepl("(Canton|Grand-D.*)", commune) ~ "Commune"
           ),
           commune = ifelse(grepl("Canton", commune),
                            stringr::str_remove_all(commune, "Canton "),
                            commune),
           commune = ifelse(grepl("Grand-D.*", commune),
                            stringr::str_remove_all(commune, "Grand-Duche de "),
                            commune),
           ) %&gt;%
    select(year,
           place_name = commune,
           level,
           everything())
}

# This reads in the data.
get_data &lt;- function(){
  list(
    "https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/unemp_2013.csv",
    "https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/unemp_2014.csv",
    "https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/unemp_2015.csv",
    "https://raw.githubusercontent.com/b-rodrigues/modern_R/master/datasets/unemployment/unemp_2016.csv",
  ) |&gt;
    purrr::map_dfr(readr::read_csv) %&gt;%
    purrr::map_dfr(clean_data)
}

# This plots the data
make_plot &lt;- function(data){
  ggplot(data) +
    geom_col(
      aes(
        y = active_population,
        x = year,
        fill = place_name
      )
    ) +
    theme(legend.position = "bottom",
          legend.title = element_blank())
}

# This saves plots to disk
save_plot &lt;- function(save_path, plot){
  ggsave(save_path, plot)
  save_path
}</code></pre>
<p>
What you could do instead of having a <code>functions.R</code> script that you source like this, is put everything inside a package that you then host on Github. But that’s outside the scope of this blog post. Put these scripts inside a folder, open an R session inside that folder, and run the pipeline using <code>targets::tar_make()</code>:
</p>
<pre class="r"><code>targets::tar_make()</code></pre>
<pre><code>/
Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

• start target unemp_data
• built target unemp_data [1.826 seconds]
• start target canton_data
• built target canton_data [0.038 seconds]
• start target lux_data
• built target lux_data [0.034 seconds]
• start target commune_data
• built target commune_data [0.043 seconds]
• start target canton_plot
• built target canton_plot [0.007 seconds]
• start target lux_plot
• built target lux_plot [0.006 seconds]
• start target commune_plot
• built target commune_plot [0.003 seconds]
• start target canton_saved_plot
Saving 7 x 7 in image
• built target canton_saved_plot [0.425 seconds]
• start target luxembourg_saved_plot
Saving 7 x 7 in image
• built target luxembourg_saved_plot [0.285 seconds]
• start target commune_saved_plot
Saving 7 x 7 in image
• built target commune_saved_plot [0.291 seconds]
• end pipeline [3.128 seconds]</code></pre>
<p>
You can now see a <code>fig/</code> folder in the root of your project with the plots. Sweet.
</p>
</section>
<section id="making-sure-this-is-reproducible" class="level2">
<h2 class="anchored" data-anchor-id="making-sure-this-is-reproducible">
Making sure this is reproducible
</h2>
<p>
Now what we would like to do is make sure that this pipeline will, for the same inputs, returns the same outputs FOREVER. If I’m running this in 10 years on R version 6.9, I want the exact same plots back. So the idea is to actually never run this on whatever version of R will be available in 10 years, but keep rerunning it, <em>ad vitam æternam</em> on whatever environment I’m using now to type this blog post. So for this, I’m going to use Docker.
</p>
<p>
(If, like me, you’re an average functional programming enjoyer, then this means getting rid of the hidden state of our pipeline. The hidden global state is the version of R and packages used to run the pipeline.)
</p>
<p>
What’s Docker? Docker is a way to run a Linux computer inside your computer (Linux or not). That computer is not real, but real enough for our purposes. Ever heard of virtual machines? Basically the same thing, but without the overhead of actually setting up and running a virtual machine.
</p>
<p>
You can write a simple text file that defines what your machine is, and what it should run. Thankfully, we don’t need to start from scratch and can use the amazing <a href="https://rocker-project.org/">Rocker project</a> that provides many, many, images for us to start playing with Docker. What’s a Docker image? A definition of a computer/machine. Which is a text file. Don’t ask why it’s called an image. Turns out the Rocker project has a page specifically on <a href="https://rocker-project.org/use/reproducibility.html">reproducibility</a>. Their advice can be summarised as follows: if you’re aiming at setting up a reproducible pipeline, use a version-stable image. This means that if you start from such an image, the exact same R version will always be used to run your pipeline. Plus, the RStudio Public Package Manager (RSPM), frozen at a specific date, will be used to fetch the packages needed for your pipeline. So, not only is the R version frozen, but the exact same packages will always get installed (as long as the RSPM exists, hopefully for a long time).
</p>
<p>
Now, I’ve been talking about a script that defines an image for some time. This script is called a <code>Dockerfile</code>, and you can find the versioned <code>Dockerfiles</code> <a href="https://github.com/rocker-org/rocker-versioned2/tree/master/dockerfiles">here</a>. As you can see there are many <code>Dockerfile</code>s, each defining a Linux machine and with several things pre-installed. Let’s take a look at the image <a href="https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/r-ver_4.2.1.Dockerfile">r-ver_4.2.1.Dockerfile</a>. What’s interesting here are the following lines (let’s ignore the others):
</p>
<pre><code>8 ENV R_VERSION=4.2.1

16 ENV CRAN=https://packagemanager.rstudio.com/cran/__linux__/focal/2022-10-28</code></pre>
<p>
The last characters of that link are a date. This means that if you use this for your project, packages will be downloaded as they were on the October 28th, 2022, and the R version used will always be version 4.2.1.
</p>
<p>
Ok so, how do we use this?
</p>
<p>
Let’s add a <code>Dockerfile</code> to our project. Simply create a text file called <code>Dockerfile</code> and add the following lines in it:
</p>
<pre><code>FROM rocker/r-ver:4.2.1

RUN R -e "install.packages(c('dplyr', 'purrr', 'readr', 'stringr', 'ggplot2', 'janitor', 'targets'))"

RUN mkdir /home/fig

COPY _targets.R /_targets.R

COPY functions.R /functions.R

CMD R -e "targets::tar_make()"</code></pre>
<p>
Before continuing, I should explain what the first line does:
</p>
<pre><code>FROM rocker/r-ver:4.2.1</code></pre>
<p>
This simply means that we are using the image <a href="https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/r-ver_4.2.1.Dockerfile">from before</a> as a base. This image is itself based on <em>Ubuntu Focal</em>, see its first line:
</p>
<pre><code>FROM ubuntu:focal</code></pre>
<p>
Ubuntu is a very popular, likely the most popular, Linux distribution. So the versioned image is built on top of Ubuntu 20.04 codenamed Focal Fossa (which is a long term support release), and our image is built on top of that. To make sense of all this, you can take a look at the table <a href="https://github.com/rocker-org/rocker-versioned2/wiki/Versions">here</a>.
</p>
<p>
So now that we’ve written this <code>Dockerfile</code>, we need to build the image. This can be done inside a terminal with the following line:
</p>
<pre><code>docker build -t my_pipeline .</code></pre>
<p>
This tells Docker to build an image called <code>my_pipeline</code> using the Dockerfile in the current directory (hence the <code>.</code>).
</p>
<p>
But, here’s what happens when we try to run the pipeline (I’ll be showing the command to run the pipeline below):
</p>
<pre><code>&gt; targets::tar_make()
Error in dyn.load(file, DLLpath = DLLpath, ...) : 
  unable to load shared object '/usr/local/lib/R/site-library/igraph/libs/igraph.so':
  libxml2.so.2: cannot open shared object file: No such file or directory
Calls: loadNamespace ... asNamespace -&gt; loadNamespace -&gt; library.dynam -&gt; dyn.load
Execution halted</code></pre>
<p>
We get a nasty error message; apparently some library, <code>libxml2.so</code> cannot be found. So we need to change our <code>Dockerfile</code>, and add the following lines:
</p>
<pre><code>FROM rocker/r-ver:4.2.1

RUN apt-get update &amp;&amp; apt-get install -y \
    libxml2-dev \
    libglpk-dev \
    libxt-dev

RUN R -e "install.packages(c('dplyr', 'purrr', 'readr', 'stringr', 'ggplot2', 'janitor', 'targets'))"

RUN mkdir /home/fig

COPY _targets.R /_targets.R

COPY functions.R /functions.R

CMD R -e "targets::tar_make()"</code></pre>
<p>
I’ve added these lines:
</p>
<pre><code>RUN apt-get update &amp;&amp; apt-get install -y \
    libxml2-dev \
    libglpk-dev \
    libxt-dev</code></pre>
<p>
this runs the <code>apt-get update</code> and <code>apt-get install</code> commands. Aptitude is Ubuntu’s package manager and is used to install software. The three pieces of software I installed will avoid further issues. <code>libxml2-dev</code> is for the error message I’ve pasted here, while the other two avoid further error messages. One last thing before we rebuild th image: we actually need to change the <code>_targets.R</code> file a bit. Let’s take a look at our <code>Dockerfile</code> again, there’s three lines I haven’t commented:
</p>
<pre><code>RUN mkdir /home/fig

COPY _targets.R /_targets.R

COPY functions.R /functions.R</code></pre>
<p>
The first line creates the <code>fig/</code> folder in the <code>home/</code> directory, and the <code>COPY</code> statements copy the files into the Docker image, so that they’re actually available inside the Docker. I also need to tell <code>_targets</code> to save the figures into the <code>home/fig</code> folder. So simply change the last three targets from this:
</p>
<pre><code>tar_target(
        luxembourg_saved_plot,
        save_plot("fig/luxembourg.png", lux_plot),
        format = "file"
    ),

    tar_target(
        canton_saved_plot,
        save_plot("fig/canton.png", canton_plot),
        format = "file"
    ),

    tar_target(
        commune_saved_plot,
        save_plot("fig/commune.png", commune_plot),
        format = "file"
    )</code></pre>
<p>
to this:
</p>
<pre><code>tar_target(
        luxembourg_saved_plot,
        save_plot("/home/fig/luxembourg.png", lux_plot),
        format = "file"
    ),

    tar_target(
        canton_saved_plot,
        save_plot("/home/fig/canton.png", canton_plot),
        format = "file"
    ),

    tar_target(
        commune_saved_plot,
        save_plot("/home/fig/commune.png", commune_plot),
        format = "file"
    )</code></pre>
<p>
Ok, so now we’re ready to rebuild the image:
</p>
<pre><code>docker build -t my_pipeline .</code></pre>
<p>
and we can now run it:
</p>
<pre><code>docker run --rm --name my_pipeline_container -v /path/to/fig:/home/fig my_pipeline</code></pre>
<p>
<code>docker run</code> runs a container based on the image you defined. <code>–rm</code> means that the container should be removed once it stops, <code>–name</code> gives it a name, here <code>my_pipeline_container</code> (this is not really needed here, because the container stops and gets removed once it’s done running), and <code>-v</code> mounts a volume, which is a fancy way of saying that the folder <code>/path/to/fig/</code>, which is a real folder on your computer, is a portal to the folder <code>/home/fig/</code> (which we created in the <code>Dockerfile</code>). This means that whatever gets saved inside <code>home/fig/</code> inside the Docker container gets also saved inside <code>/path/to/fig</code> on your computer. The last argument <code>my_pipeline</code> is simply the Docker image you built before. You should see the three plots magically appearing in <code>/path/to/fig</code> once the container is done running. The other neat thing is that you can upload this image to Docker Hub, for free (to know how to do this, check out this <a href="https://rap4mads.eu/self-contained-raps-with-docker.html#building-a-truly-reproducible-pipeline">section</a> of the course I teach on this). This way, if other people want to run it, they could do so by running the same command as above, but replacing <code>my_pipeline</code> by <code>your_username_on_docker_hub/image_name_on_docker_hub</code>. People could even create new images based on this image, by using <code>FROM your_username_on_docker_hub/image_name_on_docker_hub</code> at the beginning of their <code>Dockerfile</code>s. If you want an example of a pipeline that starts off from such an image, you can check out this <a href="https://github.com/b-rodrigues/dockerized_pipeline_demo/tree/main">repository</a>. This repository tells you how can run a reproducible pipeline by simply cloning it, building the image (which only takes a few seconds because all software is already installed in the image that I start from) and then running it.
</p>
</section>
<section id="running-this-on-github-actions" class="level2">
<h2 class="anchored" data-anchor-id="running-this-on-github-actions">
Running this on Github Actions
</h2>
<p>
Ok, so now, let’s suppose that we got an image on Docker Hub that contains all the dependencies required for our pipeline, and let’s say that we create a Github repository containing a <code>Dockerfile</code> that pulls from this image, as well as the required scripts for our pipeline. Basically, this is what I did <a href="https://github.com/b-rodrigues/dockerized_pipeline_demo/tree/main">here</a> (the same repository that I linked above already). If you take a look at the first line of the <code>Dockerfile</code> in it, you will see this:
</p>
<pre><code>FROM brodriguesco/r421_rap:version1</code></pre>
<p>
This means that the image that gets built from this <code>Dockerfile</code> starts off from <a href="https://hub.docker.com/layers/brodriguesco/r421_rap/version1/images/sha256-9b8cdaaaf14828468f6c3136c6e2916d3a6efe9c654a97a2a0d12d5d9e5b9ccc?context=repo">this image I’ve uploaded on Docker Hub</a>, this way each time the image gets rebuilt, because the dependencies are already installed, it’s going to be fast. Ok, so now what I want is the following: each time I change a file, be it the <code>Dockerfile</code>, or the <code>_targets.R</code> script, commit my changes and push them, I want Github Actions to rebuild the image, run the container, and give me the plots back.
</p>
<p>
This means that I can focus on coding, Github Actions will take care of the boring stuff.
</p>
<p>
To do this, start by creating a <code>.github/</code> directory on the root of your Github repo, and inside of it, add a <code>.workflows</code> directory, and add a file in it called something like <code>docker-build-run.yml</code>. What matters is that this file ends in <code>.yml</code>. This is what the file I use to define the actions I’ve described above looks like:
</p>
<pre><code>name: Docker Image CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:

  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - name: Build the Docker image
      run: docker build -t my-image-name .
    - name: Docker Run Action
      run: docker run --rm --name my_pipeline_container -v /github/workspace/fig/:/home/graphs/:rw my-image-name
    - uses: actions/upload-artifact@v3
      with:
        name: my-figures
        path: /github/workspace/fig/</code></pre>
<p>
The first line defines the name of the job, here <code>Docker Image CI</code>. The lines state when this should get executed: whenever there’s a push on or pull request on <code>main</code>. The job itself runs on an Ubuntu VM (so Github Actions starts an Ubuntu VM that will pull a Docker image itself running Ubuntu…). Then, there’s the <code>steps</code> statement. For now, let’s focus on the <code>run</code> statements inside <code>steps</code>, because these should be familiar:
</p>
<pre><code>run: docker build -t my-image-name .</code></pre>
<p>
and:
</p>
<pre><code>run: docker run --rm --name my_pipeline_container -v /github/workspace/fig/:/home/graphs/:rw my-image-name</code></pre>
<p>
The only new thing here, is that the path “on our machine” has been changed to <code>/github/workspace/</code>. This is the home directory of your repository, so to speak. Now there’s the <code>uses</code> keyword that’s new:
</p>
<pre><code>uses: actions/checkout@v3</code></pre>
<p>
This action checkouts your repository inside the VM, so the files in the repo are available inside the VM. Then, there’s this action here:
</p>
<pre><code>- uses: actions/upload-artifact@v3
  with:
    name: my-figures
    path: /github/workspace/fig/</code></pre>
<p>
This action takes what’s inside <code>/github/workspace/fig/</code> (which will be the output of our pipeline) and makes the contents available as so-called “artifacts”. Artifacts are the outputs of your workflow, and will be made available as <code>zip</code> files for download. In our case, as stated, the output of the pipeline. It is thus possible to rerun our workflow in the cloud. This has the advantage that we can now focus on simply changing the code, and not have to bother with useless manual steps. For example, let’s change this target in the <code>_targets.R</code> file:
</p>
<pre><code>tar_target(
    commune_data,
    clean_unemp(unemp_data,
                place_name_of_interest = c("Luxembourg", "Dippach", 
                                           "Wiltz", "Esch/Alzette", 
                                           "Mersch", "Dudelange"),
                col_of_interest = active_population)
)
</code></pre>
<p>
I’ve added “Dudelange” to the list of communes to plot. Let me push this change to the repo now, and let’s take a look at the artifacts. The video below summarises the process:
</p>
<div style="text-align:center;">
<p>
<video width="640" height="480" controls="">
<source src="../assets/img/ga_3.mp4" type="video/mp4">
</video>
</p>
</div>
<p>
As you can see in the video, the <code>_targets.R</code> script was changed, and the changes pushed to Github. This triggered the action we’ve defined before. The plots (artifacts) get refreshed, and we can download them. We see then that Dudelange was added in the <code>communes.png</code> plot!
</p>
<p>
If you enjoyed this blog post and want more of this, I wrote a whole <a href="https://rap4mads.eu/">ebook on it</a>.
</p>
<p>
</p>

</section> ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-11-19-raps.html</guid>
  <pubDate>Sat, 19 Nov 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Open source is a hard requirement for reproducibility</title>
  <link>https://b-rodrigues.github.io/posts/2022-11-16-open_source_repro.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/tux_tired_of_reproducibility_crisis.png" title="Tux is tired of the reproducibility crisis" width="80%" height="auto">
</p>
</div>
<p>
Open source is a hard requirement for reproducibility.
</p>
<p>
No ifs nor buts. And I’m not only talking about the code you typed for your research paper/report/analysis. I’m talking about the whole ecosystem that you used to type your code.
</p>
<p>
(I won’t be talking about making the data available, because I think this is another blog post on its own.)
</p>
<p>
Is your code open? That’s good. But is it code for a proprietary program, like STATA, SAS or MATLAB? Then your project is not reproducible. It doesn’t matter if this code is well documented and written and available on Github. This project is not reproducible.
</p>
<p>
Why?
</p>
<p>
Because there is on way to re-execute your code with the exact same version of this proprietary program down the line. As I’m writing these lines, MATLAB, for example, is at version R2022b. And it is very unlikely that you can buy version, say, R2008a. Maybe you can. Maybe MATLAB offers this option. But maybe they don’t. And maybe if they do today, they won’t in the future. There’s no guarantee. And if you’re running old code written for version R2008a, there’s no guarantee that it will produce the exact same results on version 2022b. And let’s not even mention the toolboxes (if you’re not familiar with MATLAB’s toolboxes, they’re the equivalent of packages or libraries in other programming languages). These evolve as well, and there’s no guarantee that you can purchase older versions of said toolboxes. And also, is a project truly reproducible (even if old programs can be purchased) if it’s behind a paywall?
</p>
<p>
And let me be clear, what I’m describing here with MATLAB could also be said for any other proprietary programs still commonly (unfortunately) used in research and in statistics (like STATA or SAS).
</p>
<p>
Then there’s another problem: let’s suppose you’ve written a nice, thoroughly tested and documented script, and made it available on Github (and let’s even assume that the data is available for people to freely download, and that the paper is open access). Let’s assume further that you’ve used R or Python, or any other open source programming language. Could this study/analysis be said to be reproducible? Well, if the analysis ran on a proprietary operating system, then the conclusion is: your project is not reproducible.
</p>
<p>
This is because the operating system the code runs on can also influence the reproducibility of the project. There are some specificities in operating systems that may make certain things work differently. Admittedly, this is in practice rarely a problem, but <a href="https://github.com/numpy/numpy/issues/9187">it does happen</a>, especially if you’re working with very high precision floating point arithmetic.
</p>
<p>
So where does that leave us? Basically, for something to be truly reproducible, it has to respect the following bullet points:
</p>
<ul>
<li>
Source code must obviously to be available and thoroughly tested and document;
</li>
<li>
To be written with an open source programming language (nocode tools are by default non-reproducible and belong in the trash);
</li>
<li>
The project needs to be run on an open source operating system.
</li>
<li>
(Data and paper need obviously to be accessible as well)
</li>
</ul>
<p>
And the whole thing would ideally be packaged using Docker or Podman. This means that someone could run an analysis in a single command, like:
</p>
<pre><code>docker run --rm --name my_analysis_container researchers_name/reproducible_project</code></pre>
<p>
Where <code>reproducible_project</code> is a Docker image, which would not only be based (very often) on the Ubuntu operating system (the most popular Linux distribution) but also contain, already installed and ready-to-use, the required programming language and the required libraries to run the project. Also, usually, the researcher would have added the required scripts and commands such that the command above, automatically, and without any further input, reruns the whole analysis. The entry cost to Docker (or similar tools) might seem high, but it is worth it, and the only way to have a truly 100% reproducible pipeline. If you’re using the R programming language for your analyses, you can use the pre-built Docker images from the amazing <a href="https://rocker-project.org/">Rocker project</a>. If you’re interested, I show how you can build a reproducible pipeline using these images <a href="https://rap4mads.eu/self-contained-raps-with-docker.html">in this chapter of my course I teach at university</a> (as of writing this blog post, this chapter is not complete yet, but it will be by Sunday evening at the latest, as I have to teach this on Monday morning at the University).
</p>
<p>
Open source programming languages and libraries can be dockerized and the Docker images can be distributed. Maybe one day we will always have a Docker image alongside a research paper.
</p>
<p>
One can dream.
</p>



 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-11-16-open_source_repro.html</guid>
  <pubDate>Wed, 16 Nov 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How to deal with annoying medium sized data inside a Shiny app</title>
  <link>https://b-rodrigues.github.io/posts/2022-10-31-optim_shiny.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<video width="640" height="480" controls="">
<source src="../assets/img/deja_vu.mp4" type="video/mp4">
</video>
</p>
</div>
<p>
<em>This blog post is taken from a chapter of my ebook on building reproducible analytical pipelines, which you can read <a href="https://rap4mads.eu">here</a></em>
</p>
<p>
If you want to follow along, you can start by downloading the data I use <a href="https://mega.nz/file/l1IxHYIT#mZkeQOVpMc9XymMNtDY687sHEZHoIvDcUOm-4AwK6OI">here</a>. This is a smaller dataset made from the one you can get <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HG7NV7">here</a>.
</p>
<p>
Uncompressed it’ll be a 2.4GB file. Not big data in any sense, but big enough to be annoying to handle without the use of some optimization strategies (I’ve seen such data described as medium sized data before.).
</p>
<p>
One such strategy is only letting the computations run once the user gives the green light by clicking on an action button. The next obvious strategy is to use packages that are optimized for speed. It turns out that the functions we have seen until now (note from the author: <em>the functions we have seen until now</em> if you’re on of my students that’s sitting in the course where I teach this), from packages like <code>{dplyr}</code> and the like, are not the fastest. Their ease of use and expressiveness come at a speed cost. So we will need to switch to something faster. We will do the same to read in the data.
</p>
<p>
This faster solution is the <code>{arrow}</code> package, which is an interface to the <a href="https://arrow.apache.org/faq/">Arrow software developed by Apache</a>.
</p>
<p>
The final strategy is to enable caching in the app.
</p>
<p>
So first, install the <code>{arrow}</code> package by running <code>install.packages(“arrow”)</code>. This will compile <code>libarrow</code> from source on Linux and might take some time, so perhaps go grab a coffee. On other operating systems, I guess that a binary version gets installed.
</p>
<p>
Before building the app, let me perform a very simple benchmark. The script below reads in the data, then performs some aggregations. This is done using standard <code>{tidyverse}</code> functions, but also using <code>{arrow}</code>:
</p>
<pre class="r"><code>start_tidy &lt;- Sys.time()
  # {vroom} is able to read in larger files than {readr}
  # I could not get this file into R using readr::read_csv
  # my RAM would get maxed out
  air &lt;- vroom::vroom("data/combined")

  mean_dep_delay &lt;- air |&gt;
    dplyr::group_by(Year, Month, DayofMonth) |&gt;
    dplyr::summarise(mean_delay = mean(DepDelay, na.rm = TRUE))
end_tidy &lt;- Sys.time()

time_tidy &lt;- end_tidy - start_tidy


start_arrow &lt;- Sys.time()
  air &lt;- arrow::open_dataset("data/combined", format = "csv")

  mean_dep_delay &lt;- air |&gt;
    dplyr::group_by(Year, Month, DayofMonth) |&gt;
    dplyr::summarise(mean_delay = mean(DepDelay, na.rm = TRUE))
end_arrow &lt;- Sys.time()

end_tidy - start_tidy
end_arrow - start_arrow</code></pre>
<p>
The “tidy” approach took 17 seconds, while the arrow approach took 6 seconds. This is an impressive improvement, but put yourself in the shoes of a user who has to wait 6 seconds for each query. That would get very annoying, very quickly. So the other strategy that we will use is to provide some visual cue that computations are running, and then we will go one step further and use caching of results in the Shiny app.
</p>
<p>
But before we continue, you may be confused by the code above. After all, I told you before that functions from <code>{dplyr}</code> and the like were not the fastest, and yet, I am using them in the arrow approach as well, and they now run almost 3 times as fast. What’s going on? What’s happening here, is that the <code>air</code> object that we read using <code>arrow::open_dataset</code> is not a dataframe, but an <code>arrow</code> dataset. These are special, and work in a different way. But that’s not what’s important: what’s important is that the <code>{dplyr}</code> api can be used to work with these <code>arrow</code> datasets. This means that functions from <code>{dplyr}</code> change the way they work depending on the type of the object their dealing with. If it’s a good old regular data frame, some C++ code gets called to perform the computations. If it’s an <code>arrow</code> dataset, <code>libarrow</code> and its black magic get called instead to perform the computations. If you’re familiar with the concept of <a href="https://en.wikipedia.org/wiki/Polymorphism_(computer_science)">polymorphism</a> this is it (think of <code>+</code> in Python: <code>1+1</code> returns <code>2</code>, <code>“a”+“b”</code> returns <code>“a+b”</code>. A different computation gets performed depending on the type of the function’s inputs).
</p>
<p>
Let’s now build a basic version of the app, only using <code>{arrow}</code> functions for speed. This is the global file:
</p>
<pre class="r"><code>library(arrow)
library(dplyr)
library(rlang)
library(DT)

air &lt;- arrow::open_dataset("data/combined", format = "csv")</code></pre>
<p>
The ui will be quite simple:
</p>
<pre class="r"><code>ui &lt;- function(request){
  fluidPage(

    titlePanel("Air On Time data"),

    sidebarLayout(

      sidebarPanel(
        selectizeInput("group_by_selected", "Variables to group by:",
                       choices = c("Year", "Month", "DayofMonth", "Origin", "Dest"),
                       multiple = TRUE,
                       selected = c("Year", "Month"),
                       options = list(
                         plugins = list("remove_button"),
                         create = TRUE,
                         persist = FALSE # keep created choices in dropdown
                       )
                       ),
        hr(),
        selectizeInput("var_to_average", "Select variable to average by groups:",
                       choices = c("ArrDelay", "DepDelay", "Distance"),
                       multiple = FALSE,
                       selected = "DepDelay",
                       ),
        hr(),
        actionButton(inputId = "run_aggregation",
                     label = "Click here to run aggregation"),
        hr(),
        bookmarkButton()
      ),

      mainPanel(
        DTOutput("result")
      )
    )
  )

}</code></pre>
<p>
And finally the server:
</p>
<pre class="r"><code>server &lt;- function(session, input, output) {

  # Numbers get crunched only when the user clicks on the action button
  grouped_data &lt;- eventReactive(input$run_aggregation, {
    air %&gt;%
      group_by(!!!syms(input$group_by_selected)) %&gt;%
      summarise(result = mean(!!sym(input$var_to_average),
                              na.rm = TRUE)) %&gt;%
      as.data.frame()
  })

  output$result &lt;- renderDT({
    grouped_data()
  })

}</code></pre>
<p>
Because <code>group_by()</code> and <code>mean()</code> expect bare variable names, I convert them from strings to symbols using <code>rlang::syms()</code> and <code>rlang::sym()</code>. The difference between the two is that <code>rlang::syms()</code> is required when a list of strings gets passed down to the function (remember that the user must select several variables to group by), and this is also why <code>!!!</code> are needed (to unquote the list of symbols). Finally, the computed data must be converted back to a data frame using <code>as.data.frame()</code>. This is actually when the computations happen. <code>{arrow}</code> collects all the aggregations but does not perform anything until absolutely required. Let’s see the app in action:
</p>
<div style="text-align:center;">
<video width="640" height="480" controls="">
<source src="../assets/img/shiny_3.mp4" type="video/mp4">
</video>
</div>
<p>
As you can see, in terms of User Experience (UX) this is quite poor. When the user clicks on the button nothing seems to be going on for several seconds, until the table appears. Then, when the user changes some options and clicks again on the action button, it looks like the app is crashing.
</p>
<p>
Let’s add some visual cues to indicate to the user that something is happening when the button gets clicked. For this, we are going to use the <code>{shinycssloaders}</code> package:
</p>
<pre class="r"><code>install.packages("shinycssloaders")</code></pre>
<p>
and simply change the ui to this (and don’t forget to load <code>{shinycssloaders}</code> in the global script!):
</p>
<pre class="r"><code>ui &lt;- function(request){
  fluidPage(

    titlePanel("Air On Time data"),

    sidebarLayout(

      sidebarPanel(
        selectizeInput("group_by_selected", "Variables to group by:",
                       choices = c("Year", "Month", "DayofMonth", "Origin", "Dest"),
                       multiple = TRUE,
                       selected = c("Year", "Month"),
                       options = list(
                         plugins = list("remove_button"),
                         create = TRUE,
                         persist = FALSE # keep created choices in dropdown
                       )
                       ),
        hr(),
        selectizeInput("var_to_average", "Select variable to average by groups:",
                       choices = c("ArrDelay", "DepDelay", "Distance"),
                       multiple = FALSE,
                       selected = "DepDelay",
                       ),
        hr(),
        actionButton(inputId = "run_aggregation",
                     label = "Click here to run aggregation"),
        hr(),
        bookmarkButton()
      ),

      mainPanel(
        # We add a tabsetPanel with two tabs. The first tab show the plot made using ggplot
        # the second tab shows the plot using g2r
        DTOutput("result") |&gt;
          withSpinner()
      )
    )
  )

}</code></pre>
<p>
The only difference with before is that now the <code>DTOutput()</code> right at the end gets passed down to <code>withSpinner()</code>. There are several spinners that you can choose, but let’s simply use the default one. This is how the app looks now:
</p>
<div style="text-align:center;">
<video width="640" height="480" controls="">
<source src="../assets/img/shiny_4.mp4" type="video/mp4">
</video>
</div>
<p>
Now the user gets a visual cue that something is happening. This makes waiting more bearable, but even better than waiting with a spinner is no waiting at all. For this, we are going to enable caching of results. There are several ways that you can cache results inside your app. You can enable the cache on a per-user and per-session basis, or only on a per-user basis. But I think that in our case here, the ideal caching strategy is to keep the cache persistent, and available across sessions. This means that each computation done by any user will get cached and available to any other user. In order to achieve this, you simply have to install the <code>{cachem}</code> packages add the following lines to the global script:
</p>
<pre class="r"><code>shinyOptions(cache = cachem::cache_disk("./app-cache",
                                        max_age = Inf))</code></pre>
<p>
By setting the <code>max_age</code> argument to <code>Inf</code>, the cache will never get pruned. The maximum size of the cache, by default is 1GB. You can of course increase it.
</p>
<p>
Now, you must also edit the server file like so:
</p>
<pre class="r"><code>server &lt;- function(session, input, output) {

  # Numbers get crunched only when the user clicks on the action button
  grouped_data &lt;- reactive({
    air %&gt;%
      group_by(!!!syms(input$group_by_selected)) %&gt;%
      summarise(result = mean(!!sym(input$var_to_average),
                              na.rm = TRUE)) %&gt;%
      as.data.frame()
  }) %&gt;%
    bindCache(input$group_by_selected,
              input$var_to_average) %&gt;%
    bindEvent(input$run_aggregation)

  output$result &lt;- renderDT({
    grouped_data()
  })

}</code></pre>
<p>
We’ve had to change <code>eventReactive()</code> to <code>reactive()</code>, just like in the app where we don’t use an action button to run computations (note of the author: in the ebook, there is an example of an app with this action button. This is what I’m referring to here). Then, we pass the reactive object to <code>bindCache()</code>. <code>bindCache()</code> also takes the <code>inputs</code> as arguments. These are used to generate cache keys to retrieve the correct objects from cache. Finally, we pass all this to <code>bindEvent()</code>. This function takes the input referencing the action button. This is how we can now bind the computations to the button once again. Let’s test our app now. You will notice that the first time we choose certain options, the computations will take time, as before. But if we perform the same computations again, then the results will be shown instantly:
</p>
<div style="text-align:center;">
<video width="640" height="480" controls="">
<source src="../assets/img/shiny_5.mp4" type="video/mp4">
</video>
</div>
<p>
As you can see, once I go back to a computation that was done in the past, the table appears instantly. At the end of the video I open a terminal and navigate to the directory of the app, and show you the cache. There are several <code>.Rds</code> objects, these are the final data frames that get computed by the app. If the user wants to rerun a previous computation, the correct data frame gets retrieved, making it look like the computation happened instantly, and with another added benefit: as discussed above, the cache is persistent between sessions, so even if the user closes the browser and comes back later, the cache is still there, and other users will also benefit from the cache.
</p>


 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-10-31-optim_shiny.html</guid>
  <pubDate>Mon, 31 Oct 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>A Linux Live USB as a statistical programming dev environment</title>
  <link>https://b-rodrigues.github.io/posts/2022-10-29-mkusb_minp.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<video width="640" height="480" controls="">
<source src="../assets/img/tux_usb_ubuntu_startup.mp4" type="video/mp4">
</video>
</p>
</div>
<p>
This blog post is divided in two parts: in the first part I’ll show you how to create a Linux Live USB with persistent storage that can be used as development environment, and in the second part I’ll show you the easiest way to set up RStudio and R in Ubuntu.
</p>
<section id="making-your-own-portable-development-environment-based-on-ubuntu-or-debian" class="level2">
<h2 class="anchored" data-anchor-id="making-your-own-portable-development-environment-based-on-ubuntu-or-debian">
Making your own, portable, development environment based on Ubuntu or Debian
</h2>
<p>
I’m currently teaching a course at the University of Luxembourg, which focuses on setting up reproducible analytical pipelines (if you’re interested, you can find the course notes <a href="https://rap4mads.eu/">here</a>).
</p>
<p>
The problem is that my work laptop runs Windows, and I didn’t want to teach on Windows since I make heavy use of the command line. Plus I don’t have admin rights on this machine, so installing what I needed would have been a pain. I also don’t have a personal laptop, so I use my wife’s laptop. However, the laptop is completely full of pictures of our kids, so I couldn’t install what I needed… This is when I thought about making a persistent live USB with Kubuntu on it (Kubuntu is a variant of Ubuntu with KDE as the desktop manager instead of Gnome) with all the software I needed (R, Quarto, RStudio basically). It works quite well, and was also quite easy to do. But what is a live USB anyways? A live USB is a full Linux installation on a USB stick, that you can use to test different Linux distributions or even to install said distribution on computers.
</p>
<p>
The first step is to get a USB stick. Those are quite cheap nowadays, but you’ll need at least one with 8GB of space, and ideally USB 3 (you probably can’t find any USB 2 these days anyways). I’ve bought a 32GB one for 10€.
</p>
<p>
Then, we need to install Ubuntu on it. I’ll be using Kubuntu 22.04, which is an LTS release. I would always recommend an LTS release for something like crafting a development environment. So if you’re reading this in the future, and there’s a new LTS (could be 24.04, 26.04, etc), you’d need to get that one.
</p>
<p>
Creating a live USB is quite simple, but the issue if you create a live USB using the standard methods is that whatever you do on it once you’re logged in will get erased after rebooting. A persistent live USB, I’m sure you’ve guessed it, keeps your changes even after rebooting, which means that you basically end up with a portable development environment. Note however that only Ubuntu (and variants) or Debian can be used to create persistent live USBs.
</p>
<p>
You can create persistent live USB from another Linux distro, Windows or macOS.
</p>
<p>
If you’re already running Ubuntu on your pc, you might want to take a look at <a href="https://help.ubuntu.com/community/mkusb#Persistent_live_systems">this page</a>. You’ll need to install a tool called <code>mkusb</code>. If you’re not running Ubuntu, but find this tool in your distribution’s package manager, I guess you’re good to go as well. In my case, I’m running opensuse tumbleweed, and could not find this program in the opensuse’s repositories. So I’ve used this <a href="https://help.ubuntu.com/community/mkusb/minp">guide</a> that shows how to achieve the same thing using a very simple to use shell script which you can get <a href="https://help.ubuntu.com/community/mkusb/minp?action=AttachFile&amp;do=view&amp;target=mkusb-minp">here</a> called <code>mkusb-minp</code>. So in my case, I simply had to stick the USB stick in my computer, find out where it was mounted by running <code>df</code> in bash (in my case it was in <code>/dev/sdd</code>), download Kubuntu’s iso image and run the following in my terminal:
</p>
<pre><code>sudo ./mkusb-minp -p kubuntu-22.04.1-desktop-amd64.iso /dev/sdX</code></pre>
<p>
(<code>/dev/sdX</code>: replace the X by the right letter, for me it was <code>/dev/sdd</code>)
</p>
<p>
If you’re using Windows, you can install <a href="https://rufus.ie/en/#">Rufus</a> to create a persistent live USB.
</p>
<p>
It would seem that for macOS the process is a bit more involved, but I’ve found this <a href="https://sebay.github.io/posts/create-live-persistent-ubuntu-usb-on-mac/">blog post</a> that explains the process.
</p>
<p>
Once the process is finished, you can boot into your live USB key. For this, you might need to press <code>delete</code> or <code>F2</code> when your computer starts booting to access the <a href="https://www.computerhope.com/jargon/b/boot_menu.htm">boot menu</a>. You can then choose to boot from your USB device.
</p>
<p>
Wait a bit and at some point you should see a prompt asking you if you want to try or install Ubuntu. Choose <code>Try Ubuntu</code>:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/try_ubuntu.png" width="80%" height="auto">
</p>
</div>
<p>
And then wait some minutes. Yes booting takes some time because you’re loading an entire operating system from a USB stick (hence why it’s a good idea to go with a USB 3 stick). After some time you should see a new window:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/try_ubuntu2.png" width="80%" height="auto">
</p>
</div>
<p>
Once again, try Ubuntu, wait a bit, and that’s it you’re inside your dev environment!
</p>
</section>
<section id="setting-up-r-and-rstudio" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-r-and-rstudio">
Setting up R and RStudio
</h2>
<p>
Now that you’re inside your dev environment, you actually need to start adding some tools. Let’s start by adding R. The easiest way that I found is to use the <a href="https://eddelbuettel.github.io/r2u/">r2u project</a> by <a href="https://github.com/eddelbuettel">Dirk Eddelbuettel</a>. If you’re on Ubuntu 22.04, run <a href="https://github.com/eddelbuettel/r2u/blob/master/inst/scripts/add_cranapt_jammy.sh">this script</a>, as explained in the tutorial. This will add the required repositories that will install binary versions of R packages in mere seconds. The script will also add a repository to install the most recent version of R, so once the script is done running, install R and the <code>{tidyverse}</code> (or any other package) with the following command:
</p>
<pre><code>sudo apt install --no-install-recommends r-base r-cran-tidyverse</code></pre>
<p>
You can then install other packages from R using <code>install.packages(“package_name”)</code> as usual, and this will also make use of the <code>r2u</code> repositories.
</p>
<p>
All that’s missing now is RStudio (if you use RStudio). Surprisingly, when I set up my live USB two weeks ago, the current version of RStudio for Ubuntu would not install. This is apparently fixed with the daily versions which you can get <a href="https://dailies.rstudio.com/">here</a>. But before that, do try to install the stable version. If you’re reading this sometime in the future, maybe the issue I encountered has been fixed. Download RStudio from <a href="https://www.rstudio.com/products/rstudio/download/#download">here</a>, and then double click on the downloaded <code>.deb</code> package. If you see this message:
</p>
<pre><code>The following packages have unmet dependencies:
 rstudio : Depends: libssl1.0.0 but it is not installable or
                    libssl1.0.2 but it is not installable or
                    libssl1.1 but it is not installable
           Recommends: r-base (&gt;= 3.0.1) but it is not going to be installed
E: Unable to correct problems, you have held broken packages.</code></pre>
<p>
then this means that the problem has not been fixed. In that case, run the following line to repair everything:
</p>
<pre><code>sudo apt-get update --fix-missing</code></pre>
<p>
This should put you back into a clean state. So to continue, install a daily build from the link above. Simply click on the Ubuntu 22 button to download the daily. Unfortunately daily builds can be unstable and are usually used for testing purposes. So hopefully Posit will fix this soon.
</p>
<p>
Of course, if you’re using the <a href="../posts/2019-05-19-spacemacs.html">greatest IDE ever made</a> instead of RStudio, you won’t have this issue.
</p>
<p>
You can now keep installing things, for example <a href="https://quarto.org/docs/get-started/">Quarto</a>, or Python, or, or, or… there are no limits, and performance, as you would have noticed is great, because the operating system has access to all the resources from your machine. A persistent live USB is a great solution if you need a portable dev environment and don’t want/can’t use Docker for example.
</p>


</section>
 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-10-29-mkusb_minp.html</guid>
  <pubDate>Sat, 29 Oct 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>R, its license and my take on it</title>
  <link>https://b-rodrigues.github.io/posts/2022-10-23-licenses.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/free_software.png" width="100%">
</p>
</div>
<p>
Foreword: This is not a tutorial nor anything like that. I’m going to talk about free software, open source, and their licenses. I’m going to give my (non-)expert opinion on it. You may find, after having finished reading this post, that I wasted your time. So only read if by some miracle the first sentence of the foreword excited you. If not, close this tab and go back now. It’s not too late.
</p>
<p>
Foreword 2: I’ve updated the post on October 24th with an additional meme, clarifications and a link to an interesting stackexchange discussion.
</p>
<section id="free-software-aint-free" class="level2">
<h2 class="anchored" data-anchor-id="free-software-aint-free">
Free software ain’t free
</h2>
<p>
Let me first re-iterate that free software and open source are not the same thing. Free software is open source, but not every piece of open source software is free. Open source means that the source code of a piece of software is available and can be consulted without much hurdles. It also means, usually, that you can take these pieces of software, modify them, and redistribute them without much hurdles either.
</p>
<p>
Free software is like open source software, but it’s much more restrictive. That may seem surprising, because there’s the word <em>free</em> in there, so how could it be more restrictive than open source software? Consider the following: I can take a piece of open source software (typically licensed under something like the <a href="https://en.wikipedia.org/wiki/MIT_License">MIT licenses</a> or the <a href="https://en.wikipedia.org/wiki/BSD_licenses">BSD licenses</a>) and re-release it with a proprietary license and sell it. I don’t actually even need to change anything substantial to the source code. I take that piece of software (which I may or may not modify), repackage it under a new name and sell it. Free software allows all of this as well (I literally could sell the Linux kernel on this website if I found people willing to pay me for it), but what it does not allow is only this: I cannot distribute (by selling or for free) the program without its source code. So if I sold the Linux kernel on here, I would need to also give out a copy of the source code with it, and this obviously would also still be necessary if I actually changed something to the source code of the Linux kernel.
</p>
<p>
R is licensed under a Free Software license, the <a href="https://en.wikipedia.org/wiki/GNU_General_Public_License#Version_2">GPL v2</a>, which means that it’s illegal for anyone to rebrand it, package it and sell it without providing the source code of their (modified) version of R. Thanks to something like the GPL, it is impossible for companies to employ what is called <a href="https://en.wikipedia.org/wiki/Embrace,_extend,_and_extinguish">Embrace, Extend and Extinguish</a>, which is a strategy that Microsoft used in the past. It consists in embracing a piece of software, extending it with proprietary bits of code and technology, use their dominant position on the desktop to impose their new version that relies on proprietary bits (or which is 100% proprietary) and then <em>extinguish</em> the open source version (in the sense that no one will use it anymore because it virtually became incompatible with the newly imposed Microsoft version).
</p>
<p>
Now some of you may now be thinking that I’m stuck in the 90’s, after all, Microsoft have been the good guys for a decade now. They contribute to open source software (not free software), have bought Github and have not ruined it (yet) and they even included the possibility to run Linux inside Windows using WSL. So what am I afraid of? Why don’t I trust them?
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/multimillion.jpg" width="100%">
</p>
</div>
</section>
<section id="all-licenses-have-their-place-but" class="level2">
<h2 class="anchored" data-anchor-id="all-licenses-have-their-place-but">
All licenses have their place, but…
</h2>
<p>
The thing is, I shouldn’t have to trust anyone not to fuck up a piece of free software. Maybe the current management of Microsoft is not hostile to free software, but maybe that’ll change in the future. That’s not really the point. The point is that I don’t need to have to trust them, and I’m happy that a <em>fundamental, crucial</em> piece of software like R uses something like the GPL. But that doesn’t mean that everything should be licensed under the GPL. For example, as far as I know, every package of the <code>{tidyverse}</code> uses an MIT license. So just because R is licensed under the GPL doesn’t mean that its packages all have to be GPL. But I must also admit that while I see why a company like Posit releases their packages under a permissive license, I don’t see why an independent developer would do that. I absolutely do not see what independent developers gain from releasing the code of their packages under anything else than the GPL. (As an aside, go read <a href="https://www.cs.vu.nl/~ast/intel/">this</a>… code under a permissive license taken from an independent developer? check. Nothing was given back to the community? check. The code in question was used for nefarious purposes? check. Original developer on massive amounts of copium? check). But, to be fair, I have a grand total of two (2) packages on CRAN that likely get less than 10 downloads a year, so what do I know. One of the arguments I’ve heard is that the GPL is not really free, because it restricts users from taking the code and releasing it under a proprietary license, so <em>akshually</em> the MIT/BSD licenses are really the free ones, and if I like freedom so much I should be using FreeBSD instead of a Linux distro and release my packages under a MIT/BSD license. I want to ask people that make this argument if they would allow the Nazi party to make a come back in their countries legislature, then.
</p>
<p>
That being said, I do release stuff with permissive licenses. For example the content of this blog or for the courses I teach are under the <a href="http://www.wtfpl.net/txt/copying/">WTFPL</a>, which is, I would say, the only acceptable permissive license for independent developers. If the name of the license was not explicit enough, the comic below illustrates what the WPTFL is all about:
</p>
<div style="text-align:center;">
<p><img src="https://b-rodrigues.github.io/assets/img/wtfpl-strip.jpg" width="100%"></p>
</div>
</section>
<section id="can-r-be-used-to-write-proprietary-code" class="level2">
<h2 class="anchored" data-anchor-id="can-r-be-used-to-write-proprietary-code">
Can R be used to write proprietary code
</h2>
<p>
Yes, you can write proprietary code using R. Microsoft has done so, for example their <code>{RevoUtilsMath}</code> package is, as far as I know, proprietary, and I’m sure that it includes some R code. I’m pretty sure it would also be possible to even build a proprietary program that would require the R interpreter to be bundled to run. As long as the developers of this tool would:
</p>
<ul>
<li>
Release their modified version of R with it (if they modified it);
</li>
<li>
Tell their users that their program runs with R, and thus also distribute R and its license;
</li>
</ul>
<p>
R could likely be downloaded at install time in cases like this, again, as long as the users get notified that it’s needed. I doubt that the rest of the program would need to be licensed under the GPL, since no code of R itself has been modified.
</p>
<p>
But I’m not that certain on this last point, so any comments welcome (on <a href="https://github.com/rbind/b-rodrigues.github.com/issues/4">here</a>).
</p>
<p>
EDIT: There’s this interesting discussion on stackexchange <a href="https://opensource.stackexchange.com/questions/7078/is-it-legal-to-use-gpl-code-in-a-proprietary-closed-source-program-by-putting-i">here</a> and it would seem that the answer is not clearcut, but, it depends. Hence why companies prefer working using permissive licenses, to avoid these types of discussions.
</p>
<p>
That’s it, that’s the blog post. Thank GNU for the GPL.
</p>
<p>
</p>

</section>

 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-10-23-licenses.html</guid>
  <pubDate>Sun, 23 Oct 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Why and how to use JS in your Shiny app</title>
  <link>https://b-rodrigues.github.io/posts/2022-10-01-why_js_shiny.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/pointing_tags_script.png" title="The gist of this blog post" width="80%" height="auto">
</p>
</div>
<section id="the-snake-biting-its-own-tail" class="level2">
<h2 class="anchored" data-anchor-id="the-snake-biting-its-own-tail">
The snake biting its own tail
</h2>
<p>
<em>Disclaimer: I’m a beginner at JS, so don’t ask me about the many intricacies of JS.</em>
</p>
<p>
I’ve been working on a Shiny app for work these past few weeks, and had to use Javascript to solve a very specific issue I encountered. Something for which, as far as I know, there is no other solution than using Javascript. The problem had to do with dynamically changing the UI of an app. The way to usually achieve this is using <code>renderUI()/uiOutput()</code>. For example, consider the following little app (if you don’t want to run it, watch the video below):
</p>
<pre class="r"><code>library(shiny)
library(ggplot2)

data(mtcars)

ui &lt;- fluidPage(
  selectInput("var", "Select variable:", choices = colnames(mtcars)),
  uiOutput("welcome"),
  plotOutput("my_plot")
)

server &lt;- function(input, output) {

  output$welcome &lt;- renderUI({
      tags$div(paste0("Welcome to my award-winning app! Currently showing variable: ", input$var))
  })

  output$my_plot &lt;- renderPlot({
        ggplot(data = mtcars) +
          geom_bar(aes_string(y = input$var))
      })
}

shinyApp(ui, server)</code></pre>
<div style="text-align:center;">
<video width="320" height="240" controls="">
<source src="../assets/img/why_js_shiny_1.mp4" type="video/mp4">
</video>
</div>
<p>
As you can see, when the user chooses a new variable, the plot gets updated of course, but the welcome message changes as well. Normally, the UI of a Shiny app gets rendered once, at startup, and stays fixed. But thanks to <code>renderUI()/uiOutput()</code>, it is possible to change UI elements on the fly, and anything can go inside of <code>renderUI()/uiOutput()</code>, it can be something much more complex than a simple message like in my example above.
</p>
<p>
So, why did I need to use Javascript to basically achieve the same thing? The reason is that I am currently using <a href="https://rinterface.github.io/bs4Dash/index.html"><code>{bs4Dash}</code></a>, an amazing package to build Shiny dashboard using Bootstrap 4. <code>{bs4Dash}</code> comes with many neat features, one of them being improved <code>box()</code>es (improved when compared to the <code>box()</code>es from <code>{shinydashboard}</code>). These improved boxes allow you to do something like this (if you don’t want to run it, watch the video below):
</p>
<pre class="r"><code>library(shiny)
library(ggplot2)
library(bs4Dash)

data(mtcars)

shinyApp(
  ui = dashboardPage(
    header = dashboardHeader(
      title = dashboardBrand(
        title = "Welcome to my award-winning dashboard!",
        color = "primary"
      )
    ),
    sidebar = dashboardSidebar(),
    body = dashboardBody(
      box(
        plotOutput("my_plot"),
        title = "This is where I will put the title, but bear with me.",
        width = 12,
        sidebar = boxSidebar(
          id = "sidebarid",
          startOpen = TRUE,
          selectInput("var", "Select variable:", choices = colnames(mtcars))
          ))
    ),
    controlbar = dashboardControlbar(),
    title = "DashboardPage"
  ),
  server = function(input, output, session) {

    output$my_plot &lt;- renderPlot({
      ggplot(data = mtcars) +
        geom_bar(aes_string(y = input$var))
    })

  }
)</code></pre>
<div style="text-align:center;">
<video width="320" height="240" controls="">
<source src="../assets/img/why_js_shiny_2.mp4" type="video/mp4">
</video>
</div>
<p>
Each box can have a side bar, and these side bars can contain toggles specific to the graph. If you click outside the side bar, the side bar closes; to show the side bar, click on the little gears in the top right corner of the side bar. Ok we’re almost done with the setup: see how the box can have a title? Let’s make it change like before; for this, because the title is part of the <code>box()</code> function, I need to re-render the whole box (if you don’t want to run it, watch the video below):
</p>
<pre class="r"><code>library(shiny)
library(ggplot2)
library(bs4Dash)

data(mtcars)

shinyApp(
  ui = dashboardPage(
    header = dashboardHeader(
      title = dashboardBrand(
        title = "Welcome to my award-winning dashboard!",
        color = "primary"
      )
    ),
    sidebar = dashboardSidebar(),
    body = dashboardBody(
      uiOutput("my_dynamic_box")
    ),
    controlbar = dashboardControlbar(),
    title = "DashboardPage"
  ),
  server = function(input, output, session) {

    output$my_plot &lt;- renderPlot({
      ggplot(data = mtcars) +
        geom_bar(aes_string(y = input$var))
    })

    output$my_dynamic_box &lt;- renderUI({
      box(
        plotOutput("my_plot"),
        title = paste0("Currently showing variable:", input$var),
        width = 12,
        sidebar = boxSidebar(
          id = "sidebarid",
          startOpen = TRUE,
          selectInput("var", "Select variable:", choices = colnames(mtcars))
        ))
    })
  }
)</code></pre>
<div style="text-align:center;">
<video width="320" height="240" controls="">
<source src="../assets/img/why_js_shiny_3.mp4" type="video/mp4">
</video>
</div>
<p>
Now try changing variables and see what happens… as soon as you change the value in the <code>selectInput()</code>, it goes back to selecting <code>mpg</code>! The reason is because the whole box gets re-rendered, including the <code>selectInput()</code>, and its starting, default, value (even if we did not specify one, this value is simply the first element of <code>colnames(mtcars)</code> which happens to be <code>mpg</code>). So now you see the problem; I have to re-render part of the UI, but doing so puts the <code>selectInput()</code> on its default value… so I need to be able to only to re-render the title, not the whole box (or move the <code>selectInput()</code> outside the boxes, but that was not an acceptable solution in my case).
</p>
<p>
So there we have it, we’re done with the problem statement. Now on to the solution.
</p>
<section id="update" class="level3">
<h3 class="anchored" data-anchor-id="update">
<strong>UPDATE</strong>
</h3>
<p>
It turns out that it’s not needed to use JS for this special use case! <code>{bs4Dash}</code> comes with a function, called <code>updateBox()</code> which updates a targeted box. You can read about it <a href="https://rinterface.github.io/bs4Dash/reference/box.html">here</a>. Thanks to <code>{bs4Dash}</code>’s author, <a href="https://twitter.com/divadnojnarg/status/1576210017497550849?s=20&amp;t=wz3NfqHB4SWtcVAUH_KPRA">David Granjon</a> for the heads-up!
</p>
<p>
Well, even though my specific use case does not actually need Javascript, you can continue reading, because in case your use case does not have an happy ending like mine, the blog post is still relevant!
</p>
</section>
</section> ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-10-01-why_js_shiny.html</guid>
  <pubDate>Sat, 01 Oct 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>What’s the fastest way to search and replace strings in a data frame?</title>
  <link>https://b-rodrigues.github.io/posts/2022-07-23-grepl_vs_stringi.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://www.craiyon.com/"> <img src="https://b-rodrigues.github.io/assets/img/wojak_violin.jpg" title="Made by DALL-E mini" width="80%" height="auto"></a>
</p>
</div>
<p>
I’ve tweeted this:
</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Just changed like 100 grepl calls to stringi::stri_detect and my pipeline now runs 4 times faster <a href="https://twitter.com/hashtag/RStats?src=hash&amp;ref_src=twsrc%5Etfw">#RStats</a>
</p>
— Bruno Rodrigues (<span class="citation"><span class="citation" data-cites="brodriguesco">@brodriguesco</span></span>) <a href="https://twitter.com/brodriguesco/status/1549659454483857409?ref_src=twsrc%5Etfw">July 20, 2022</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>
much discussed ensued. Some people were surprised, because in their experience, <code>grepl()</code> was faster than alternatives, especially if you set the <code>perl</code> parameter in <code>grepl()</code> to <code>TRUE</code>. My use case was quite simple; I have a relatively large data set (half a million lines) with one column with several misspelling of city names. So I painstakingly wrote some code to correct the spelling of the major cities (those that came up often enough to matter. Minor cities were set to “Other”. Sorry, <a href="https://en.wikipedia.org/wiki/Wiltz">Wiltz</a>!)
</p>
<p>
So in this short blog post, I benchmark some code to see if what I did the other day was a fluke. Maybe something weird with my R installation on my work laptop running Windows 10 somehow made <code>stri_detect()</code> run faster than <code>grepl()</code>? I don’t even know if something like that is possible. I’m writing these lines on my Linux machine, unlike the code I run at work. So maybe if I find some differences, they could be due to the different OS running. I don’t want to have to deal with Windows on my days off (for my blood pressure’s sake), so I’m not running this benchmark on my work laptop. So that part we’ll never know.
</p>
<p>
Anyways, let’s start by getting some data. I’m not commenting the code below, because that’s not the point of this post.
</p>
<pre class="r"><code>library(dplyr)
library(stringi)
library(stringr)
library(re2)

adult &lt;- vroom::vroom(
  "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
)

adult_colnames &lt;- readLines(
  "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names"
)

adult_colnames &lt;- adult_colnames[97:110] %&gt;%
  str_extract(".*(?=:)") %&gt;%
  str_replace_all("-", "_")

adult_colnames &lt;- c(adult_colnames, "wage")

colnames(adult) &lt;- adult_colnames

adult</code></pre>
<pre><code>## # A tibble: 32,560 × 15
##      age workclass    fnlwgt educa…¹ educa…² marit…³ occup…⁴ relat…⁵ race  sex  
##    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;
##  1    50 Self-emp-no…  83311 Bachel…      13 Marrie… Exec-m… Husband White Male 
##  2    38 Private      215646 HS-grad       9 Divorc… Handle… Not-in… White Male 
##  3    53 Private      234721 11th          7 Marrie… Handle… Husband Black Male 
##  4    28 Private      338409 Bachel…      13 Marrie… Prof-s… Wife    Black Fema…
##  5    37 Private      284582 Masters      14 Marrie… Exec-m… Wife    White Fema…
##  6    49 Private      160187 9th           5 Marrie… Other-… Not-in… Black Fema…
##  7    52 Self-emp-no… 209642 HS-grad       9 Marrie… Exec-m… Husband White Male 
##  8    31 Private       45781 Masters      14 Never-… Prof-s… Not-in… White Fema…
##  9    42 Private      159449 Bachel…      13 Marrie… Exec-m… Husband White Male 
## 10    37 Private      280464 Some-c…      10 Marrie… Exec-m… Husband Black Male 
## # … with 32,550 more rows, 5 more variables: capital_gain &lt;dbl&gt;,
## #   capital_loss &lt;dbl&gt;, hours_per_week &lt;dbl&gt;, native_country &lt;chr&gt;, wage &lt;chr&gt;,
## #   and abbreviated variable names ¹​education, ²​education_num, ³​marital_status,
## #   ⁴​occupation, ⁵​relationship
## # ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names</code></pre>
<p>
Let’s now write the functions used for benchmarking. There will be 5 of them:
</p>
<ul>
<li>
One using <code>grepl()</code> without any fancy options;
</li>
<li>
One using <code>grepl()</code> where <code>perl</code> is set to <code>TRUE</code>;
</li>
<li>
One that uses <code>stringi::stri_detect()</code>;
</li>
<li>
One that uses <code>stringr::str_detect()</code>;
</li>
<li>
One that uses <code>re2::re2_detect()</code>.
</li>
</ul>
<p>
Below you can read the functions. They’re all pretty much the same, only the function looking for the string changes. These functions look for a string in the <code>marital_status</code> variable and create a new variable with a corresponding integer.
</p>
<pre class="r"><code>with_grepl &lt;- function(dataset){
  dataset |&gt;
    mutate(married = case_when(
             grepl("Married", marital_status) ~ 1,
             grepl("married", marital_status) ~ 2,
             TRUE ~ 3)
           )
}

with_grepl_perl &lt;- function(dataset){
  dataset |&gt;
    mutate(married = case_when(
             grepl("Married", marital_status, perl = TRUE) ~ 1,
             grepl("married", marital_status, perl = TRUE) ~ 2,
             TRUE ~ 3)
           )
}

with_stringi &lt;- function(dataset){
  dataset |&gt;
    mutate(married = case_when(
             stri_detect(marital_status, regex = "Married") ~ 1,
             stri_detect(marital_status, regex = "married") ~ 2,
             TRUE ~ 3)
           )
}

with_stringr &lt;- function(dataset){
  dataset |&gt;
    mutate(married = case_when(
             str_detect(marital_status, "Married") ~ 1,
             str_detect(marital_status, "married") ~ 2,
             TRUE ~ 3)
           )
}

with_re2 &lt;- function(dataset){
  dataset |&gt;
    mutate(married = case_when(
             re2_detect(marital_status, "Married") ~ 1,
             re2_detect(marital_status, "married") ~ 2,
             TRUE ~ 3)
           )
}</code></pre>
<p>
Now I make extra sure these functions actually return the exact same thing. So for this I’m running them once on the data and use <code>testthat::expect_equal()</code>. It’s a bit unwieldy, so if you have a better way of doing this, please let me know.
</p>
<pre class="r"><code>run_grepl &lt;- function(){
  with_grepl(adult) %&gt;%
    count(married, marital_status)
}

one &lt;- run_grepl()

run_grepl_perl &lt;- function(){
  with_grepl_perl(adult) %&gt;%
    count(married, marital_status)
}

two &lt;- run_grepl_perl()

run_stringi &lt;- function(){
  with_stringi(adult) %&gt;%
    count(married, marital_status)
}

three &lt;- run_stringi()

run_stringr &lt;- function(){
  with_stringr(adult) %&gt;%
    count(married, marital_status)
}

four &lt;- run_stringr()

run_re2 &lt;- function(){
  with_re2(adult) %&gt;%
    count(married, marital_status)
}

five &lt;- run_re2()

one_eq_two &lt;- testthat::expect_equal(one, two)
one_eq_three &lt;- testthat::expect_equal(one, three)
three_eq_four &lt;- testthat::expect_equal(three, four)

testthat::expect_equal(
            one_eq_two,
            one_eq_three
          )

testthat::expect_equal(
            one_eq_three,
            three_eq_four
          )

testthat::expect_equal(
            one,
            five)</code></pre>
<p>
<code>testthat::expect_equal()</code> does not complain, so I’m pretty sure my functions, while different, return the exact same thing. Now, we’re ready for the benchmark itself. Let’s run these function 500 times using <code>{microbenchmark}</code>:
</p>
<pre class="r"><code>microbenchmark::microbenchmark(
     run_grepl(),
     run_grepl_perl(),
     run_stringi(),
     run_stringr(),
     run_re2(),
     times = 500
)</code></pre>
<pre><code>## Unit: milliseconds
##              expr      min       lq     mean   median       uq      max neval
##       run_grepl() 24.37832 24.89573 26.64820 25.50033 27.05967 115.0769   500
##  run_grepl_perl() 19.03446 19.41323 20.91045 19.89093 21.16683 104.3917   500
##     run_stringi() 23.01141 23.40151 25.00304 23.82441 24.83598 104.8065   500
##     run_stringr() 22.98317 23.44332 25.32851 23.92721 25.18168 145.5861   500
##         run_re2() 22.22656 22.60817 24.07254 23.05895 24.22048 108.6825   500</code></pre>
<p>
There you have it folks! The winner is <code>grepl()</code> with <code>perl = TRUE</code>, and then it’s pretty much tied between <code>stringi()</code>, <code>stringr()</code> and <code>re2()</code> (maybe there’s a slight edge for <code>re2()</code>) and <code>grepl()</code> without <code>perl = TRUE</code> is last. But don’t forget that this is running on my machine with Linux installed on it; maybe you’ll get different results on different hardware and OSs! So if you rely a lot on <code>grepl()</code> and other such string manipulation function, maybe run a benchmark on your hardware first. How come switching from <code>grepl()</code> (without <code>perl = TRUE</code> though) to <code>stri_detect()</code> made my pipeline at work run 4 times faster I don’t know. Maybe it has also to do with the size of the data, and the complexity of the regular expression used to detect the problematic strings?
</p>



 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-07-23-grepl_vs_stringi.html</guid>
  <pubDate>Sat, 23 Jul 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>R will always be arcane to those who do not make a serious effort to learn it…</title>
  <link>https://b-rodrigues.github.io/posts/2022-06-02-arcane.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://adv-r.hadley.nz/"> <img src="https://b-rodrigues.github.io/assets/img/third_impact.png" title="You need to put in the effort"></a>
</p>
</div>
<blockquote class="blockquote">
<p>
R will always be arcane to those who do not make a serious effort to learn it. It is <strong>not</strong> meant to be intuitive and easy for casual users to just plunge into. It is far too complex and powerful for that. But the rewards are great for serious data analysts who put in the effort.
</p>
<footer>
— Berton Gunter R-help August 2007
</footer>
</blockquote>
<p>
I’ve posted this quote on twitter the other day and it sparked some discussion. Personally I agree with this quote, and I’ll explain why.
</p>
<p>
Just like any tool aimed at professionals, R requires people to spend time to actually master it. There is no ifs or buts. Just like I don’t want a casual carpenter doing my carpentry, or a casual electrician doing the wiring in my house, I don’t think anyone should want to be a casual R user. Now of course, depending on your needs, you might not need to learn everything the language has to offer. I certainly don’t know everything R has to offer, far from it. But whatever task you need to fulfill, take the time to learn the required syntax and packages. As Berton Gunter said in 2007, <em>the rewards are great</em> if you put in the effort. You need to create top notch plots? Master <code>{ggplot2}</code>. Need to create top notch web apps? <code>{shiny}</code>, and so on and so forth… you get the idea. But as a shiny expert, you might not need to know, nor care, about R’s object oriented capabilities for example.
</p>
<p>
That’s fine.
</p>
<blockquote class="blockquote">
<p>
Evelyn Hall: I would like to know how (if) I can extract some of the information from the summary of my nlme.
</p>
<p>
Simon Blomberg: This is R. There is no if. Only how.
</p>
<footer>
— Evely Hall and Simon ’Yoda’ Blomberg, R-help April 2005
</footer>
</blockquote>
<p>
I remember being extremely frustrated when I started to learn R, not because the language was overly complex, (even if that was the case in the beginning, but honestly, that’s true for any language, even for supposedly piss-easy languages <a href="https://twitter.com/Aella_Girl/status/1522633160483385345">like Python</a>) but because my professors kept saying “no need to learn the language in great detail, we’re economists after all, not programmers”. That didn’t seem right, and now that I’ve been working with R for years (and with economists for some time as well), it certainly is important, even for economists, to be quite fluent in at least one programming language like R. How fluent should you be? Well, enough that you can test new ideas, or explore new data without much googling nor friction. Your creativity and curiosity cannot be limited by your lack of knowledge of the tools you need to use.
</p>
<p>
Some people posit that the <code>{tidyverse}</code> (and Rstudio, the GUI interface) made R more accessible. I’d say yes and no. On one hand, the tidyverse has following nice things going for it:
</p>
<ul>
<li>
Consistent api across packages. That definitely makes R easier to learn!
</li>
<li>
Made the <code>%&gt;%</code> operator famous, which improves readability.
</li>
<li>
Top notch documentation, and also many packages come with books that you can read online for free! That certainly makes R easier to learn.
</li>
</ul>
<p>
(and Rstudio was the first, really good, GUI for R).
</p>
<p>
But while this is all true, on the other hand, the <code>{tidyverse}</code> also makes it possible to write code like this (I’ll be using the <code>package::function()</code> to make the origin of the functions clear):
</p>
<pre class="r"><code>library(dplyr)
library(purrr)
library(ggfortify) # Not part of the tidyverse, but needed to make ggplot2::autoplot work on lm
library(ggplot2)
library(broom) # Not part of the tidyverse, but adheres to the *tidy* principles

result &lt;- mtcars %&gt;%
  dplyr::group_nest(am) %&gt;%
  dplyr::mutate(models = purrr::map(data, ~lm(hp ~ mpg + cyl, data = .))) %&gt;%
  dplyr::mutate(diag_plots = purrr::map(models, ggplot2::autoplot)) %&gt;%
  dplyr::mutate(model_summary = purrr::map(models, broom::tidy))</code></pre>
<p>
<code>result</code> is now a data frame with several columns:
</p>
<pre class="r"><code>result</code></pre>
<pre><code>## # A tibble: 2 × 5
##      am                data models diag_plots model_summary   
##   &lt;dbl&gt; &lt;list&lt;tibble[,10]&gt;&gt; &lt;list&gt; &lt;list&gt;     &lt;list&gt;          
## 1     0           [19 × 10] &lt;lm&gt;   &lt;ggmltplt&gt; &lt;tibble [3 × 5]&gt;
## 2     1           [13 × 10] &lt;lm&gt;   &lt;ggmltplt&gt; &lt;tibble [3 × 5]&gt;</code></pre>
<p>
<code>am</code> defines the groups, and then <code>data</code>, <code>models</code> and <code>model_summary</code> are list-columns containing complex objects (data frames, models, and plots, respectively). And don’t get me wrong here, this is not code that I made look complicated on purpose. This type of workflow is <em>canon</em> in the tidyverse lore. This is how you can avoid for loops and keep every result together neatly in a single object.
</p>
<p>
Let’s look at another esoteric example: imagine I want to publish a paper and am only interested in the coefficients of the model where the p-value is less than .05 (lol):
</p>
<pre class="r"><code>mtcars %&gt;%
  dplyr::group_nest(am) %&gt;%
  dplyr::mutate(models = purrr::map(data, ~lm(hp ~ mpg + cyl, data = .))) %&gt;%
  dplyr::mutate(model_summary = purrr::map(models, broom::tidy)) %&gt;%
  dplyr::mutate(model_summary = purrr::map(model_summary, \(x)(filter(x, p.value &lt; .05))))</code></pre>
<pre><code>## # A tibble: 2 × 4
##      am                data models model_summary   
##   &lt;dbl&gt; &lt;list&lt;tibble[,10]&gt;&gt; &lt;list&gt; &lt;list&gt;          
## 1     0           [19 × 10] &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
## 2     1           [13 × 10] &lt;lm&gt;   &lt;tibble [1 × 5]&gt;</code></pre>
<p>
I’ve mapped an anomymous function to the model summary, to filter out p-values greater than .05. Do you think this looks comprehensible to the beginner? I don’t think so. But I also don’t think that the beginners must stay beginners, and this is what matters.
</p>
<blockquote class="blockquote">
<p>
Actually, I see it as part of my job to inflict R on people who are perfectly happy to have never heard of it. Happiness doesn’t equal proficient and efficient. In some cases the proficiency of a person serves a greater good than their momentary happiness.
</p>
<footer>
— Patrick Burns, R-help April 2005
</footer>
</blockquote>
<p>
I’d argue that R, as arcane as it is (or not), is very likely one of the easiest languages to learn, and this is because there are a lot, and I mean a lot, of resources online:
</p>
<ul>
<li>
Free books (just take a look at the <a href="https://www.bigbookofr.com/">big book of R</a> to find everything you need)
</li>
<li>
Youtube channels dedicated to R (I’m shamelessly plugging <a href="https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ">mine</a>)
</li>
<li>
Packages with great documentation (take a look at the <a href="https://easystats.github.io/easystats/">easystats</a> suite for an example, or <a href="https://vincentarelbundock.github.io/modelsummary/index.html">modelsummary</a> and <a href="https://vincentarelbundock.github.io/marginaleffects/">marginaleffects</a>, both by Vincent Arel Bundock, and I’m not citing many, many others here)
</li>
<li>
Slack channels where you can get help
</li>
<li>
The community of R users on twitter (check out the <a href="https://twitter.com/hashtag/rstats">#RStats</a> hashtag)
</li>
<li>
The <a href="https://community.rstudio.com/#">RStudio Community forums</a>
</li>
<li>
And of course, the good old <a href="https://stat.ethz.ch/mailman/listinfo/r-help">R-help mailing list</a>
</li>
</ul>
<p>
And that’s only the free stuff. If you can afford it, there’s plenty of courses available as well. But no amount of free or paid content will be enough if you don’t invest enough time to learn the language, and this is true of <em>anything</em>. There are no secret recipes.
</p>
<p>
P.S.: I got all these quotes from the <code>{fortunes}</code> <a href="https://cran.r-project.org/web/packages/fortunes/index.html">package</a>.
</p>
<p>
</p>


 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-06-02-arcane.html</guid>
  <pubDate>Thu, 02 Jun 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Some learnings from functional programming you can use to write safer programs</title>
  <link>https://b-rodrigues.github.io/posts/2022-05-26-safer_programs.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<video width="320" height="240" controls="">
<source src="../assets/img/american_psycho.mp4" type="video/mp4">
</video>
</div>
<section id="learning-number-1-make-functions-fail-early" class="level2">
<h2 class="anchored" data-anchor-id="learning-number-1-make-functions-fail-early">
Learning number 1: make functions fail early
</h2>
<p>
When writing your own functions, avoid conversion of types without warning. For example, this function only works on characters:
</p>
<pre class="r"><code>my_nchar &lt;- function(x, result = 0){

  if(x == ""){
    result
  } else {
    result &lt;- result + 1
    split_x &lt;- strsplit(x, split = "")[[1]]
    my_nchar(paste0(split_x[-1],
                    collapse = ""), result)
  }

}</code></pre>
<pre class="r"><code>my_nchar("100000000")</code></pre>
<pre><code>## [1] 9</code></pre>
<pre class="r"><code>my_nchar(100000000)</code></pre>
<pre><code>Error in strsplit(x, split = "") : non-character argument</code></pre>
<p>
It may tempting to write functions that accept a lot of different types of inputs, because it seems convenient and you’re a lazy ding-dong:
</p>
<pre class="r"><code>my_nchar2 &lt;- function(x, result = 0){

  # What could go wrong?
  x &lt;- as.character(x)

  if(x == ""){
    result
  } else {
    result &lt;- result + 1
    split_x &lt;- strsplit(x, split = "")[[1]]
    my_nchar2(paste0(split_x[-1],
                    collapse = ""), result)
  }

}</code></pre>
<p>
You should avoid doing this, because this can have unforseen consequences:
</p>
<pre class="r"><code>my_nchar2(10000000)</code></pre>
<pre><code>## [1] 5</code></pre>
<p>
If you think that this example is far-fetched, you’d be surprised to learn that this is exactly what <code>nchar()</code>, the built-in function to count characters, does:
</p>
<pre class="r"><code>nchar("10000000")</code></pre>
<pre><code>## [1] 8</code></pre>
<p>
to this:
</p>
<pre class="r"><code>nchar(10000000)</code></pre>
<pre><code>## [1] 5</code></pre>
<p>
(thanks to <a href="https://twitter.com/cararthompson/status/1525114767614087169?s=20&amp;t=tP8Wh8Iy25bWUC1y3Qk5oQ"><span class="citation"><span class="citation" data-cites="cararthompson">@cararthompson</span></span></a> for pointing this out on twitter)
</p>
<p>
You can also add guards to be extra safe:
</p>
<pre class="r"><code>my_nchar2 &lt;- function(x, result = 0){

  if(!isTRUE(is.character(x))){
    stop(paste0("x should be of type 'character', but is of type '",
                typeof(x), "' instead."))
  } else if(x == ""){
    result
  } else {
    result &lt;- result + 1
    split_x &lt;- strsplit(x, split = "")[[1]]
    my_nchar2(paste0(split_x[-1],
                     collapse = ""), result)
  }
}</code></pre>
<pre class="r"><code>my_nchar2("10000000")</code></pre>
<pre><code>## [1] 8</code></pre>
<p>
compare to this:
</p>
<pre class="r"><code>my_nchar2(10000000)</code></pre>
<pre><code>Error in my_nchar2(1000):
x should be of type 'character', but is of type 'double' instead.</code></pre>
<p>
Now this doesn’t really help here, because our function is already safe (it only handles characters, since <code>strsplit()</code> only handles characters), but in other situations this could be helpful (and at least we customized the error message). Since it can be quite tedious to write all these <code>if…else…</code> statements, you might want to take a look at <code>purrr::safely()</code> (and <code>purrr::possibly()</code>), the <a href="https://armcn.github.io/maybe/">{maybe}</a> package, or the <a href="https://github.com/moodymudskipper/typed">{typed}</a> package, or even <a href="https://b-rodrigues.github.io/chronicler/">my package</a> for that matter.
</p>
</section>
<section id="learning-number-2-make-your-functions-referentially-transparent-and-as-pure-as-possible" class="level2">
<h2 class="anchored" data-anchor-id="learning-number-2-make-your-functions-referentially-transparent-and-as-pure-as-possible">
Learning number 2: Make your functions referentially transparent (and as pure as possible)
</h2>
<p>
Any variable used by a function should be one of its parameters. Don’t do this:
</p>
<pre class="r"><code>f &lt;- function(x){
  x + y
}</code></pre>
<p>
This function has only one parameter, <code>x</code>, and so depends on <code>y</code> outside of this scope. This function is unpredictable, because the result it provides depends on the value of <code>y</code>.
</p>
<p>
See what happens:
</p>
<pre class="r"><code>f(10)</code></pre>
<pre><code>## [1] 20</code></pre>
<pre class="r"><code>f(10)</code></pre>
<pre><code>## [1] 10</code></pre>
<p>
I called <code>f</code> twice with <code>10</code> and got two results (because I changed the value of <code>y</code> without showing you). In very long scripts, having functions like this depending on values in the global environment is a recipe for disaster. It’s better to make this function referentially transparent; some very complicated words to describe a very simple concept:
</p>
<pre class="r"><code>f &lt;- function(x, y){
  x + y
}</code></pre>
<p>
Just give <code>f</code> a second parameter, and you’re good to go.
</p>
<p>
Something else your functions shouldn’t do is changing stuff outside of its scope:
</p>
<pre class="r"><code>f &lt;- function(x, y){
  result &lt;&lt;- x + y
}</code></pre>
<p>
Let’s take a look at variables in global environment before calling <code>f</code>:
</p>
<pre class="r"><code>ls()</code></pre>
<pre><code>## [1] "f"         "my_nchar"  "my_nchar2" "view"      "view_xl"   "y"</code></pre>
<p>
Now let’s call it:
</p>
<pre class="r"><code>f(1, 2)</code></pre>
<p>
And let’s have a good look at the global environment again:
</p>
<pre class="r"><code>ls()</code></pre>
<pre><code>## [1] "f"         "my_nchar"  "my_nchar2" "result"    "view"      "view_xl"  
## [7] "y"</code></pre>
<p>
We now see that <code>result</code> has been defined in the global environment:
</p>
<pre class="r"><code>result</code></pre>
<pre><code>## [1] 3</code></pre>
<p>
Just like before, if your functions change stuff outside their scope, this is a recipe for disaster. You have to be very careful and know exactly what you’re doing if you want to use <code>&lt;&lt;-</code>.
</p>
<p>
So it’s better to write your function like this, and call it like this:
</p>
<pre class="r"><code>f &lt;- function(x, y){
  x + y
}

result &lt;- f(1, 2)</code></pre>
</section>
<section id="learning-number-3-make-your-functions-do-one-thing" class="level2">
<h2 class="anchored" data-anchor-id="learning-number-3-make-your-functions-do-one-thing">
Learning number 3: make your functions do one thing
</h2>
<p>
Try to write small functions that do just one thing. This make them easier to document, test and simply wrap your head around. You can then pipe your function one after the other to get stuff done:
</p>
<pre class="r"><code>a |&gt;
  f() |&gt;
  g() |&gt;
  h()</code></pre>
<p>
You have of course to make sure that the output of <code>f()</code> is of the correct type, so that <code>g()</code> then knows how to handle it. In some cases, you really need a function to do several things to get the output you want. In that case, still write small functions to handle every aspect of the whole algorithm, and then write a function that calls each function. And if needed, you can even provide functions as arguments to other functions:
</p>
<pre class="r"><code>h &lt;- function(x, y, f, g){
  f(x) + g(y)
}</code></pre>
<p>
This makes <code>h()</code> a higher-order function.
</p>
</section>
<section id="learning-number-4-use-higher-order-functions-to-abstract-loops-away" class="level2">
<h2 class="anchored" data-anchor-id="learning-number-4-use-higher-order-functions-to-abstract-loops-away">
Learning number 4: use higher-order functions to abstract loops away
</h2>
<p>
Loops are hard to write. Higher order function are really cool though:
</p>
<pre class="r"><code>Reduce(`+`, seq(1:100))</code></pre>
<pre><code>## [1] 5050</code></pre>
<p>
<code>Reduce()</code> is a higher-order function that takes a function (here <code>+</code>) and a list of inputs compatible with the function. So <code>Reduce()</code> performs this operation:
</p>
<pre class="r"><code>Reduce(`+`, seq(1:100))

100 + Reduce(`+`, seq(2:100))
100 + 99 + Reduce(`+`, seq(3:100))
100 + 99 + 98 + Reduce(`+`, seq(4:100))</code></pre>
<p>
This avoids having to write a loop, which can go wrong for many reasons (typos, checking input types, depending on variables outside the global environment… basically anything I mentioned already).
</p>
<p>
There’s also <code>purrr::reduce()</code> if you prefer the <code>tidyverse</code> ecosystem. Higher-order functions are super flexible; all that matters is that the function you give to <code>reduce()</code> knows what the do with the elements in the list.
</p>
<p>
Another higher-order function you should know about is <code>purrr::map()</code> (or <code>lapply()</code> if your prefer <code>base</code> functions):
</p>
<pre class="r"><code>purrr::map(list(mtcars, iris), nrow)</code></pre>
<pre><code>## [[1]]
## [1] 32
## 
## [[2]]
## [1] 150</code></pre>
<p>
This loops a function (here <code>nrow()</code>) over a list of whatevers (here data frames). Super flexible once again.
</p>
</section>
<section id="optional-learning-number-5-use-recursion-to-avoid-loops-further" class="level2">
<h2 class="anchored" data-anchor-id="optional-learning-number-5-use-recursion-to-avoid-loops-further">
(Optional) Learning number 5: use recursion to avoid loops further
</h2>
<p>
The following function calls itself and reverses a string:
</p>
<pre class="r"><code>rev_char &lt;- function(x){

  try({
    if(x == ""){
      ""
    } else {
      split_x &lt;- strsplit(x, split = "")[[1]]

      len_x &lt;- length(split_x)

      paste0(split_x[len_x],
             rev_char(paste0(split_x[1:len_x-1],
                             collapse = "")))
    }
  }, stop(paste0("x should be of type 'character', but is of type '",
                 typeof(x), "' instead.")))

}

rev_char("abc")</code></pre>
<pre><code>## [1] "cba"</code></pre>
<p>
I say that this is optional, because while it might sometimes be easier to use recursion to define a functions, this is not always the case, and (in the case of R) runs slower than using a loop. If you’re interested in learning more about <code>map()</code> and <code>reduce()</code>, I wrote several blog posts on it <a href="https://www.brodrigues.co/blog/2018-01-03-lists_all_the_way/">here</a>, <a href="https://www.brodrigues.co/blog/2018-01-05-lists_all_the_way2/">here</a> and <a href="https://www.brodrigues.co/blog/2018-01-19-mapping_functions_with_any_cols/">here</a> and some youtube videos as well:
</p>
<ul>
<li>
<a href="https://www.youtube.com/watch?v=3xIKZbZKCWQ" class="uri">https://www.youtube.com/watch?v=3xIKZbZKCWQ</a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=WjtXc4OXZuk" class="uri">https://www.youtube.com/watch?v=WjtXc4OXZuk</a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=vxaKamox_CQ" class="uri">https://www.youtube.com/watch?v=vxaKamox_CQ</a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=H3ao7LzcvW8" class="uri">https://www.youtube.com/watch?v=H3ao7LzcvW8</a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=vtxb1j0aqJM" class="uri">https://www.youtube.com/watch?v=vtxb1j0aqJM</a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=F2U-l3IcCtc" class="uri">https://www.youtube.com/watch?v=F2U-l3IcCtc</a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=gVW9KfkJIrQ" class="uri">https://www.youtube.com/watch?v=gVW9KfkJIrQ</a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=FanU60pjmt0" class="uri">https://www.youtube.com/watch?v=FanU60pjmt0</a>
</li>
<li>
<a href="https://www.youtube.com/watch?v=DERMZi3Ck20" class="uri">https://www.youtube.com/watch?v=DERMZi3Ck20</a>
</li>
</ul>


</section>
 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-05-26-safer_programs.html</guid>
  <pubDate>Thu, 26 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Get packages that introduce unique syntax adopted less?</title>
  <link>https://b-rodrigues.github.io/posts/2022-05-21-heavy_syntax.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://cran.r-project.org/src/contrib/Archive/"> <img src="https://b-rodrigues.github.io/assets/img/packages.jpg" title="The CRAN archive will always be there, at least"></a>
</p>
</div>
<p>
I have this hypothesis that packages that introduce a unique syntax, or a workflow change, get adopted less by users, even if what these packages do is super useful. I’m going to discuss two examples of packages that I think are really, really useful, but sometimes I wonder how many R users use them, or would use them if they were aware these packages existed. I myself, only use one of them!
</p>
<p>
The first package is <a href="https://github.com/moodymudskipper/typed"><code>{typed}</code></a> which introduces a type system for R. No more silent conversion to and from types without your knowing! If you don’t know what a type system is, consider the following:
</p>
<pre class="r"><code>nchar("100000000")</code></pre>
<pre><code>## [1] 9</code></pre>
<p>
you get “9” back, no problem. But if you do:
</p>
<pre class="r"><code>nchar(100000000)</code></pre>
<pre><code>## [1] 5</code></pre>
<p>
You get 5 back… what in the Lord’s name happened here? What happened is that the number 100000000 was converted to a character implicitly. But because of all these 0’s, this is what happened:
</p>
<pre class="r"><code>as.character(100000000)</code></pre>
<pre><code>## [1] "1e+08"</code></pre>
<p>
It gets converted to a character alright, but scientific notation gets used! So yes, 1e+08 is 5 characters long… Ideally <code>nchar()</code> would at least warn you that this conversion is happening, or maybe even error. After all, it’s called <code>nchar()</code> not <code>nnumeric()</code> or whatever. (Thanks to <a href="https://twitter.com/cararthompson/status/1525114767614087169?s=20&amp;t=oEOD1Vf7q9l0ZpdVLyDeUw"><code><span class="citation" data-cites="cararthompson">@cararthompson</span></code></a> for this!)
</p>
<p>
A solution could be to write a wrapper around it:
</p>
<pre class="r"><code>nchar2 &lt;- function(x, ...){
  stopifnot("x is not a character" = is.character(x))

  nchar(x, ...)
}</code></pre>
<p>
Now this function is safe:
</p>
<pre class="r"><code>nchar2(123456789)</code></pre>
<pre class="r"><code>## [1] Error in nchar2(123456789) : x is not a character</code></pre>
<p>
<code>{typed}</code> makes writing safe functions like this easier. Using <code>{typed}</code> you can write the wrapper like this:
</p>
<pre class="r"><code>library(typed, warn.conflicts = FALSE) 

strict_nchar &lt;- ? function(x = ? Character(), ...){

  nchar(x, ...)

}</code></pre>
<p>
<code>{typed}</code> introduces <code>?</code> (masking the base <code>?</code> function to read a function’s docs) allowing you to set the type the function’s arguments. It’s also possible to set the return type of the function:
</p>
<pre class="r"><code>strict_nchar &lt;- Integer() ? function(x = ? Character(), ...){

  nchar(x, ...)

}</code></pre>
<pre class="r"><code>strict_nchar("10000000")</code></pre>
<pre><code>## [1] 8</code></pre>
<p>
This is very useful if you want to write safe functions in a very concise and clean way.
</p>
<p>
The second kind of package I was thinking about are packages like <code>{targets}</code>, which force users to structure their projects in a very specific way. I really like <code>{targets}</code> and have been using it for quite some time. <code>{targets}</code> takes inspiration from build automation tools from the software development world and introduces the concept of build automation in R. If you’re a linux user, you’ve probably dealt with <code>Makefile</code>s (especially if you’ve been using linux for more than 10 years), and <code>{targets}</code> works in a similar way; by writing a script in which you define <em>targets</em>, these get built in a reproducible way. If you’d like to see it in action, take a look at <a href="https://www.youtube.com/watch?v=FvJ4xRGiEgw">this video</a> of mine. As useful as it is, I can imagine that some potential users will end up not adopting it, because <code>{targets}</code> really does things in a very unique and different way. Most people do not know what build automation tools are, and the cost of adopting <code>{targets}</code> seems disproportionally higher to its benefits (but believe me, it is well worth the cost!).
</p>
<p>
Now here’s the meat of the post: I think that packages like these, even though they’re very useful, get adopted less by users than other packages, that either:
</p>
<ul>
<li>
do not introduce a unique way of doing things;
</li>
<li>
for which alternatives are available.
</li>
</ul>
<p>
The reason, I believe, is that users do not feel comfortable adopting a unique syntax and way of doing things that impact their code so much, because if these libraries get abandoned, users will need to completely rewrite their scripts. And this is especially true when the two conditions above are not verified.
</p>
<p>
Take <code>{dplyr}</code>: one could argue that it introduces both a unique syntax, and a very specific workflow/way of doing things:
</p>
<pre class="r"><code>library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: 'dplyr'</code></pre>
<pre><code>## The following objects are masked from 'package:stats':
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>mtcars %&gt;%
 filter(am == 0) %&gt;%
 group_by(cyl) %&gt;%
 summarise(mean_hp = mean(hp))</code></pre>
<pre><code>## # A tibble: 3 × 2
##     cyl mean_hp
##   &lt;dbl&gt;   &lt;dbl&gt;
## 1     4    84.7
## 2     6   115. 
## 3     8   194.</code></pre>
<p>
But there are alternatives to it (a lot of <code>{dplyr}</code> functionality is covered by <code>base</code> functions already, and there’s also <code>{data.table}</code>), so IF <code>{dplyr}</code> would get abandoned by Rstudio (which will never happen, but let’s assume for the sake of argument), users <em>could</em> switch to <code>{data.table}</code>. Not so with more niche packages like the ones discussed above. Also, even <code>{dplyr}</code>’s unique syntax making heavy use of <code>%&gt;%</code> is not so unique anymore, since the release of R 4.1. A base approach to the above snippet would be:
</p>
<pre class="r"><code>mtcars |&gt;
  subset(am == 0) |&gt;
  with(aggregate(hp, by = list(cyl), mean))</code></pre>
<pre><code>##   Group.1         x
## 1       4  84.66667
## 2       6 115.25000
## 3       8 194.16667</code></pre>
<p>
Before R 4.1, looking at <code>{dplyr}</code> chains felt like looking at a completely different language than base R, but now with the introduction of <code>|&gt;</code> not so anymore. The other thing packages like <code>{dplyr}</code> have going for them, even when they introduce a completely new syntax, and do not have any alternative like <code>{ggplot2}</code> (I don’t consider <code>base</code> plotting an alternative to <code>{ggplot2}</code>, because it works in a completely different way) is that they have big teams and/or companies behind them, like Rstudio. So users feel much more confident adopting such packages, than if they’re written by a very small team (sometimes even just one person).
</p>
<p>
The reason I’m thinking about all this, is because I <a href="https://www.brodrigues.co/blog/2022-05-18-cran_0_2_0/">recently released a package</a> that raises all of the above red flags:
</p>
<ul>
<li>
new syntax (makes heavy use of a new pipe <code>%&gt;=%</code>);
</li>
<li>
forces a new workflow on users;
</li>
<li>
developed by a single dude in his free time who isn’t even a programmer (me).
</li>
</ul>
<p>
If I was a potential interested user, I honestly don’t know if I’d adopt this package for anything critical. I might play around with it a bit, but using that in production? What if the author (me) gets sick of it after a few months/years? Even I, as the author, cannot guarantee today that this package will still be maintained in 2 years. So users that might have important stuff running which uses my package are now screwed. I think that the only way for such packages to succeed, is if a sizeable community gathers around it and if the team of developers expands, and ideally, if it gets backed by a company (like Rstudio with all their packages, or rOpenSci <a href="https://docs.ropensci.org/targets/">does for <code>{targets}</code></a>.
</p>
<p>
To be clear, I am NOT complaining about free and open source software: these problems also exist with proprietary software. If a company builds something and they decide to abandon it, that’s it, it’s over. If there are no alternatives to it, users are screwed just as well. And companies can also go bankrupt or <em>change focus on other more profitable projects</em>. At least with free and open source software, if the author of a package has had enough and decides to not maintain anymore, there is still the possibility of someone else taking it over, and this someone else might be a user! There is also the possibility of running old R version with older versions of packages, even if they’re abandoned, using Docker. So maybe it’s not so bad.
</p>
<p>
What do you think? I’d be curious to hear your thoughts. Tell me what you think on <a href="https://github.com/b-rodrigues/fp_in_R_discussion/issues/2">this github issue I opened</a>.
</p>
<p>
Oh and by the way, IF you’re using <code>{chronicler}</code> after reading this, really, thank you.
</p>



 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-05-21-heavy_syntax.html</guid>
  <pubDate>Sat, 21 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>chronicler is now available on CRAN</title>
  <link>https://b-rodrigues.github.io/posts/2022-05-18-cran_0_2_0.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://b-rodrigues.github.io/chronicler/"> <img src="https://b-rodrigues.github.io/chronicler/reference/figures/hex.png" title="chronicler's hex logo" height="400px"></a>
</p>
</div>
<p>
I am very happy to annouce that the <code>{chronicler}</code> package, which I’ve been working on for the past 3 months has been released on CRAN. Install it with:
</p>
<pre class="r"><code>install.packages("chronicler")</code></pre>
<p>
<code>{chronicler}</code> allows you to create objects that carry a log with them. Here is an example of an object that has been created using <code>{chronicler}</code>, and saved using <code>saveRDS()</code> (which we now load back into our session using <code>readRDS()</code>):
</p>
<pre class="r"><code>library(chronicler)

my_df &lt;- readRDS("path/to/my_df.rds")</code></pre>
<p>
Printing <code>my_df</code> shows the following output:
</p>
<pre class="r"><code>my_df</code></pre>
<pre><code>## OK! Value computed successfully:
## ---------------
## Just
## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi'lek    female           55  
## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, "value").
## To read the log of this object, call read_log(.c).</code></pre>
<p>
<code>my_df</code> is made up of two parts, one is a data set, and the other is the log. If you wish to know how this data set was created, you can call <code>read_log(my_df)</code> (this function will be renamed to <code>read.log()</code> in the next release, to avoid clashing with <code>readr::read_log()</code>):
</p>
<pre class="r"><code>read_log(my_df)</code></pre>
<pre><code>## [1] "Complete log:"                                                                  
## [2] "OK! select(height,mass,species,sex) ran successfully at 2022-05-18 10:56:52"    
## [3] "OK! group_by(species,sex) ran successfully at 2022-05-18 10:56:52"              
## [4] "OK! filter(sex != \"male\") ran successfully at 2022-05-18 10:56:52"            
## [5] "OK! summarise(mean(mass, na.rm = TRUE)) ran successfully at 2022-05-18 10:56:52"
## [6] "Total running time: 0.185953617095947 secs"</code></pre>
<p>
if you want to get the dataset out of the <code>{chronicler}</code> “box”, you can do so with <code>pick(my_df, “value”)</code>:
</p>
<pre class="r"><code>pick(my_df, "value")</code></pre>
<pre><code>## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi'lek    female           55</code></pre>
<p>
To know more about all the package has to offer, read the <a href="https://b-rodrigues.github.io/chronicler/">readme</a> and the <a href="https://b-rodrigues.github.io/chronicler/articles/">vignettes</a> on the package’s website. I’m already working on the next release, where I plan to add the following features:
</p>
<ul>
<li>
Rename <code>read_log()</code> to <code>read.log()</code>
</li>
<li>
Make <code>{chronicler}</code> work with <code>{ggplot2}</code> (as described <a href="../posts/2022-05-15-self_doc_ggplot.html">here</a>)
</li>
<li>
Introduce functions to save <code>{chronicler}</code> objects as <code>.csv</code> or <code>.xlsx</code> files to disk (if the underlying value is a <code>data.frame</code>, as in the example above)
</li>
<li>
Anything else I think of between now and then!
</li>
</ul>
<p>
I’m really looking forward to see how people are going to use this package for their work, personally I’ve been mixing <code>{chronicler}</code> with <code>{targets}</code> to build very robust pipelines to build <code>chronicle</code> objects!
</p>
<section id="thanks" class="level2">
<h2 class="anchored" data-anchor-id="thanks">
Thanks
</h2>
<p>
I’d like to thank <a href="https://github.com/armcn">armcn</a>, <a href="https://github.com/Kupac">Kupac</a> for their blog posts (<a href="https://kupac.gitlab.io/biofunctor/2019/05/25/maybe-monad-in-r/">here</a>) and packages (<a href="https://armcn.github.io/maybe/">maybe</a>) which inspired me to build this package. Thank you as well to <a href="https://community.rstudio.com/t/help-with-writing-a-custom-pipe-and-environments/133447/2?u=brodriguesco">TimTeaFan</a> for his help with writing the <code>%&gt;=%</code> infix operator, <a href="https://community.rstudio.com/t/best-way-to-catch-rlang-errors-consistently/131632/5?u=brodriguesco">nigrahamuk</a> for showing me a nice way to catch errors, and finally <a href="https://community.rstudio.com/t/how-to-do-call-a-dplyr-function/131396/2?u=brodriguesco">Mwavu</a> for pointing me towards the right direction with an issue I’ve had as I started working on this package. Thanks to <a href="https://twitter.com/putosaure">Putosaure</a> for designing the hex logo, and of course to every single person that makes free and open source software possible.
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-05-18-cran_0_2_0.html</guid>
  <pubDate>Wed, 18 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Self-documenting {ggplot}s thanks to the power of monads!</title>
  <link>https://b-rodrigues.github.io/posts/2022-05-15-self_doc_ggplot.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://www.youtube.com/watch?v=I8LbkfSSR58&amp;list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_"> <img src="https://b-rodrigues.github.io/assets/img/monoids_endofunctors.jpg" title="How it feels to implement your own monad" width="80%" height="auto"></a>
</p>
</div>
<p>
Hey kid, fancy some self-documenting <code>{ggplots}</code> like this one:
</p>
<p>
<img src="https://b-rodrigues.github.io/assets/img/self_doc_ggplot-1-1.png" width="80%" height="auto">
</p>
<p>
Just read on!
</p>
<p>
I’ve been working hard on a package that I’ve called <code>{chronicler}</code> (read my post on it <a href="../posts/2022-04-04-chron_post.html">here</a>) which allows you to attach a log to the objects you create, thus making it easy to know how some data (for example) has been created. Here’s a quick example and intro to the main features:
</p>
<pre class="r"><code>suppressPackageStartupMessages(
  library(dplyr)
)
library(chronicler)

# record() decorates functions so they provide enriched output
r_group_by &lt;- record(group_by)
r_select &lt;- record(select)
r_summarise &lt;- record(summarise)
r_filter &lt;- record(filter)

output_pipe &lt;- starwars %&gt;%
  r_select(height, mass, species, sex) %&gt;=% # &lt;- this is a special pipe operator to handle `chronicle` objects
  r_group_by(species, sex) %&gt;=%
  r_filter(sex != "male") %&gt;=%
  r_summarise(mass = mean(mass, na.rm = TRUE))</code></pre>
<p>
<code>output_pipe</code> not only has the result of all the <code>{dplyr}</code> operations, but also carries a log with it. Let’s print the object:
</p>
<pre class="r"><code>output_pipe</code></pre>
<pre><code>## OK! Value computed successfully:
## ---------------
## Just
## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi'lek    female           55  
## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, "value").
## To read the log of this object, call read_log(.c).</code></pre>
<p>
Accessing the value is possible with <code>pick(“value”)</code>:
</p>
<pre class="r"><code>pick(output_pipe, "value")</code></pre>
<pre><code>## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi'lek    female           55</code></pre>
<p>
and you can read the log with <code>read_log()</code>:
</p>
<pre class="r"><code>read_log(output_pipe)</code></pre>
<pre><code>## [1] "Complete log:"                                                                  
## [2] "OK! select(height,mass,species,sex) ran successfully at 2022-05-15 17:10:43"    
## [3] "OK! group_by(species,sex) ran successfully at 2022-05-15 17:10:43"              
## [4] "OK! filter(sex != \"male\") ran successfully at 2022-05-15 17:10:43"            
## [5] "OK! summarise(mean(mass, na.rm = TRUE)) ran successfully at 2022-05-15 17:10:43"
## [6] "Total running time: 0.0434844493865967 secs"</code></pre>
<p>
If you want to understand how this works, I suggest you read the blog post I linked above but also <a href="https://www.brodrigues.co/blog/2022-04-11-monads/">this one</a>, where I explain the nitty gritty, theoretical details behind what <code>{chronicler}</code> does. To make a long story short, <code>{chronicler}</code> uses an advanced functional programming concept called a monad. And using the power of monads, I can now make self-documenting <code>{ggplot2}</code> graphs.
</p>
<p>
The idea was to be able to build a plot in a way similar to how I built that dataset just above, and have a log of how it was created attached to it. The issue is that the function that <em>transforms</em> functions to <code>chronicler</code> functions, <code>record()</code>, does not work on <code>{ggplot2}</code> functions.
</p>
<p>
This is because the way you create <code>{ggplot2}</code> graphs is by adding layers on top of each other:
</p>
<pre class="r"><code>library(ggplot2)

ggplot(mtcars) +
  geom_point(aes(mpg, hp))</code></pre>
<p>
<img src="https://b-rodrigues.github.io/assets/img/self_doc_ggplot-6-1.png" width="80%" height="auto">
</p>
<p>
The <code>+</code> here acts as a way to “add” the <code>geom_point(mpg, hp)</code> layer on top of the <code>ggplot(mtcars)</code> layer. I remember reading some tweets, quite some time ago, from people asking why <code>%&gt;%</code> couldn’t work with <code>{ggplot2}</code> and if Hadley Wickham, the developer of <code>{ggplot2}</code>, was considering making something like this work:
</p>
<pre class="r"><code>ggplot(mtcars) %&gt;%
  geom_point(aes(mpg, hp))</code></pre>
<p>
because people kept forgetting using <code>+</code> and kept using <code>%&gt;%</code>. The thing is, <code>%&gt;%</code> and <code>+</code> do very different things. <code>%&gt;%</code> takes its first argument and passes it as the first argument of its second argument, in other words this:
</p>
<pre class="r"><code>a %&gt;% f(b)</code></pre>
<p>
is exactly the same as:
</p>
<pre class="r"><code>f(a, b)</code></pre>
<p>
This is not what <code>{ggplot2}</code> functions do. When you call <code>+</code> on <code>{ggplot2}</code> objects, this is NOT what happens:
</p>
<pre class="r"><code>geom_point(ggplot(mtcars), aes(mpg, hp))</code></pre>
<p>
So that’s why <code>%&gt;%</code> cannot be used with <code>{ggplot2}</code> functions, and that’s also why the functions I developed in <code>{chronicle}</code> could not handle <code>{ggplot2}</code> functions either. So I had to provide new functions. The first function I developed is called <code>ggrecord()</code> and it decorates <code>{ggplot2}</code> functions:
</p>
<pre class="r"><code>r_ggplot &lt;- ggrecord(ggplot)
r_geom_point &lt;- ggrecord(geom_point)
r_labs &lt;- ggrecord(labs)</code></pre>
<p>
Now the output of these functions are not <code>ggplot</code> objects anymore, but chronicle objects. So to make layering them possible, I also needed to rewrite <code>+</code>. I called my rewritten <code>+</code> like this: <code>%&gt;+%</code>:
</p>
<pre class="r"><code>a &lt;- r_ggplot(mtcars) %&gt;+%
  r_geom_point(aes(y = mpg, x = hp)) %&gt;+%
  r_labs(title = "Self-documenting ggplot!\nLook at the bottom right",
         caption = "This is an example caption")</code></pre>
<p>
Let’s first take a look at <code>a</code>:
</p>
<pre class="r"><code>a</code></pre>
<pre><code>## OK! Ggplot computed successfully:
## ---------------
## Just</code></pre>
<p>
<img src="https://b-rodrigues.github.io/assets/img/self_doc_ggplot-13-1.png" width="80%" height="auto">
</p>
<pre><code>## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, "value").
## To read the log of this object, call read_log(.c).</code></pre>
<p>
As before expected, <code>a</code> is now an object of type <code>{chronicle}</code>, where its “value” is a <code>ggplot</code> object. But where is the self-documenting part? For this, you use the last piece of the puzzle, <code>document_gg()</code>:
</p>
<pre class="r"><code>document_gg(a)</code></pre>
<pre><code>## OK! Ggplot computed successfully:
## ---------------
## Just</code></pre>
<p>
<img src="https://b-rodrigues.github.io/assets/img/self_doc_ggplot-14-1.png" width="80%" height="auto">
</p>
<pre><code>## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, "value").
## To read the log of this object, call read_log(.c).</code></pre>
<p>
The caption now contains the log of the plot, making it easily reproducible!
</p>
<p>
This is still in very early development, but if you want to try it out, you’ll need to try the <code>dev</code> branch of <a href="https://github.com/b-rodrigues/chronicler/tree/dev">the package</a>.
</p>
<p>
Any feedback, comments, ideas, pull requests, more than welcome.
</p>



 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-05-15-self_doc_ggplot.html</guid>
  <pubDate>Sun, 15 May 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Why you should(n’t) care about Monads if you’re an R programmer</title>
  <link>https://b-rodrigues.github.io/posts/2022-04-11-monads.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://www.youtube.com/watch?v=I8LbkfSSR58&amp;list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_"> <img src="https://b-rodrigues.github.io/assets/img/pondering.jpg" title="How it feels to implement your own monad" width="80%" height="auto"></a>
</p>
</div>
<p>
<em>Update: I also made a video out of this blog post; watch it on <a href="https://www.youtube.com/watch?v=Hlypj6-n51c">youtube</a>.</em>
</p>
<section id="introduction-functions" class="level2">
<h2 class="anchored" data-anchor-id="introduction-functions">
Introduction: functions
</h2>
<p>
To understand Monads, I think it’s useful to first think about functions; why do we use functions? Why don’t we simply write scripts with the required operations one after the other? For instance, to compute the average height by species in a data set of individuals from the famous space opera “Star Wars”, we could very well write this code:
</p>
<pre class="r"><code>suppressPackageStartupMessages(library(dplyr))

data(starwars)

sum_humans &lt;- 0
sum_others &lt;- 0
n_humans &lt;- 0
n_others &lt;- 0

for(i in seq_along(1:nrow(starwars))){

  if(!is.na(unlist(starwars[i, "species"])) &amp;
     unlist(starwars[i, "species"]) == "Human"){
    if(!is.na(unlist(starwars[i, "height"]))){
      sum_humans &lt;- sum_humans + unlist(starwars[i, "height"])
      n_humans &lt;- n_humans + 1
    } else {

      0

    }

  } else {
    if(!is.na(unlist(starwars[i, "height"]))){
      sum_others &lt;- sum_others + unlist(starwars[i, "height"])
      n_others &lt;- n_others + 1
    } else {
      0
    }
  }
}

mean_height_humans &lt;- sum_humans/n_humans
mean_height_others &lt;- sum_others/n_others</code></pre>
<p>
Well, we <em>could</em> do it like this, but we definitely shouldn’t:
</p>
<ul>
<li>
what this code does is not immediately obvious. If the code blocks aren’t commented, readers of this code will have to read line by line to understand what is going on;
</li>
<li>
this code is not reusable. If now I need the average height by species and sex, I need to copy and paste the code, and modify it, and in some cases modify it substantially;
</li>
<li>
this code handles missing values in a cumbersome way, with nested <code>if…else…</code>s;
</li>
<li>
this code is not easy to test;
</li>
<li>
this code cannot be composed (meaning, chained) with other code without substantially altering it (to be precise, chaining and composing are two different things, strictly speaking, but for simplicity’s sake, let’s just assume it is the same. Whenever I’m talking about “composing” something, I mean “chaining” something.)
</li>
</ul>
<p>
But it’s not just shortcomings, this <em>imperative</em> code has one advantage; it uses only some very fundamental building blocks: <code>if…else…</code>, for loops and that’s almost it (it does use some functions provided by a base installation of R, namely <code>is.na()</code>, <code>!()</code>, <code>unlist()</code> and <code>[()</code>, so strictly speaking, the code above is not purely imperative, but maybe closer to being procedural?).
</p>
<p>
Using functions solves all the issues from imperative programming. Here is a base solution to the problem above, using a declarative, or functional, approach:
</p>
<pre class="r"><code>aggregate(starwars$height,
          by = list(starwars$species == "Human"),
          FUN = \(x)(mean(x, na.rm = TRUE)))</code></pre>
<pre><code>##   Group.1        x
## 1   FALSE 172.4043
## 2    TRUE 176.6452</code></pre>
<p>
This code has many advantages:
</p>
<ul>
<li>
what this code does is obvious, but only if you know what <code>aggregate()</code> does. But if you read its documentation you’ll know, and you’ll know every time you’ll see <code>aggregate()</code> unlike a loop like the loop above where you’ll have to read it each time to understand;
</li>
<li>
this code is reusable. Replace the data frame by another, and that’s it;
</li>
<li>
Missing values are now ignored easily using the <code>na.rm</code> argument of <code>mean()</code>;
</li>
<li>
this code is easy to test (using unit tests);
</li>
<li>
this code can be composed, for instance like this:
</li>
</ul>
<pre class="r"><code>aggregate(starwars$height,
          by = list(starwars$species == "Human"),
          FUN = \(x)(mean(x, na.rm = TRUE))) |&gt;
  setNames(c("is_human", "mean_height"))</code></pre>
<pre><code>##   is_human mean_height
## 1    FALSE    172.4043
## 2     TRUE    176.6452</code></pre>
<p>
The issue with the functional approach (at least that’s the issue that many people I spoke to about this raise) is that… in some way people that don’t like this approach feel like they “lose” control over what’s going on. You don’t know what happens inside these functions. I remember, while working my first job, that my boss required that I don’t use any functions nor packages, but instead write all the loops explicitely, because she wanted to understand what was going on (of course, I completely ignored this request and just did as I pleased). As discussed above, the imperative approach requires minimum knowledge of the language, and almost anyone with an ounce of programming experience can understand imperative code. That’s not the case with a functional approach. Readers will have to be familiar with the individual functions like <code>aggregate()</code>, but also anonymous functions (I had to use <code>(x)(mean(x, na.rm = TRUE))</code> to set <code>na.rm = TRUE</code>, which is <code>FALSE</code> by default) and also <code>|&gt;</code> for composition/chaining.
</p>
<p>
It may same more complex, and maybe it is, but the advantages far outweigh the shortcoming.
</p>
<p>
For completeness, here is a <code>{dplyr}</code> version:
</p>
<pre class="r"><code>starwars %&gt;%
  group_by(is_human = species == "Human") %&gt;%
  summarise(mean_height = mean(height, na.rm = TRUE))</code></pre>
<pre><code>## # A tibble: 3 × 2
##   is_human mean_height
##   &lt;lgl&gt;          &lt;dbl&gt;
## 1 FALSE           172.
## 2 TRUE            177.
## 3 NA              181.</code></pre>
<p>
<code>{dplyr}</code> code is even more concise than base functional code. Here again, users will have to know about the individual functions and <code>%&gt;%</code>. But personally, I think that the only hurdle is understanding what <code>%&gt;%</code> does, and once you know this, <code>{dplyr}</code> code can be understood quite easily, thanks to very explicit function names.
</p>
<p>
So functions are great. They’re easy to test, easy to document, easy to package, easy to reuse, and easy to compose. Composition is really important. For example, let’s go back to the imperative code, and put the result in a neat data frame object, like the functional solutions do:
</p>
<pre class="r"><code>sum_humans &lt;- 0
sum_others &lt;- 0
n_humans &lt;- 0
n_others &lt;- 0

for(i in seq_along(1:nrow(starwars))){

  if(!is.na(unlist(starwars[i, "species"])) &amp;
     unlist(starwars[i, "species"]) == "Human"){
    if(!is.na(unlist(starwars[i, "height"]))){
      sum_humans &lt;- sum_humans + unlist(starwars[i, "height"])
      n_humans &lt;- n_humans + 1
    } else {

      0

    }

  } else {
    if(!is.na(unlist(starwars[i, "height"]))){
      sum_others &lt;- sum_others + unlist(starwars[i, "height"])
      n_others &lt;- n_others + 1
    } else {
      0
    }
  }
}

mean_height_humans &lt;- sum_humans/n_humans
mean_height_others &lt;- sum_others/n_others

# These two lines are new
data.frame(list("is_human" = c(TRUE, FALSE),
           "mean_height" = c(mean_height_others, mean_height_humans)))</code></pre>
<pre><code>##   is_human mean_height
## 1     TRUE    172.9400
## 2    FALSE    176.6452</code></pre>
<p>
It’s just two lines (right at the end), but the implications are huge; because imperative code cannot be composed, I had to write separate code to put the result into a data frame. More code that I need to write, more opportunities for mistakes. I actually did a mistake, did you notice? This kind of mistake could go unnoticed for eons. But if you use functions, you don’t have this problem, and can focus on getting (even complex) things done:
</p>
<pre class="r"><code>starwars %&gt;%
  filter(skin_color == "light") %&gt;%
  select(species, sex, mass) %&gt;%
  group_by(sex, species) %&gt;%
  summarise(
    total_individuals = n(),
    min_mass = min(mass, na.rm = TRUE),
    mean_mass = mean(mass, na.rm = TRUE),
    sd_mass = sd(mass, na.rm = TRUE),
    max_mass = max(mass, na.rm = TRUE)
  ) %&gt;%
  select(-species) %&gt;%
  tidyr::pivot_longer(-sex, names_to = "statistic", values_to = "value")</code></pre>
<pre><code>## `summarise()` has grouped output by 'sex'. You can override using the `.groups`
## argument.</code></pre>
<pre><code>## # A tibble: 10 × 3
## # Groups:   sex [2]
##    sex    statistic         value
##    &lt;chr&gt;  &lt;chr&gt;             &lt;dbl&gt;
##  1 female total_individuals   6  
##  2 female min_mass           45  
##  3 female mean_mass          56.3
##  4 female sd_mass            16.3
##  5 female max_mass           75  
##  6 male   total_individuals   5  
##  7 male   min_mass           79  
##  8 male   mean_mass          90.5
##  9 male   sd_mass            19.8
## 10 male   max_mass          120</code></pre>
<p>
Needless to say, trying to write the above code using only for loops and <code>if…else…</code> is not something I’d wish to do, especially passing the result of all the <code>{dplyr}</code> calls to <code>pivot_longer()</code>. Creating that last data frame by hand is error prone, and there would definitely be mistakes in there.
</p>
<p>
I hope I don’t need to convince you any more that functions are great, and that one of the great things they offer is their ability to be chained, or composed. But strictly speaking, you don’t need them. You <em>could</em> write your code without any function whatsoever, and use the most basic building blocks there are (loops and <code>if…else…</code> and little more). However, doing this would result in much messier code. It’s the same with monads. You can live without them. But there will be situations where not using them will result in messier code.
</p>
<p>
One more thing: as I was writing this blog post, I happened on this tweet:
</p>
<p>
{{% tweet “1513080736785604611” %}}
</p>
<p>
This is a fine example of all that I’ve been discussing until now. The person who wrote this code was very likely trying to get the diagonal elements of a matrix. That person was likely a beginner in R and used for loops to try to get the answer. We have all been there; what I’m trying to articulate is this: imperative programming can be useful, but it can get messy very quickly…
</p>
</section>
<section id="when-functions-are-not-enough" class="level2">
<h2 class="anchored" data-anchor-id="when-functions-are-not-enough">
When functions are not enough
</h2>
<p>
Functions are awesome, but there are situations which functions simply can’t easily deal with. Situations in which you would like your functions to do a little extra more, and the only way forward you see is to rewrite them to do something totally unrelated. For example, suppose you would like to time your code. Most people would to something such as:
</p>
<pre class="r"><code>tic &lt;- Sys.time()
starwars %&gt;%
  filter(skin_color == "light") %&gt;%
  select(species, sex, mass) %&gt;%
  group_by(sex, species) %&gt;%
  summarise(
    total_individuals = n(),
    min_mass = min(mass, na.rm = TRUE),
    mean_mass = mean(mass, na.rm = TRUE),
    sd_mass = sd(mass, na.rm = TRUE),
    max_mass = max(mass, na.rm = TRUE)
  ) %&gt;%
  select(-species) %&gt;%
  tidyr::pivot_longer(-sex, names_to = "statistic", values_to = "value")</code></pre>
<pre><code>## `summarise()` has grouped output by 'sex'. You can override using the `.groups`
## argument.</code></pre>
<pre><code>## # A tibble: 10 × 3
## # Groups:   sex [2]
##    sex    statistic         value
##    &lt;chr&gt;  &lt;chr&gt;             &lt;dbl&gt;
##  1 female total_individuals   6  
##  2 female min_mass           45  
##  3 female mean_mass          56.3
##  4 female sd_mass            16.3
##  5 female max_mass           75  
##  6 male   total_individuals   5  
##  7 male   min_mass           79  
##  8 male   mean_mass          90.5
##  9 male   sd_mass            19.8
## 10 male   max_mass          120</code></pre>
<pre class="r"><code>toc &lt;- Sys.time()

(running_time &lt;- toc - tic)</code></pre>
<pre><code>## Time difference of 0.04228544 secs</code></pre>
<p>
You could totally do that. But now you’re back to square one. You have to deal with this tic-toc nonsense separately, have to keep track it, overburdening you mentally and polluting your code. To keep track of it, you’ll want to add the running times in a separate data frame, in which you could have all the running times of all your operations you need to run:
</p>
<pre class="r"><code>data.frame(list("operations" = seq(1:3),
                "running_time" = c(running_time, running_time * 2, running_time * 3)))</code></pre>
<pre><code>##   operations    running_time
## 1          1 0.04228544 secs
## 2          2 0.08457088 secs
## 3          3 0.12685633 secs</code></pre>
<p>
This data frame is the consequence of this tic-toc nonsense not being composable and now you have to deal with it, but you don’t want to. So what now? You might be tempted to do something like this:
</p>
<pre class="r"><code>tic_filter &lt;- function(...){

  tic &lt;- Sys.time()

  result &lt;- filter(...)

  toc &lt;- Sys.time()

  message("Running time: ", toc - tic)

  return(result)

}

starwars %&gt;%
  tic_filter(species == "Human")</code></pre>
<pre><code>## Running time: 0.00481176376342773</code></pre>
<pre><code>## # A tibble: 35 × 14
##    name     height  mass hair_color skin_color eye_color birth_year sex   gender
##    &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; 
##  1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…
##  2 Darth V…    202   136 none       white      yellow          41.9 male  mascu…
##  3 Leia Or…    150    49 brown      light      brown           19   fema… femin…
##  4 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…
##  5 Beru Wh…    165    75 brown      light      blue            47   fema… femin…
##  6 Biggs D…    183    84 black      light      brown           24   male  mascu…
##  7 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…
##  8 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…
##  9 Wilhuff…    180    NA auburn, g… fair       blue            64   male  mascu…
## 10 Han Solo    180    80 brown      fair       brown           29   male  mascu…
## # … with 25 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;,
## #   films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt;</code></pre>
<p>
But that’s actually worse: not only do you have to change all the functions you need, and wrap them around tic-toc, but the running time is only shown as a message, so you can’t reuse it. You could then try to rewrite the function like this:
</p>
<pre class="r"><code>tic_filter &lt;- function(...){

  tic &lt;- Sys.time()

  result &lt;- filter(...)

  toc &lt;- Sys.time()

  running_time &lt;- toc - tic

  list("result" = result,
       "running_time" = running_time)

}

starwars %&gt;%
  tic_filter(species == "Human")</code></pre>
<pre><code>## $result
## # A tibble: 35 × 14
##    name     height  mass hair_color skin_color eye_color birth_year sex   gender
##    &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; 
##  1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…
##  2 Darth V…    202   136 none       white      yellow          41.9 male  mascu…
##  3 Leia Or…    150    49 brown      light      brown           19   fema… femin…
##  4 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…
##  5 Beru Wh…    165    75 brown      light      blue            47   fema… femin…
##  6 Biggs D…    183    84 black      light      brown           24   male  mascu…
##  7 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…
##  8 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…
##  9 Wilhuff…    180    NA auburn, g… fair       blue            64   male  mascu…
## 10 Han Solo    180    80 brown      fair       brown           29   male  mascu…
## # … with 25 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;,
## #   films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt;
## 
## $running_time
## Time difference of 0.004878759 secs</code></pre>
<p>
At least now you save the running time along with the object. But the problem of rewriting many functions remains, and these rewritten <code>{dplyr}</code> functions now return a list, and not a data frame anymore so something like this:
</p>
<pre class="r"><code>starwars %&gt;%
  tic_filter(species == "Human") %&gt;%
  tic_select(species, sex)</code></pre>
<p>
wouldn’t work, because <code>tic_select()</code> expects a data frame, not a list where the first element is a data frame and the second a double.
</p>
<p>
So what else can be done? Perhaps you’d be tempted to use a global variable for this:
</p>
<pre class="r"><code>tic_filter &lt;- function(..., running_time = 0){

  tic &lt;- Sys.time()

  result &lt;- filter(...)

  toc &lt;- Sys.time()

  running_time &lt;&lt;- toc - tic + running_time

  result

}</code></pre>
<p>
Functions written like this would save the running time in a global variable called <code>running_time</code> and each of them would take turns overwriting it:
</p>
<pre class="r"><code>running_time &lt;- 0

one &lt;- starwars %&gt;%
  tic_filter(species == "Human", running_time = running_time)

running_time</code></pre>
<pre><code>## Time difference of 0.00490284 secs</code></pre>
<pre class="r"><code>two &lt;- one %&gt;%
  tic_select(species, sex, running_time = running_time)

running_time</code></pre>
<pre><code>## Time difference of 0.007258415 secs</code></pre>
<p>
(I defined <code>tic_select()</code> but am not showing it here.)
</p>
<p>
This has the advantage that the wrapped functions now return data frames as well, and can thus be composed/chained. But these functions are not pure functions, because they change something (the global variable <code>running_time</code>) outside their scope. Impure functions can be tricky; for instance here, because the code keeps overwriting the same variable, if you run the whole script and then separate chunks to try some things, <code>running_time</code> will keep getting incremented. Once again, you have to be extra careful and keep track of it, once again overburdening you mentally.
</p>
</section>
<section id="the-solution" class="level2">
<h2 class="anchored" data-anchor-id="the-solution">
The solution
</h2>
<p>
The solution to this problem looks like one of the previous things we tried, namely:
</p>
<pre class="r"><code>tic_filter &lt;- function(...){

  tic &lt;- Sys.time()

  result &lt;- filter(...)

  toc &lt;- Sys.time()

  running_time &lt;- toc - tic

  list("result" = result,
       "running_time" = running_time)

}</code></pre>
<p>
While it is true that it returns a list, this function has the yuge advantage of being pure. But still, we need to solve two problems:
</p>
<ul>
<li>
how to avoid having to rewrite every function;
</li>
<li>
how to compose these functions so that the output of one function can be ingested as the input of the next.
</li>
</ul>
<p>
Solving the first problem consists in writing a new function that builds functions, what Hadley Wickham calls <a href="https://adv-r.hadley.nz/function-factories.html">function factories</a>. Let’s try:
</p>
<pre class="r"><code>timeit &lt;- function(.f, ..., running_time = 0){

  function(..., .running_time = running_time){

    tic &lt;- Sys.time()

    result &lt;- .f(...)

    toc &lt;- Sys.time()

    list(result = result,
         running_time = toc - tic + .running_time)
  }


}</code></pre>
<p>
<code>timeit()</code> is a function that takes a function (and its arguments as an input), and returns a new function. This function returns the result of the original function (<code>.f</code>) evaluated on its arguments (<code>…</code>) as well as the time it took to run as a list. You’ll notice as well that this function takes another argument, called <code>running_time</code> with a default value of 0. This will become useful below, for now, ignore it.
</p>
<pre class="r"><code>t_sqrt &lt;- timeit(sqrt)

t_sqrt(10)</code></pre>
<pre><code>## $result
## [1] 3.162278
## 
## $running_time
## Time difference of 8.34465e-06 secs</code></pre>
<p>
That’s great, but we can’t compose these functions. This fails:
</p>
<pre class="r"><code>t_log &lt;- timeit(log)

10 |&gt;
  t_sqrt() |&gt;
  t_log()</code></pre>
<pre class="r"><code>Error in .f(...) : non-numeric argument to mathematical function</code></pre>
<p>
because <code>t_log()</code> expects a number, not a list. The solution? Write another functions to help! Let’s call this function bind:
</p>
<pre class="r"><code>bind &lt;- function(.l, .f, ...){

  .f(.l$result, ..., .running_time = .l$running_time)

}</code></pre>
<p>
<code>bind()</code> takes a list object returned by a timed function (<code>.l</code>, with elements <code>$result</code> and <code>$running_time</code>) and applies another timed function <code>.f()</code> to the <code>$result</code> element of <code>.l</code> as well as any further arguments <code>…</code> and finally sets the <code>running_time</code> argument of <code>.f</code> equal to <code>.l$running_time</code>. <code>.l$running_time</code> is the running time of the previous timed function call, so now this running time gets added to the running time of <code>.f</code> (see the definition of the list of <code>timeit()</code>).
</p>
<p>
An example might help:
</p>
<pre class="r"><code>t_log &lt;- timeit(log)

10 |&gt;
  t_sqrt() |&gt;
  bind(t_log)</code></pre>
<pre><code>## $result
## [1] 1.151293
## 
## $running_time
## Time difference of 8.368492e-05 secs</code></pre>
<p>
What’s nice with this solution, is that it works with any function:
</p>
<pre class="r"><code>t_filter &lt;- timeit(filter)
t_select &lt;- timeit(select)
t_group_by &lt;- timeit(group_by)
t_summarise &lt;- timeit(summarise)
t_p_longer &lt;- timeit(tidyr::pivot_longer)

starwars %&gt;%
  t_filter(skin_color == "light") %&gt;% # no need to use bind here
  bind(t_select, species, sex, mass) %&gt;%
  bind(t_group_by, sex, species) %&gt;%
  bind(t_summarise,
    total_individuals = n(),
    min_mass = min(mass, na.rm = TRUE),
    mean_mass = mean(mass, na.rm = TRUE),
    sd_mass = sd(mass, na.rm = TRUE),
    max_mass = max(mass, na.rm = TRUE)
  ) %&gt;%
  bind(t_select, -species) %&gt;%
  bind(t_p_longer, -sex, names_to = "statistic", values_to = "value")</code></pre>
<pre><code>## `summarise()` has grouped output by 'sex'. You can override using the `.groups`
## argument.</code></pre>
<pre><code>## $result
## # A tibble: 10 × 3
## # Groups:   sex [2]
##    sex    statistic         value
##    &lt;chr&gt;  &lt;chr&gt;             &lt;dbl&gt;
##  1 female total_individuals   6  
##  2 female min_mass           45  
##  3 female mean_mass          56.3
##  4 female sd_mass            16.3
##  5 female max_mass           75  
##  6 male   total_individuals   5  
##  7 male   min_mass           79  
##  8 male   mean_mass          90.5
##  9 male   sd_mass            19.8
## 10 male   max_mass          120  
## 
## $running_time
## Time difference of 0.09293914 secs</code></pre>
<p>
There is some overhead compared to the solution that simply calls <code>tic</code> at the beginning of all the <code>{dplyr}</code> calls and then <code>toc</code> at the end, but this overhead becomes negligible the longer the base operations run for. And now the advantage is that you don’t have to think about keeping track of running times. Re-running separate chunks will also not interfere with the running time of any other chunk.
</p>
</section>
<section id="monads" class="level2">
<h2 class="anchored" data-anchor-id="monads">
Monads
</h2>
<p>
So here we are, ready to learn what monads are, or rather, we’re done, because you already know what monads are. The solution described before is a monad:
</p>
<ul>
<li>
a function factory to create functions that return a special, wrapped value (here it simply was a list of elements <code>$result</code> and <code>$running_time</code>). This wrapped value is also called a monadic value.
</li>
<li>
a function to compose, or chain, these special functions together.
</li>
</ul>
<p>
Some other pieces can be added to the list, and one would need to check so-called monadic laws to make extra sure we’re dealing with a monad, but that’s outside the scope of this blog post.
</p>
<p>
There are many monads, for instance the so-called <code>Maybe</code> monad, available on R thanks to <a href="https://twitter.com/armcn_">Andrew McNeil</a> who implemented this monad as an R <a href="https://armcn.github.io/maybe/">package</a>. I have also developed a monad for logging (which also logs execution time), which I called <code>{chronicler}</code>, read more about it <a href="https://www.brodrigues.co/blog/2022-04-04-chron_post/">here</a>.
</p>
<p>
To conclude, why did I title this post <em>why you should(n’t) care about Monads if you’re an R programmer</em>? The reason is that you can live without monads. However, certain things will be more complex if you don’t know about monads or if you don’t want to use them, just like functions. If for some reason you don’t use functions in your code, your life will be more complicated. So should you go ahead and start using monads in your code? Well, maybe (hehe) you should, especially if you’re doing the same thing over and over again, like timing your code. Maybe using a monad to time your code could be a nice solution, especially if you’ve been burned in the past by using the other, sub-optimal solutions?
</p>
</section>
<section id="extra-reading" class="level2">
<h2 class="anchored" data-anchor-id="extra-reading">
Extra reading
</h2>
<p>
If this blog post was not enough to satiate your curiosity, here are some more nice resources:
</p>
<ul>
<li>
<a href="https://twitter.com/kupac">Laszlo Kupcsik</a> great <a href="https://kupac.gitlab.io/biofunctor/2019/05/25/maybe-monad-in-r/">blog post</a> on the maybe monad,
</li>
<li>
<a href="https://twitter.com/armcn_">Andrew McNeil</a> implementation of the <code>Maybe</code> monad as a <a href="https://armcn.github.io/maybe/">package</a>
</li>
<li>
this nice <a href="https://www.youtube.com/watch?v=C2w45qRc3aU">video</a> by <a href="https://www.youtube.com/channel/UCUdkjbeIFea0qUSgwR1CUOg">Studying With Alex</a>
</li>
<li>
and of course, the GOAT, <a href="https://twitter.com/BartoszMilewski">Bartosz Milewski’s</a> Category Theory For Programmers on <a href="https://www.youtube.com/watch?v=I8LbkfSSR58&amp;list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_">YouTube</a> if you really want to go into the nitty-gritty theoretical details of functional programming.
</li>
<li>
There’s also this very accessible and nice blog post, <a href="https://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html">Functors, applicatives and monads in pictures</a> which I highly recommend.
</li>
</ul>


</section>

 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-04-11-monads.html</guid>
  <pubDate>Mon, 11 Apr 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>The {chronicler} package, an implementation of the logger monad in R</title>
  <link>https://b-rodrigues.github.io/posts/2022-04-04-chron_post.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://wiki.haskell.org/Monad_laws"> <img src="https://b-rodrigues.github.io/assets/img/monads.jpg" title="Believe me, the reward is not so great without the struggle. - Wilma Rudolph" width="80%" height="auto"></a>
</p>
</div>
<p>
<a href="../posts/2022-02-18-loudly.html">Back in February</a> I discussed a package I was working on which allowed users to add logging to function calls. I named the package <code>{loudly}</code> but decided to rename it to <a href="https://github.com/b-rodrigues/chronicler"><code>{chronicler}</code></a>.
</p>
<p>
I have been working on it for the past few weeks, and I think that a CRAN release could happen soon.
</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">
Introduction
</h2>
<p>
So what does <code>{chronicler}</code> do? <code>{chronicler}</code> allows you do decorate functions, so that they provide enhanced output:
</p>
<pre class="r"><code>library(chronicler)</code></pre>
<pre><code>## Loading required package: rlang</code></pre>
<pre class="r"><code>r_sqrt &lt;- record(sqrt)

a &lt;- r_sqrt(1:5)</code></pre>
<p>
Object <code>a</code> is now an object of class <code>chronicle</code>. Let’s print <code>a</code> to the terminal:
</p>
<pre class="r"><code>a</code></pre>
<pre><code>## ✔ Value computed successfully:
## ---------------
## [1] 1.000000 1.414214 1.732051 2.000000 2.236068
## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, "value").
## To read the log of this object, call read_log().</code></pre>
<p>
as the output says, <code>a</code> is an object of type <code>chronicle</code>. Let’s use <code>read_log()</code> as suggested:
</p>
<pre class="r"><code>read_log(a)</code></pre>
<pre><code>## [1] "Complete log:"                                      
## [2] "✔ sqrt(1:5) ran successfully at 2022-04-01 21:14:28"
## [3] "Total running time: 0.000240325927734375 secs"</code></pre>
<p>
The log tells us how <code>a</code> was built, and it’s especially useful for objects that are the result of many function calls:
</p>
<pre class="r"><code>r_sqrt &lt;- record(sqrt)
r_exp &lt;- record(exp)
r_mean &lt;- record(mean)

b &lt;- 1:10 |&gt;
  r_sqrt() |&gt;
  bind_record(r_exp) |&gt;
  bind_record(r_mean)</code></pre>
<p>
The log gives all the details:
</p>
<pre class="r"><code>read_log(b)</code></pre>
<pre><code>## [1] "Complete log:"                                           
## [2] "✔ sqrt(1:10) ran successfully at 2022-04-01 21:14:28"    
## [3] "✔ exp(.c$value) ran successfully at 2022-04-01 21:14:28" 
## [4] "✔ mean(.c$value) ran successfully at 2022-04-01 21:14:28"
## [5] "Total running time: 0.00820255279541016 secs"</code></pre>
<p>
The end result, or what is called <code>value</code> can be obtained using <code>pick()</code> (you could also use <code>a$value</code>):
</p>
<pre class="r"><code>pick(a, "value")</code></pre>
<pre><code>## [1] 1.000000 1.414214 1.732051 2.000000 2.236068</code></pre>
<pre class="r"><code>pick(b, "value")</code></pre>
<pre><code>## [1] 11.55345</code></pre>
</section>
<section id="composing-decorated-functions" class="level2">
<h2 class="anchored" data-anchor-id="composing-decorated-functions">
Composing decorated functions
</h2>
<p>
<code>bind_record()</code> is used to pass the output from one decorated function to the next:
</p>
<pre class="r"><code>suppressPackageStartupMessages(
  library(dplyr)
)

r_group_by &lt;- record(group_by)
r_select &lt;- record(select)
r_summarise &lt;- record(summarise)
r_filter &lt;- record(filter)

output &lt;- starwars %&gt;%
  r_select(height, mass, species, sex) %&gt;%
  bind_record(r_group_by, species, sex) %&gt;%
  bind_record(r_filter, sex != "male") %&gt;%
  bind_record(r_summarise,
              mass = mean(mass, na.rm = TRUE)
              )</code></pre>
<pre class="r"><code>read_log(output)</code></pre>
<pre><code>## [1] "Complete log:"                                                                         
## [2] "✔ select(.,height,mass,species,sex) ran successfully at 2022-04-01 21:14:28"           
## [3] "✔ group_by(.c$value,species,sex) ran successfully at 2022-04-01 21:14:28"              
## [4] "✔ filter(.c$value,sex != \"male\") ran successfully at 2022-04-01 21:14:28"            
## [5] "✔ summarise(.c$value,mean(mass, na.rm = TRUE)) ran successfully at 2022-04-01 21:14:28"
## [6] "Total running time: 0.11384654045105 secs"</code></pre>
<p>
The value can then be saved in a new variable:
</p>
<pre class="r"><code>(my_df &lt;- pick(output, "value"))</code></pre>
<pre><code>## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi'lek    female           55</code></pre>
<p>
You can save the <code>output</code> object with <code>saveRDS()</code> and share it; your colleague can then read the log to learn how the object was created.
</p>
<p>
This package also ships with a dedicated pipe, <code>%&gt;=%</code> which you can use instead of <code>bind_record()</code>:
</p>
<pre class="r"><code>output_pipe &lt;- starwars %&gt;%
  r_select(height, mass, species, sex) %&gt;=%
  r_group_by(species, sex) %&gt;=%
  r_filter(sex != "male") %&gt;=%
  r_summarise(mass = mean(mass, na.rm = TRUE))</code></pre>
<pre class="r"><code>pick(output_pipe, "value")</code></pre>
<pre><code>## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi'lek    female           55</code></pre>
</section>
<section id="condition-handling" class="level2">
<h2 class="anchored" data-anchor-id="condition-handling">
Condition handling
</h2>
<p>
By default, errors and warnings get caught and composed in the log:
</p>
<pre class="r"><code>errord_output &lt;- starwars %&gt;%
  r_select(height, mass, species, sex) %&gt;=%
  r_group_by(species, sx) %&gt;=% # typo, "sx" instead of "sex"
  r_filter(sex != "male") %&gt;=%
  r_summarise(mass = mean(mass, na.rm = TRUE))</code></pre>
<pre class="r"><code>errord_output</code></pre>
<pre><code>## ✖ Value computed unsuccessfully:
## ---------------
## [1] NA
## 
## ---------------
## This is an object of type `chronicle`.
## Retrieve the value of this object with pick(.c, "value").
## To read the log of this object, call read_log().</code></pre>
<p>
Reading the log tells you which function failed, and with which error message:
</p>
<pre class="r"><code>read_log(errord_output)</code></pre>
<pre><code>## [1] "Complete log:"                                                                                                                                                                                    
## [2] "✔ select(.,height,mass,species,sex) ran successfully at 2022-04-01 21:14:28"                                                                                                                      
## [3] "✖ group_by(.c$value,species,sx) ran unsuccessfully with following exception: Must group by variables found in `.data`.\n✖ Column `sx` is not found. at 2022-04-01 21:14:28"                       
## [4] "✖ filter(.c$value,sex != \"male\") ran unsuccessfully with following exception: no applicable method for 'filter' applied to an object of class \"logical\" at 2022-04-01 21:14:28"               
## [5] "✖ summarise(.c$value,mean(mass, na.rm = TRUE)) ran unsuccessfully with following exception: no applicable method for 'summarise' applied to an object of class \"logical\" at 2022-04-01 21:14:28"
## [6] "Total running time: 0.163575887680054 secs"</code></pre>
<p>
It is also possible to only capture errors, or catpure errors, warnings and messages using the <code>strict</code> parameter of <code>record()</code>
</p>
<pre class="r"><code># Only errors:

r_sqrt &lt;- record(sqrt, strict = 1)

# Nothing will be captured here, since sqrt(-10) returns a NA and a warning
r_sqrt(-10) |&gt;
  read_log()</code></pre>
<pre><code>## Warning in .f(...): NaNs produced</code></pre>
<pre><code>## [1] "Complete log:"                                                                     
## [2] "✖ sqrt(-10) ran unsuccessfully with following exception: NA at 2022-04-01 21:14:28"
## [3] "Total running time: 0.000255584716796875 secs"</code></pre>
<pre class="r"><code># Errors and warnings:

r_sqrt &lt;- record(sqrt, strict = 2)

# The warning gets captured
r_sqrt(-10) |&gt;
  read_log()</code></pre>
<pre><code>## [1] "Complete log:"                                                                                
## [2] "✖ sqrt(-10) ran unsuccessfully with following exception: NaNs produced at 2022-04-01 21:14:28"
## [3] "Total running time: 0.00019383430480957 secs"</code></pre>
<pre class="r"><code># Errors, warnings and messages

my_f &lt;- function(x){
  message("this is a message")
  10
}

record(my_f, strict = 3)(10) |&gt;
                         read_log()</code></pre>
<pre><code>## [1] "Complete log:"                                                                                     
## [2] "✖ my_f(10) ran unsuccessfully with following exception: this is a message\n at 2022-04-01 21:14:28"
## [3] "Total running time: 0.000336408615112305 secs"</code></pre>
</section>
<section id="advanced-logging" class="level2">
<h2 class="anchored" data-anchor-id="advanced-logging">
Advanced logging
</h2>
<p>
You can provide a function to <code>record()</code>, which will be evaluated on the output. This makes it possible to, for example, monitor the size of a data frame throughout the pipeline. In the example below I provide <code>dim()</code>, which will return the dimensions of the data frame, as an argument to <code>record()</code>:
</p>
<pre class="r"><code>r_group_by &lt;- record(group_by)
r_select &lt;- record(select, .g = dim)
r_summarise &lt;- record(summarise, .g = dim)
r_filter &lt;- record(filter, .g = dim)

output_pipe &lt;- starwars %&gt;%
  r_select(height, mass, species, sex) %&gt;=%
  r_group_by(species, sex) %&gt;=%
  r_filter(sex != "male") %&gt;=%
  r_summarise(mass = mean(mass, na.rm = TRUE))</code></pre>
<p>
The <code>$log_df</code> element of a <code>chronicle</code> object contains detailed information. In most cases you don’t need to worry about it:
</p>
<pre class="r"><code>pick(output_pipe, "log_df")</code></pre>
<pre><code>## # A tibble: 4 × 8
##   outcome   `function` arguments message start_time          end_time           
##   &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;   &lt;dttm&gt;              &lt;dttm&gt;             
## 1 ✔ Success select     ".,heigh… NA      2022-04-01 21:14:28 2022-04-01 21:14:28
## 2 ✔ Success group_by   ".c$valu… NA      2022-04-01 21:14:28 2022-04-01 21:14:28
## 3 ✔ Success filter     ".c$valu… NA      2022-04-01 21:14:28 2022-04-01 21:14:29
## 4 ✔ Success summarise  ".c$valu… NA      2022-04-01 21:14:28 2022-04-01 21:14:29
## # … with 2 more variables: run_time &lt;drtn&gt;, g &lt;list&gt;</code></pre>
<p>
but if you want to look at the output of <code>.g</code>, then you have to grab it and see:
</p>
<pre class="r"><code># I coerce it to a data.frame just for the output here on my blog, to make the column `g` readable
as.data.frame(output_pipe$log_df[, c("function", "g")])</code></pre>
<pre><code>##    function     g
## 1    select 87, 4
## 2  group_by    NA
## 3    filter 23, 4
## 4 summarise  9, 3</code></pre>
<p>
We can see that the dimension of the dataframe was (87, 4) after the call to <code>select()</code>, (23, 4) after the call to <code>filter()</code> and finally (9, 3) after the call to <code>summarise()</code>.
</p>
</section>
<section id="monads" class="level2">
<h2 class="anchored" data-anchor-id="monads">
Monads
</h2>
<p>
This package implements a logger monad. I might talk about monads in the future, but probably in a video; if you don’t know what monads are, don’t worry, no one really knows. Legend has it that to truly understand what monads are you have to have a PhD in computer science and have been born in the former Soviet Union. But to make things simple, you can think of a monad as a way to:
</p>
<ul>
<li>
embelish functions to provide additional output without having to touch the function’s core behaviour
</li>
<li>
a way to compose these functions and work with the embelished outputs (also called monadic values)
</li>
<li>
monadic values are basically containers that contain the actual value of the function evaluated on its inputs and something else (here, a log)
</li>
</ul>
<p>
Monads are quite useful in some programming languanges, like Haskell. Not so much in R, but I think that the logger monad I propose here can be quite useful. So let me know if you find it useful or if you have suggestions!
</p>
<p>
You can install <code>{chronicler}</code> from its <a href="https://github.com/b-rodrigues/chronicler">github repo</a>.
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-04-04-chron_post.html</guid>
  <pubDate>Fri, 01 Apr 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Capture errors, warnings and messages</title>
  <link>https://b-rodrigues.github.io/posts/2022-03-12-purely.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://www.youtube.com/watch?v=vUvut7jOPgs"> <img src="https://b-rodrigues.github.io/assets/img/pure.jpg" title="Hell is side effects" width="80%" height="auto"></a>
</p>
</div>
<p>
In my <a href="https://www.youtube.com/watch?v=vUvut7jOPgs">last video</a> I tried to add a feature to my {loud} package (more info <a href="https://b-rodrigues.github.io/loud/">here</a>) and I succeeded. But in succeeding in realised that I would need to write a bit more code than what I expected. To make a long story short: it is possible to capture errors using <code>purrr::safely()</code>:
</p>
<pre class="r"><code>library(purrr)
safe_log &lt;- safely(log)

a &lt;- safe_log("10")

str(a)</code></pre>
<pre><code>## List of 2
##  $ result: NULL
##  $ error :List of 2
##   ..$ message: chr "non-numeric argument to mathematical function"
##   ..$ call   : language .Primitive("log")(x, base)
##   ..- attr(*, "class")= chr [1:3] "simpleError" "error" "condition"</code></pre>
<p>
<code>a</code> is now a list with elements <code>$result</code> and <code>$error</code>. If everything goes right, <code>$result</code> holds the result of the operation, and if everything goes wrong, <code>$result</code> is <code>NULL</code> but <code>$error</code> now contains the error message. This is especially useful in non-interactive contexts. There is another similar function in <code>{purrr}</code> called <code>quietly()</code>, which captures warnings and messages:
</p>
<pre class="r"><code>quiet_log &lt;- quietly(log)

b &lt;- quiet_log(-10)

str(b)</code></pre>
<pre><code>## List of 4
##  $ result  : num NaN
##  $ output  : chr ""
##  $ warnings: chr "NaNs produced"
##  $ messages: chr(0)</code></pre>
<p>
as you can see, providing a negative number to <code>log()</code> does not cause an error, but simply a warning. A result of <code>NaN</code> is returned (you can try with <code>log(-10)</code> in your console). <code>quietly()</code> captures the warning message and returns a list of 4 elements, <code>$result</code>, <code>$output</code>, <code>$warnings</code> and <code>$messages</code>. The problem here, is that:
</p>
<pre class="r"><code>safe_log(-10)</code></pre>
<pre><code>## Warning in .Primitive("log")(x, base): NaNs produced</code></pre>
<pre><code>## $result
## [1] NaN
## 
## $error
## NULL</code></pre>
<p>
returns something useless: <code>$result</code> is <code>NaN</code> (because that’s what <code>log()</code> returns for negative numbers) but <code>$error</code> is <code>NULL</code> since no error was thrown, but only a warning! We have a similar problem with <code>quiet_log()</code>:
</p>
<pre class="r"><code>quiet_log("10")</code></pre>
<pre><code>Error in .Primitive("log")(x, base) : 
  non-numeric argument to mathematical function</code></pre>
<p>
here, the error message is thrown, but not captured, since <code>quietly()</code> does not capture error messages.
</p>
<p>
So, are we back to square one? Not necessarily, since you could compose both functions:
</p>
<pre class="r"><code>pure_log &lt;- quietly(safely(log))

a2 &lt;- pure_log(-10)

str(a2)</code></pre>
<pre><code>## List of 4
##  $ result  :List of 2
##   ..$ result: num NaN
##   ..$ error : NULL
##  $ output  : chr ""
##  $ warnings: chr "NaNs produced"
##  $ messages: chr(0)</code></pre>
<pre class="r"><code>b2 &lt;- pure_log("10")

str(b2)</code></pre>
<pre><code>## List of 4
##  $ result  :List of 2
##   ..$ result: NULL
##   ..$ error :List of 2
##   .. ..$ message: chr "non-numeric argument to mathematical function"
##   .. ..$ call   : language .Primitive("log")(x, base)
##   .. ..- attr(*, "class")= chr [1:3] "simpleError" "error" "condition"
##  $ output  : chr ""
##  $ warnings: chr(0) 
##  $ messages: chr(0)</code></pre>
<p>
As you can see, in the case of <code>a2</code>, the warning was captured, and in the case of <code>b2</code> the error was captured. The problem, is that the resulting object is quite complex. It’s a list where <code>$result</code> is itself a list in case of a warning, or <code>$error</code> is a list in case of an error.
</p>
<p>
I tried to write a function that would decorate a function (as do <code>safely()</code> and <code>quietly()</code>), which in turn would then return a simple list and capture, errors, warnings and messages. I came up with this code, after re-reading <em>Advanced R</em>, in particular this <a href="https://adv-r.hadley.nz/conditions.html">chapter</a>:
</p>
<pre class="r"><code>purely &lt;- function(.f){

  function(..., .log = "Log start..."){

    res &lt;- rlang::try_fetch(
                    rlang::eval_bare(.f(...)),
                    error = function(err) err,
                    #rlang_error = function(rlerr) rlerr,
                    warning = function(warn) warn,
                    message = function(message) message,
                    )

    final_result &lt;- list(
      result = NULL,
      log = NULL
    )

    final_result$result &lt;- if(any(c("error", "rlang_error", "warning", "message") %in% class(res))){
                             NA
                           } else {
                             res
                           }

    final_result$log &lt;- if(any(c("error", "rlang_error", "warning", "message") %in% class(res))){
                          #res$message
                          purrr::pluck(res, "message", .default = "undefined error")
                        } else {
                          NA
                        }
    final_result
  }
}</code></pre>
<pre class="r"><code>f_m &lt;- function(x){
  message("this is a message")
  str(x)
}

f_w &lt;- function(x){
  warning("this is a warning")
  str(x)

}

f_e &lt;- function(){
  stop("This is an error")

}

pure_fm &lt;- purely(f_m)
pure_fw &lt;- purely(f_w)
pure_fe &lt;- purely(f_e)</code></pre>
<p>
Messages get captured:
</p>
<pre class="r"><code>pure_fm(10) |&gt;
  str()</code></pre>
<pre><code>## List of 2
##  $ result: logi NA
##  $ log   : chr "this is a message\n"</code></pre>
<p>
as do warnings:
</p>
<pre class="r"><code>pure_fw(10) |&gt;
  str()</code></pre>
<pre><code>## List of 2
##  $ result: logi NA
##  $ log   : chr "this is a warning"</code></pre>
<p>
as do errors:
</p>
<pre class="r"><code>pure_fe() |&gt;
  str()</code></pre>
<pre><code>## List of 2
##  $ result: logi NA
##  $ log   : chr "This is an error"</code></pre>
<p>
The structure of the result is always <code>$result</code> and <code>$log</code>. In case everything goes well <code>$result</code> holds the result:
</p>
<pre class="r"><code>pure_log &lt;- purely(log)

pure_log(c(1,10))</code></pre>
<pre><code>## $result
## [1] 0.000000 2.302585
## 
## $log
## [1] NA</code></pre>
<p>
And another example, with a more complex call:
</p>
<pre class="r"><code>pure_mean &lt;- purely(mean)

pure_mean(c(1,10, NA), na.rm = TRUE)</code></pre>
<pre><code>## $result
## [1] 5.5
## 
## $log
## [1] NA</code></pre>
<p>
But in case something goes wrong, the error message will get captured.
</p>
<pre class="r"><code>suppressPackageStartupMessages(library(dplyr))</code></pre>
<pre><code>## {paint} masked print.tbl_df</code></pre>
<pre class="r"><code>pure_select &lt;- purely(select)</code></pre>
<p>
Let’s try here to select a column that does not exist:
</p>
<pre class="r"><code>clean_mtcars &lt;- mtcars %&gt;%
  pure_select(hp, am, bm) #bm does not exist

str(clean_mtcars)</code></pre>
<pre><code>## List of 2
##  $ result: logi NA
##  $ log   : chr ""</code></pre>
<p>
Compare to what happens with <code>select()</code>:
</p>
<pre class="r"><code>clean_mtcars2 &lt;- mtcars %&gt;%
  select(hp, am, bm) #bm does not exist</code></pre>
<pre><code>Error in `select()`:
! Can't subset columns that don't exist.
✖ Column `bm` doesn't exist.
Backtrace:
  1. mtcars %&gt;% select(hp, am, bm)
...
...</code></pre>
<section id="update-2022-03-13" class="level2">
<h2 class="anchored" data-anchor-id="update-2022-03-13">
Update 2022-03-13
</h2>
<p>
After writing this post I realised that the error message of select does not get captured. This is the only example I’ve found where the error message does not get caught. This seems to be related to the fact that tidyverse function have their own class of error messages that inherit from <code>error</code>. For some reason, there are no issues with other functions, for example:
</p>
<pre class="r"><code>purely(group_by)(mtcars, bm)</code></pre>
<pre><code>## $result
## [1] NA
## 
## $log
##                                             
## "Must group by variables found in `.data`."</code></pre>
<p>
I will need to solve this…
</p>
</section>
<section id="post-continued" class="level2">
<h2 class="anchored" data-anchor-id="post-continued">
Post continued…
</h2>
<p>
The code (and thus the pipeline) completely fails! I’ve added this function to my <a href="https://b-rodrigues.github.io/loud/">{loud}</a> package, but the biggest benefit of all this is that the main function of the package, <code>loudly()</code> now uses <code>purely()</code> under the hood to provide more useful log messages in case of failure:
</p>
<pre class="r"><code>suppressPackageStartupMessages(library(loud))

loud_sqrt &lt;- loudly(sqrt)
loud_mean &lt;- loudly(mean)
loud_exp &lt;- loudly(exp)


result_pipe &lt;- -1:-10 |&gt;
  loud_mean() %&gt;=% # This results in a negative number...
  loud_sqrt() %&gt;=% # which sqrt() does not know how to handle
  loud_exp()</code></pre>
<p>
If we now inspect <code>result_pipe</code>, we find a complete log of what went wrong:
</p>
<pre class="r"><code>result_pipe</code></pre>
<pre><code>## $result
## NULL
## 
## $log
## [1] "Log start..."                                                                                                                                                            
## [2] "✔ mean(-1:-10) started at 2022-03-13 14:17:30 and ended at 2022-03-13 14:17:30"                                                                                          
## [3] "✖ CAUTION - ERROR: sqrt(.l$result) started at 2022-03-13 14:17:30 and failed at 2022-03-13 14:17:30 with following message: NaNs produced"                               
## [4] "✖ CAUTION - ERROR: exp(.l$result) started at 2022-03-13 14:17:30 and failed at 2022-03-13 14:17:30 with following message: non-numeric argument to mathematical function"</code></pre>
<p>
If you want to know more about <code>{loud}</code>, I suggest you read <a href="../posts/2022-02-18-loudly.html">my previous blog post</a> and if you need a more realistic example, take a look at <a href="https://b-rodrigues.github.io/loud/articles/real-world-example.html">this</a>.
</p>
<p>
If you try it, please let me know!
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-03-12-purely.html</guid>
  <pubDate>Sat, 12 Mar 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Add logging to your functions using my newest package {loud}</title>
  <link>https://b-rodrigues.github.io/posts/2022-02-18-loudly.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ"> <img src="https://b-rodrigues.github.io/assets/img/tuba.jpg" title="I have nothing to add" width="80%" height="auto"></a>
</p>
</div>
<section id="update-loud-has-been-superseded-by-chronicle-read-about-it-here" class="level2">
<h2 class="anchored" data-anchor-id="update-loud-has-been-superseded-by-chronicle-read-about-it-here">
UPDATE: {loud} has been superseded by {chronicle}, read about it <a href="../posts/2022-04-04-chron_post.html">here</a>
</h2>
<p>
This is a short blog post to announce the early alpha, hyper unstable, use at your own peril, package I’ve been working on for the past 6 hours or so (actually longer if I add all the research/study time). This package provides the function <code>loudly()</code> which allows you to do cool stuff like:
</p>
<pre class="r"><code># First two lines install the package
# install.packages("devtools")
# devtools::install_github("b-rodrigues/loud")
library(loud)</code></pre>
<pre><code>## Loading required package: rlang</code></pre>
<pre class="r"><code>loud_sqrt &lt;- loudly(sqrt)

loud_sqrt(1:10)</code></pre>
<pre><code>## $result
##  [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427
##  [9] 3.000000 3.162278
## 
## $log
## [1] "Log start..."                                                                
## [2] "✔ sqrt(1:10) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"</code></pre>
<p>
As you can see, I start by applying <code>loudly()</code> to a function, and then I can use this function as usual. Not only do I get the result, but also a logging message telling me which function and which arguments got used, and when the computation started and ended.
</p>
<p>
It is also possible to chain operations:
</p>
<pre class="r"><code>loud_sqrt &lt;- loudly(sqrt)
loud_exp &lt;- loudly(exp)
loud_mean &lt;- loudly(mean)

1:10 |&gt;
  loud_sqrt() |&gt;
  bind_loudly(loud_exp) |&gt;
  bind_loudly(loud_mean)</code></pre>
<pre><code>## $result
## [1] 11.55345
## 
## $log
## [1] "Log start..."                                                                     
## [2] "✔ sqrt(1:10) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"     
## [3] "✔ exp(.l$result) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00" 
## [4] "✔ mean(.l$result) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"</code></pre>
<p>
You’ll notice that here I have to use another function called <code>bind_loudly()</code>. The reason is because <em>loud</em> functions return a list. The first element of that list is the result of the function applied to the inputs, and the second element is the log message. So <code>bind_loudly()</code> passes the first element of the output of <code>loud_sqrt()</code> to the actual function <code>exp()</code> and also passes the second element, this time the log message, to the part of the function that concatenates the log messages.
</p>
<p>
This works with any function:
</p>
<pre class="r"><code>library(dplyr)</code></pre>
<pre class="r"><code>loud_group_by &lt;- loudly(group_by)
loud_select &lt;- loudly(select)
loud_summarise &lt;- loudly(summarise)
loud_filter &lt;- loudly(filter)

starwars %&gt;%
  loud_select(height, mass, species, sex) %&gt;%
  bind_loudly(loud_group_by, species, sex) %&gt;%
  bind_loudly(loud_filter, sex != "male") %&gt;%
  bind_loudly(loud_summarise,
              mass = mean(mass, na.rm = TRUE)
              )</code></pre>
<pre><code>## $result
## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi'lek    female           55  
## 
## $log
## [1] "Log start..."                                                                                                   
## [2] "✔ select(.,height,mass,species,sex) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"            
## [3] "✔ group_by(.l$result,species,sex) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"              
## [4] "✔ filter(.l$result,sex != \"male\") started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"            
## [5] "✔ summarise(.l$result,mean(mass, na.rm = TRUE)) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"</code></pre>
<p>
This is not perfect however. You’ll notice that the last log message states:
</p>
<pre><code>summarise(.l$result,mean(mass, na.rm = TRUE)) ....</code></pre>
<p>
ideally I would like for it to say:
</p>
<pre><code>summarise(.l$result,mass = mean(mass, na.rm = TRUE)) ....</code></pre>
<p>
Also, I’ve added a pipe operator so you don’t need to use <code>bind_loudly()</code> if you don’t want to:
</p>
<pre class="r"><code>1:10 |&gt;
  loud_sqrt() %&gt;=%
  loud_exp() %&gt;=%
  loud_mean()</code></pre>
<pre><code>## $result
## [1] 11.55345
## 
## $log
## [1] "Log start..."                                                                     
## [2] "✔ sqrt(1:10) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"     
## [3] "✔ exp(.l$result) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00" 
## [4] "✔ mean(.l$result) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"</code></pre>
<p>
However, this operator does not work well with <code>{dplyr}</code> functions. See here:
</p>
<pre class="r"><code>starwars %&gt;%
  loud_select(height, mass, species, sex) %&gt;=%
  loud_group_by(species, sex) %&gt;=%
  loud_filter(sex != "male") %&gt;=%
  loud_summarise(mass = mean(mass, na.rm = TRUE))</code></pre>
<pre><code>## $result
## # A tibble: 9 × 3
## # Groups:   species [9]
##   species    sex              mass
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;
## 1 Clawdite   female           55  
## 2 Droid      none             69.8
## 3 Human      female           56.3
## 4 Hutt       hermaphroditic 1358  
## 5 Kaminoan   female          NaN  
## 6 Mirialan   female           53.1
## 7 Tholothian female           50  
## 8 Togruta    female           57  
## 9 Twi'lek    female           55  
## 
## $log
## [1] "Log start..."                                                                                                   
## [2] "✔ select(.,height,mass,species,sex) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"            
## [3] "✔ group_by(.l$result,species,sex) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"              
## [4] "✔ filter(.l$result,sex != \"male\") started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"            
## [5] "✔ summarise(.l$result,mean(mass, na.rm = TRUE)) started at 2022-04-01 21:20:00 and ended at 2022-04-01 21:20:00"</code></pre>
<p>
If you look at the result, you’ll see that it is not equal to the obtained with <code>bind_loudly()</code>, and if you look at the last logging message you’ll see why. Instead of
</p>
<pre><code>summarise(.l$result,mean(mass, na.rm = TRUE)) ....</code></pre>
<p>
the message states:
</p>
<pre><code>summarise(.l$result,mass,TRUE) started at</code></pre>
<p>
I know where the problem is (it’s due to some regex fuckery) so I think that I should be able to correct this in the coming days. Ideally, in the future, I would also like for the users to provide their own log messages.
</p>
<p>
The package has a website with a vignette that shows another interesting example <a href="https://b-rodrigues.github.io/loud/articles/real-world-example.html">here</a>. Source code can be found <a href="https://github.com/b-rodrigues/loud">here</a>.
</p>
<p>
It is almost certain that function names will change, maybe even the package name itself. Contributions, bug reports, suggestions, etc, welcome of course.
</p>
<p>
A final word: this is the result of me exploring more advanced functional programming concepts and discussing with really nice people like <a href="https://twitter.com/ShinyD3js">Andrew R Mcneil</a>, <a href="https://twitter.com/kupac">Laszlo Kupcsik</a>. Andrew wrote a cool package called <a href="https://armcn.github.io/maybe/">maybe</a> and Laszlo a super cool blog post explaining what monads are <a href="https://kupac.gitlab.io/biofunctor/2019/05/25/maybe-monad-in-r/">here</a>.
</p>
<p>
I’ll be writing a blog post on monads, in particular the maybe monad soonish.
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2022-02-18-loudly.html</guid>
  <pubDate>Fri, 18 Feb 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How to write code that returns (Rmarkdown) code</title>
  <link>https://b-rodrigues.github.io/posts/2021-12-17-expand_knitr.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://en.wikipedia.org/wiki/Fractal"> <img src="https://b-rodrigues.github.io/assets/img/fractal_doge.gif" title="Nature is fractal"></a>
</p>
</div>
<p>
One of the most useful aspects of using a programming language instead of… well, not using a programming language, is that you can write code in a way that minimizes, and ideally, eliminates the need to repeat yourself.
</p>
<p>
For instance, you can write a function to show you a frequency table, like so:
</p>
<pre class="r"><code>suppressMessages(library(dplyr))

create_table &lt;- function(dataset, var){

  var &lt;- enquo(var)

  dataset %&gt;%
    count(!!var) %&gt;%
    knitr::kable()

}</code></pre>
<p>
And can now get some fancy looking tables by simply writing:
</p>
<pre class="r"><code>create_table(mtcars, cyl)</code></pre>
<table class="table">
<thead>
<tr class="header">
<th align="right">
cyl
</th>
<th align="right">
n
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">
4
</td>
<td align="right">
11
</td>
</tr>
<tr class="even">
<td align="right">
6
</td>
<td align="right">
7
</td>
</tr>
<tr class="odd">
<td align="right">
8
</td>
<td align="right">
14
</td>
</tr>
</tbody>
</table>
<p>
If I want such tables for hundreds of columns, I can use this function and loop over the columns and not have to write the code inside the body of the function over and over again. You’ll notice that the function <code>create_table()</code> makes use of some advanced programming techniques I have discussed <a href="https://www.brodrigues.co/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/">here</a>. There’s also an alternative way of programming with <code>{dplyr}</code>, using the <code>{{}}</code> construct I discussed <a href="https://www.brodrigues.co/blog/2019-06-20-tidy_eval_saga/">here</a>, but I couldn’t get what I’m going to show you here to work with <code>{{}}</code>.
</p>
<p>
Recently, I had to create a Rmarkdown document with many sections, where each section title was a question from a survey and the content was a frequency table. I wanted to write a fuction that would create a section with the right question title, and then show the table, and I wanted to then call this function over all the questions from the survey and have my document automatically generated.
</p>
<p>
The result should look like <a href="https://dazzling-thompson-964d5b.netlify.app/">this</a>, but it would be a PDF instead of HTML.
</p>
<p>
Let’s first load the data and see how it looks like:
</p>
<pre class="r"><code>library(dplyr)
library(purrr)
library(readr)

suppressMessages(
  survey_data &lt;- read_csv(
    "https://gist.githubusercontent.com/b-rodrigues/0c2249dec5a9c9477e0d1ad9964a1340/raw/873bcc7532b8bad613235f029884df1d0b947c90/survey_example.csv"
  )
)

glimpse(survey_data)</code></pre>
<pre><code>## Rows: 100
## Columns: 4
## $ `Random question?`                         &lt;chr&gt; "no", "yes", "yes", "yes", …
## $ `Copy of Random question?`                 &lt;chr&gt; "yes", "yes", "no", "yes", …
## $ `Copy of Copy of Random question?`         &lt;chr&gt; "yes", "no", "no", "yes", "…
## $ `Copy of Copy of Copy of Random question?` &lt;chr&gt; "yes", "yes", "no", "yes", …</code></pre>
<p>
Each column name is the question, and each row is one answer to the survey question. To create the document I showed above, you’d probably write something like this:
</p>
<pre><code>
## Random question?

` ``{r}

create_table(survey_data, `Random question?`)

` ``

## Copy of Random question?

` ``{r}

create_table(survey_data, `Copy of Random question?`)

` ``

## Copy of Copy of Random question?

` ``{r}

create_table(survey_data, `Copy of Copy of Random question?`)

` ``

## Copy of Copy of Copy of Random question?

` ``{r}

create_table(survey_data, `Copy of Copy of Copy of Random question?`)

` ``
</code></pre>
<p>
As you can see, this gets tedious very quickly, especially if you have 100’s of variables. So how to not repeat yourself? The solution has two steps; first you should try to automate what you have as much as possible. Ideally, you don’t want to have to write the complete question every time. So first, let’s replace the questions by simpler variable names:
</p>
<pre class="r"><code>questions &lt;- colnames(survey_data)

codes &lt;- paste0("var_", seq(1, length(questions)))

lookup &lt;- bind_cols("codes" = codes, "questions" = questions)

colnames(survey_data) &lt;- codes</code></pre>
<p>
<code>lookup</code> is a data frame with the questions and their respective codes:
</p>
<pre class="r"><code>lookup</code></pre>
<pre><code>## tibble [4, 2] 
## codes     chr var_1 var_2 var_3 var_4
## questions chr Random question? Copy of Random question? Cop~</code></pre>
<p>
and our data now has simpler variable names:
</p>
<pre class="r"><code>glimpse(survey_data)</code></pre>
<pre><code>## Rows: 100
## Columns: 4
## $ var_1 &lt;chr&gt; "no", "yes", "yes", "yes", "no", NA, "no", NA, "no", "no", "no",…
## $ var_2 &lt;chr&gt; "yes", "yes", "no", "yes", "no", "yes", "yes", NA, "yes", NA, "n…
## $ var_3 &lt;chr&gt; "yes", "no", "no", "yes", "yes", "no", "no", "yes", "no", "yes",…
## $ var_4 &lt;chr&gt; "yes", "yes", "no", "yes", "yes", "no", "no", "yes", "no", "no",…</code></pre>
<p>
Doing this allows us to replace the source code of our Rmarkdown like so:
</p>
<pre class="r"><code>## `r lookup$questions[grepl("var_1", lookup$codes)]`

`&nbsp;``{r}
create_table(survey_data, var_1)
`&nbsp;``</code></pre>
<p>
This already makes things easier, as now you only have to change <code>var_1</code> to <code>var_2</code> to <code>var_3</code>… the inline code gets executed and the right title (the question text) appears. But how to go further? I don’t want to have to copy and paste this and change <code>var_1</code> to <code>var_2</code> etc… So the second step of the two-step solution is to use a function called <code>knitr_expand()</code> described <a href="https://bookdown.org/yihui/rmarkdown-cookbook/knit-expand.html">here</a>. The idea of <code>knitr::knitr_expand()</code> is that it uses some Rmd source as a template, and also allows the user to define some variables that will be replaced at compile time. Simple examples are available <a href="https://cran.r-project.org/web/packages/knitr/vignettes/knit_expand.html">here</a>. I want to build upon that, because I need to pass my variable (in this case <code>var_1</code> for instance) to my function <code>create_table()</code>.
</p>
<p>
The solution is to write another function that uses <code>knitr::knitr_expand()</code>. This is how it could look like:
</p>
<pre class="r"><code>create_table &lt;- function(dataset, var){

  dataset %&gt;%
    count(!!var) %&gt;%
    knitr::kable()

}


return_section &lt;- function(var){

  a &lt;- knitr::knit_expand(text = c("## {{question}}",   create_table(survey_data, var)),
                          question =  lookup$questions[grepl(quo_name(var), lookup$codes)])

  cat(a, sep = "\n")
}</code></pre>
<p>
I needed to edit <code>create_table()</code> a little bit, and remove the line <code>var &lt;- enquo(var)</code>. This is because now, I won’t be passing a variable down to the function, but a quosure, and there is a very good reason for it, you’ll see. <code>return_section()</code> makes use of <code>knitr_expand()</code>, and the <code>text =</code> argument is the template that will get expanded. <code>{{question}}</code> will get replaced by the variable I defined which is the code I wrote above to automatically get the question text. Finally, <code>var</code> will get replaced by the variable I pass to the function.
</p>
<p>
First, let’s get it running on one single variable:
</p>
<pre class="r"><code>return_section(quo(var_1))</code></pre>
<pre><code>## ## Random question?
## |var_1 |  n|
## |:-----|--:|
## |no    | 40|
## |yes   | 44|
## |NA    | 16|</code></pre>
<p>
As you see, I had to use <code>quo(var_1)</code> and not only <code>var_1</code>. But apart from this, the function seems to work well. Putting this in an Rmarkdown document would create a section with the question as the text of the section and a frequency table as the body. I could now copy and paste this and only have to change <code>var_1</code>. But I don’t want to have to copy and paste! So the idea would be to loop the function over a list of variables.
</p>
<p>
I have such a list already:
</p>
<pre class="r"><code>codes</code></pre>
<pre><code>## [1] "var_1" "var_2" "var_3" "var_4"</code></pre>
<p>
But it’s not a list of quosures, but a list of strings, and this is not going to work (it will return an error):
</p>
<pre class="r"><code>walk(codes, return_section)</code></pre>
<p>
(I’m using <code>walk()</code> instead of <code>map()</code> because <code>return_section()</code> doesn’t return an object, but only shows something on screen. This is called a side effect, and <code>walk()</code> allows you to loop properly over functions that only return side effects).
</p>
<p>
The problem I have now is to convert strings to quosures. This is possible using <code>rlang::sym()</code>:
</p>
<pre class="r"><code>sym_codes &lt;- map(codes, sym)</code></pre>
<p>
And now I’m done:
</p>
<pre class="r"><code>walk(sym_codes, return_section)</code></pre>
<pre><code>## ## Random question?
## |var_1 |  n|
## |:-----|--:|
## |no    | 40|
## |yes   | 44|
## |NA    | 16|
## ## Copy of Random question?
## |var_2 |  n|
## |:-----|--:|
## |no    | 52|
## |yes   | 32|
## |NA    | 16|
## ## Copy of Copy of Random question?
## |var_3 |  n|
## |:-----|--:|
## |no    | 46|
## |yes   | 47|
## |NA    |  7|
## ## Copy of Copy of Copy of Random question?
## |var_4 |  n|
## |:-----|--:|
## |no    | 48|
## |yes   | 42|
## |NA    | 10|</code></pre>
<p>
Putting this in an Rmarkdown source create a PDF (or Word, or HTML) document with one section per question, and without have to do copy-pasting which is quite error-prone. Here is the final Rmarkdown <a href="https://gist.github.com/b-rodrigues/843011bb863f27a8fe7f299e13eb4491">file</a>. You’ll notice that the last chunk has the option <code>results = ‘asis’</code>, which is needed for this trick to work.
</p>



 ]]></description>
  <category>R</category>
  <category>programming</category>
  <guid>https://b-rodrigues.github.io/posts/2021-12-17-expand_knitr.html</guid>
  <pubDate>Fri, 17 Dec 2021 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Speedrunning row-oriented workflows</title>
  <link>https://b-rodrigues.github.io/posts/2021-09-05-speedrunning_rows.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://www.youtube.com/watch?v=1UkeFwJ-yHI"> <img src="https://b-rodrigues.github.io/assets/img/cringe_speedrun.png" title="Doom's first level in 8 seconds"></a>
</p>
</div>
<p>
<em>If you haven’t, you should read <a href="../posts/2021-09-04-quest_fast.html">this</a> first. This is part two.</em>
</p>
<p>
Speedrunning is the… hrm… - sport? art? - of playing games from start to finish as fast as possible. Speedrunning requires an insane amount of knowledge of the game being played, as well as an enourmous amount of skill. Also, contrary to what you might think, it is a community effort. Players do speedrun the game alone, and it is a ferocious competition, each one of them aiming for the top spot on the leaderboards. But discovering the strategies that will allow the top players to shave off, sometimes literally, hundredths of seconds from the previous world record require many, many, people from the speedrunning community trying to break the games in new ways, or testing how fast <em>theoretical</em> strategies using computers that play the game perfectly are (these type of speedruns are called TAS, for Tool Assisted Speedrun, and are a very important part of the speedrunning effort).
</p>
<p>
If you read until here, I commend you dear reader, and thank you for not having already closed the tab. The meat of the post is coming.
</p>
<p>
If you don’t know anything about speedrunning, I can only urge you to watch <a href="https://www.youtube.com/watch?v=7rIJNT7dCmE">this video</a> about the story of the Super Mario Bros.&nbsp;World Records. If you’re more into Doom, then watch <a href="https://www.youtube.com/watch?v=rqbc4nTivlg">this video</a> abut the history of Doom 2 World Records. It really is worth your time, believe me.
</p>
<p>
Anyways, why am I talking about this? What is the point of this blog post? Isn’t this a blog about <em>Econometrics and Free Software</em> (lol)?
</p>
<p>
The reason I’m talking about speedrunning in video games, is because my <a href="../posts/2021-09-04-quest_fast.html">previous blog post</a> sparked an interesting discussion on <a href="https://twitter.com/brodriguesco/status/1434076568649969665">twitter</a>, which very much reminded me of what you’d see in the speedrunning community.
</p>
<p>
Just like in speedrunning, I tried to play a game which consisted in running an arbitrary function over the rows of a data frame, and employed some basic strategies for it. As a reminder, here is the example code with the top two strategies: using <code>apply()</code> and a combination of <code>asplit()</code> and <code>map()</code> (I won’t be showing all the code here, it’s the same as in the <a href="https://www.brodrigues.co/blog/2021-09-04-quest_fast/">previous blog post</a>):
</p>
<pre class="r"><code>run_apply &lt;- function(dataset, my_function = my_function){

  dataset %&gt;%
    mutate(score = apply(., MARGIN = 1, my_function))

}

run_map &lt;- function(dataset, my_function = my_function){
  dataset %&gt;%
    mutate(score = map_dbl(asplit(., 1), .f = my_function))
}</code></pre>
<p>
Also, just as a reminder, here is the <code>rowwise()</code> approach:
</p>
<pre class="r"><code>run_rowwise &lt;- function(dataset, my_function = my_function){
  dataset %&gt;%
    rowwise() %&gt;%
    mutate(score = my_function(c_across(everything()))) %&gt;%
    ungroup()
}</code></pre>
<p>
This is, AFAIK, the <em>official</em> tidyverse-approach, but not the fastest. However, while it is slower than the two approaches above, it does have the advantage that you can run the function over the rows, but only by using certain columns instead of all of them. For example, to apply the function over only the columns that start with the letter “c” (and for each row), you could write this:
</p>
<pre class="r"><code>run_rowwise &lt;- function(dataset, my_function = my_function){
  dataset %&gt;%
    rowwise() %&gt;%
    mutate(score = my_function(c_across(starts_with("c")))) %&gt;%
    ungroup()
}</code></pre>
<p>
This is not possible with the two fast approaches, <code>run_map()</code> and <code>run_apply()</code>. These two approaches do run quite fast, but in the twitter discussion I linked above, many more suggestions were made, and some are likely faster, so let’s see! There’s first an approach using <code>pmap()</code> proposed by both <a href="https://twitter.com/lgaborini/status/1434138358381481989"><code><span class="citation" data-cites="lgaborini">@lgaborini</span></code></a> and <a href="https://twitter.com/JoeWasserman/status/1434175452457930755"><code>@</code>JoeWasserman</a>:
</p>
<pre class="r"><code>run_pmap &lt;- function(dataset, my_function = my_function){
  dataset %&gt;%
    mutate(score = pmap_dbl(., .f = lift_vd(my_function)))

}</code></pre>
<p>
I won’t go into the details here of how and why this works. For more details, <a href="https://github.com/jennybc/row-oriented-workflows/blob/master/ex09_row-summaries.md#how-to-use-an-arbitrary-function-inside-pmap">click here</a>. In any case, this does not run faster that the two approaches listed above. But it does run faster than using <code>rowwise()</code> and also allows for selecting columns over which to run the function:
</p>
<pre class="r"><code>run_pmap &lt;- function(dataset, my_function = my_function){
  dataset %&gt;%
    mutate(score = pmap_dbl(select(., matches(".(4|5|6)")), .f = lift_vd(mean)))

}

run_pmap(dataset) %&gt;%
  head</code></pre>
<pre><code>## # A tibble: 6 × 7
##       x1     x2     x3    x4    x5     x6 score
##    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 0.0644 0.789  0.489  0.665 0.664 0.230  0.520
## 2 0.771  0.209  0.443  0.248 0.756 0.0164 0.340
## 3 0.342  0.0382 0.619  0.196 0.115 0.783  0.365
## 4 0.638  0.915  0.0472 0.891 0.346 0.639  0.625
## 5 0.0366 0.601  0.426  0.421 0.835 0.906  0.721
## 6 0.0465 0.937  0.260  0.803 0.376 0.330  0.503</code></pre>
<p>
So this is quite useful!
</p>
<p>
There was another proposal, a pure base approach, by <a href="https://twitter.com/grant_mcdermott/status/1434278563994169344"><code><span class="citation" data-cites="grant_mcdermott">@grant_mcdermott</span></code></a>:
</p>
<pre class="r"><code>run_pure_base &lt;- function(dataset, my_function = my_function){
  dataset |&gt;
    within({score = sapply(asplit(dataset, 1), my_function)})
}</code></pre>
<p>
It even uses the new, shiny (haha), native pipe, |&gt;! I have not benchmarked this yet, as I’m writing this, so let’s see…
</p>
<p>
Finally, there is also a <code>{data.table}</code> approach, proposed by <a href="https://twitter.com/thatpinkney/status/1434289185532297219?s=20"><code><span class="citation" data-cites="thatpinkney">@thatpinkney</span></code></a>:
</p>
<pre class="r"><code>library(data.table)

run_dt2 &lt;- function(dataset, my_function = my_function){

  dataset &lt;- as.data.table(dataset)
  dataset[, rowid := .I]
  dataset[, ":=" (score = melt(dataset, id.vars = "rowid")[, my_function(value), by = rowid][, V1],
                  rowid = NULL)]

}</code></pre>
<p>
The problem of this approach, at least to me, is that I do not know <code>{data.table}</code>, which is the reason why I did not include it in the previous blog post. But I have read many times that <code>{data.table}</code> is blazing fast, so I definitely should learn at least some basics!
</p>
<p>
Now is benchmarking time. Let’s see (I’m not considering <code>run_pmap()</code>, because I already benchmarked it before writing this blog post, and know that it runs slower than the <code>run_map()</code> or <code>run_apply()</code>):
</p>
<pre class="r"><code>list_datasets &lt;- map(seq(2, 5), ~init_pop(objective_function = my_function,
                                          pop_size = `^`(10, .x)))


run_benchmarks &lt;- function(dataset, times = 5){
  microbenchmark::microbenchmark(
                    run_apply(dataset, my_function = my_function),
                    run_pure_base(dataset, my_function = my_function),
                    run_dt2(dataset, my_function = my_function),
                    run_map(dataset, my_function = my_function),
                    times = times,
                    unit = "s"
                  )
}</code></pre>
<pre class="r"><code>benchmark_results &lt;- map(list_datasets, run_benchmarks)

benchmark_data &lt;- map2(.x = benchmark_results, .y = 10^seq(2, 5), .f = ~mutate(tibble(.x), pop_size = .y)) %&gt;%
  bind_rows() %&gt;%
  mutate(expr = str_remove_all(expr, "\\(.*\\)")) %&gt;%
  group_by(expr, pop_size) %&gt;%
  mutate(time_seconds = time/10^9) %&gt;%
  summarise(fastest_run = min(time_seconds),
            average_run = mean(time_seconds),
            slowest_run = max(time_seconds))</code></pre>
<pre><code>## `summarise()` has grouped output by 'expr'. You can override using the `.groups` argument.</code></pre>
<pre class="r"><code>benchmark_data %&gt;%
  ggplot(aes(y = average_run, x = pop_size)) +
  geom_ribbon(aes(ymin = fastest_run, ymax = slowest_run, fill = expr), alpha = .6) +
  geom_line(aes(group = expr, col = expr)) +
  ylab("Seconds") +
  xlab("Rows in the dataset") +
  ggtitle("Speed of rowwise operations using different methods") +
  theme_blog()</code></pre>
<p>
<img src="https://b-rodrigues.github.io/assets/img/speedrunning_rows-13-1.png" width="672">
</p>
<p>
These are really interesting results! The <em>pure</em> base solution runs almost as fast as the one that uses <code>asplit()</code> and <code>map()</code>. The one that uses <code>apply()</code> only is a close second, but all these strategies get obliterated by the <code>{data.table}</code> solution!
</p>
<p>
So, what have we learned?
</p>
<ul>
<li>
First of all, the #RStats community is really great! I’m really blown away by the interest that my previous blog post generated and by the very interesting discussion that ensued.
</li>
<li>
Second, if speed is really paramount to solving your problem, you’d probably want to use <code>{data.table}</code>. It does seem to be incredibly fast!
</li>
<li>
Third, and final point, if you need to run rowwise operations, but only over certain columns, use <code>pmap()</code> instead of <code>rowwise()</code> - <code>across()</code> - <code>everything()</code>.
</li>
</ul>



 ]]></description>
  <category>R</category>
  <category>programming</category>
  <guid>https://b-rodrigues.github.io/posts/2021-09-05-speedrunning_rows.html</guid>
  <pubDate>Sun, 05 Sep 2021 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
