<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Econometrics and Free Software</title>
<link>https://b-rodrigues.github.io/</link>
<atom:link href="https://b-rodrigues.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.6.37</generator>
<lastBuildDate>Mon, 17 Feb 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Why we forked nixpkgs</title>
  <link>https://b-rodrigues.github.io/posts/2025-02-17-rstats-on-nix.html</link>
  <description><![CDATA[ 




<div style="text-align: center;">
<p>
<a> <img src="https://b-rodrigues.github.io/assets/img/fork.webp" style="width: 50%; height: auto;"> </a>
</p>
</div>
<section id="heres-why" class="level2">
<h2 class="anchored" data-anchor-id="heres-why">Here’s why</h2>
<p><code>nixpkgs</code> is a GitHub repository that contains tens of thousands of Nix expressions used by the Nix package manager to install software. By default, the nix package manager will pull expressions from <code>NixOS/nixpkgs</code>, but when using <code>{rix}</code> our fork <code>rstats-on-nix/nixpkgs</code> is used instead.</p>
<p>Because forks can sometimes be a bit controversial, we decided a blog post was in order.</p>
<p>First of all, let’s make something clear: this doesn’t mean that we don’t contribute to upstream anymore, quite the contrary. But Nix is first and foremost the package manager of a Linux distribution, NixOS, and as such, the way it does certain things only make sense in that context. For our needs, having a fork gives us more flexibility. Let me explain.</p>
<p>As you’ll know, if you’ve been using <code>{rix}</code> and thus Nix, it is possible to use a commit of the <code>nixpkgs</code> GitHub repository as the source for your packages. For example, the <code>6a9bda32519e710a0c0ab8ecfabe9307ab90ef0c</code> commit of <code>nixpkgs</code> will provide <code>{dplyr}</code> version 1.1.4 while this commit <code>407f8825b321617a38b86a4d9be11fd76d513da2</code> will provide version 1.0.7.</p>
<p>While it is technically possible for Nix to provide many versions of the same package (for example, you can install the latest Emacs by installing the <code>emacs</code> package, or Emacs 28 by installing <code>emacs28</code>) this ultimately depends on whether the maintainer wishes to do so, or whether it is practical. As you can imagine, with more than 20’000 CRAN and Bioconductor packages, that is not possible for us (by “us”, I mean the maintainers of the R ecosystem for Nix). So for a given <code>nixpkgs</code> commit, you won’t be able to <em>easily</em> install a specific version of <code>{dplyr}</code> that is not included in that particular <code>nixpkgs</code> commit. Instead, you can install it from source, and this is possible with <code>{rix}</code> by writing something like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rix</span>(..., <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">r_pkgs =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dplyr@1.0.7"</span>, ...)</span></code></pre></div>
</div>
<p>but because this attempts to install the package from source, it can fail if that package needs Nix-specific fixes to work.</p>
<p>Also, it isn’t practical to update the whole of the R packages set on Nix every day: so while CRAN and Bioconductor get updates daily, the R packages set on Nix gets updated only around new releases of R. Again, this is a consequence of Nix being first and foremost the package manager of a Linux distribution with its own governance and way of doing things.</p>
<p>This is where the <code>rstats-on-nix</code> fork of <code>nixpkgs</code> is interesting: because it is a fork, we can afford to do things in a way that could not be possible or practical for upstream.</p>
<p>The first thing this fork allows us to do is offer a daily snapshot of CRAN. Every day, thanks to Github Actions, the R packages set gets updated, and the result commited to a dated branch. This has been going on since the 14th of December 2024 (see <a href="https://github.com/rstats-on-nix/nixpkgs/tree/2024-12-14">here</a>). So when you set a date as in <code>rix(date = "2024-12-14", ...)</code> this the fork that is going to get used. But this doesn’t mean that we recommend you use any date from the <code>rstats-on-nix/nixpkgs</code> fork: instead, each Monday, another action uses this fork and tries to build a set of popular packages on Linux and macOS, and only if this succeeds is the date added through a PR to the list of available dates on <code>{rix}</code>!</p>
<p>The reason this is done like this is to manage another <em>risk</em> of the upstream <code>nixpkgs</code>. As you know, <code>nixpkgs</code> is huge, and though the utmost care is taken by contributors and the PR review process is very strict, it can happen that updating packages breaks other packages. For example recently RStudio was in a broken state due to an issue in one its dependencies, <code>boost</code>. This is not the fault of anyone in particular: it’s just that packages get updated and packages that depend on them should get updated as well: but if that doesn’t happen quickly enough, the <code>nixpkgs</code> maintainer faces a conundrum. Either he or she doesn’t update the package because it breaks others, but not updating a package could be a security vulnerability, or he or she updates the package, but now others, perhaps less critical packages are broken and need to be fixed, either by their upstream developers, or by the <code>nixpkgs</code> maintainer of said packages. In the case of RStudio a fix was proposed and promptly merged, but if you wanted to install RStudio during the time it took to fix it, you would have faced an error message, which isn’t great if all you want is use Nix shells as development environments.</p>
<p>So for us, having a fork allows us to backport these fixes and so if you try to install RStudio using the latest available date, which is <code>"2025-02-10"</code>, it’s going to work, whereas if you tried to build it on that date using upstream <code>nixpkgs</code> you’d be facing an error!</p>
<p>We spent quite some time backporting fixes: we went back all the way to 2019. The way this works, is that we start by checking out a <code>nixpkgs</code> commit on selected dates, then we “update” the R packages set by using the Posit CRAN and Bioconductor daily snapshots. Then, we backport as many fixes as possible, and ensure that a selection of popular packages work on both x86-linux (which includes Windows, through WSL) and aarch64-darwin (the M-series of Macs). Then we commit everything to a dated branch of the <code>rstats-on-nix/nixpkgs</code> fork. You can check out all the available dates by running: <code>rix::available_dates()</code>. We’re pretty confindent that you should not face any issues when using Nix to build reproducible environments for R. However, should you face a problem, don’t hesitate to open an issue!</p>
<p>We have now packages and R versions working on Linux and macOS from March 2019 to now. See <a href="https://github.com/rstats-on-nix/daily_cran/blob/master/readme.md">this repository</a> that contains the scripts that allowed us to do it. Backporting fixes was especially important for Apple Silicon computers, as it took some time for this platform to work correctly on Nix. By backporting fixes, we can now provide olders versions of these packages for Apple Silicon as well!</p>
<p>Using this approach, our fork now contains many more versions of working R packages than upstream. <code>{rix}</code> will thus likely keep pointing towards our fork in the future, and not upstream anymore. This should provide a much better user experience. An issue with our fork though, is that by backporting fixes, we essentially create new Nix packages that are not included in upstream, and thus, these are not built by Hydra, Nix’s CI platform which builds binary packages. In practice this means that anyone using our fork will have to compile many packages from source. Now this is pretty bad, as building packages from source takes quite some time. But fear not, because thanks to <a href="https://www.cachix.org/">Cachix</a> we now also have a dedicated binary cache of packages that complements the default, public Nix cache! We provide instructions on how to use Cachix, it’s very easy, it’s just running 2 additional commands after installing Nix. Using Cachix speeds up the installation process of packages tremendously. I want to give my heartfelt thanks to <a href="https://www.cachix.org/about">Domen Kožar</a> for sponsoring the cache!</p>
<p>Another thing we do with our fork is run an action every day at midnight, that monitors the <em>health</em> of the R packages set. Of course, we don’t build every CRAN package, merely a handful, but these are among the most popular or the most <em>at-risk</em> of being in a broken state. See <a href="https://github.com/rstats-on-nix/monitor_health/actions">here</a>.</p>
</section>
<section id="also-theres-a-new-rix-release-on-cran" class="level2">
<h2 class="anchored" data-anchor-id="also-theres-a-new-rix-release-on-cran">Also, there’s a new rix release on CRAN</h2>
<p><code>{rix}</code> now handles remote packages that have remote dependencies (themselves with remote dependencies) much better thanks to code by <a href="https://github.com/mihem">Michael Heming</a>.</p>
<p>We also spent quite some time making <code>{rix}</code> work better with IDEs and have also documented that in a <a href="https://docs.ropensci.org/rix/articles/e-configuring-ide.html">new vignette</a>. The difference with previous releases of <code>{rix}</code>, is that now when a user supplies an IDE name to the <code>ide</code> argument of the <code>rix()</code> function, that IDE will get installed by Nix, which was previously not the case. This only really affects VS Code, as before, setting <code>ide = "code"</code> would only add the <code>{languageserver}</code> server package to the list of R packages to install. That was confusing, because if <code>ide = "rstudio"</code>, then RStudio would be installed. So we decided that if <code>ide = "some editor"</code>, then that editor should be installed by Nix. The vignette linked above explains in great detail how you can configure your editor to work with Nix shells.</p>
<p>If you decide to give <code>{rix}</code> a try, please let us know how it goes!</p>


</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2025-02-17-rstats-on-nix.html</guid>
  <pubDate>Mon, 17 Feb 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Using options() to inject a function’s internal variable for reproducible testing</title>
  <link>https://b-rodrigues.github.io/posts/2025-02-13-testthat.html</link>
  <description><![CDATA[ 




<p><em>No image this time</em></p>
<p>Imagine you have a function that does something complicated, and in the middle of its definition it generates a variable. Now suppose that you want to save this variable and then re-use it for tests, what I mean is that you want your function to always reproduce this intermediary variable, regardless of what you give it as inputs. This can be useful for testing, if computing this intermediate variable is costly.</p>
<p>In my <code>{rix}</code> package, the <code>rix()</code> function generates valid Nix expressions from R input and these Nix expressions can then be used to build reproducible development environments that include R, R packages, development libraries, and so on. If you want a 5-minute intro to <code>{rix}</code>, click <a href="https://www.youtube.com/watch?v=OOu6gjQ310c">here</a>.</p>
<p>Anyways, sometimes, computing these expressions can take some time, especially if the users wants to include remote dependencies that have themselves remote dependencies. <code>rix()</code> will try to look for suitable GitHub commits to pin all the packages for reproducibility purposes, and this can imply quite a lot of api calls. Now for my tests, I wanted to use an already generated <code>default.nix</code> file (which contains the generated Nix expression) but I didn’t want to have to recompute it every time I ran the test and I couldn’t simply use it as is for the test either. You see, that <code>default.nix</code> was in an intermediary state, before <code>rix()</code> is supposed to do some post-processing to it, which is what I actually want to test (I want to actually test the argument that makes <code>rix()</code> skip this post-processing step).</p>
<p>So suppose <code>rix()</code> looks like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1">rix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(a,b,c){</span>
<span id="cb1-2">  ... <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># lots of code</span></span>
<span id="cb1-3">  ... <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># lots of code</span></span>
<span id="cb1-4">  default.nix_file <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> ... <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># it's generated here</span></span>
<span id="cb1-5">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Then a bunch of things happen to it</span></span>
<span id="cb1-6">  out <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">f</span>(default.nix_file)</span>
<span id="cb1-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">writeLines</span>(out, path) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># this is what's written</span></span>
<span id="cb1-8">}</span></code></pre></div>
</div>
<p>Now what I want is to be able to “overwrite” the <code>default.nix_file</code> variable on line 4 when testing, to provide what I want. This way, I can call <code>rix()</code> with some “easy” parameters that make the computations up to that point very quick. My goal is essentially to test <code>f()</code> (line 6), which begs the question, why not write <code>f()</code> as a separate function and test it? This would be the best practice, however, I don’t really have such an <code>f()</code>, rather it’s a series of complicated steps that follow and rewriting everything to make it easily testable would just take too much time.</p>
<p>Instead, I opted for the following:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1">rix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(a,b,c){</span>
<span id="cb2-2">  ... <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># lots of code</span></span>
<span id="cb2-3">  ... <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># lots of code</span></span>
<span id="cb2-4"></span>
<span id="cb2-5">  stub_default.nix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getOption</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TESTTHAT_DEFAULT.NIX"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">default =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">is.null</span>(stub_default.nix)){</span>
<span id="cb2-8">    default.nix_file <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">readLines</span>(stub_default.nix)</span>
<span id="cb2-9">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> {</span>
<span id="cb2-10">    default.nix_file <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> ... <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># it's generated here if not being tested</span></span>
<span id="cb2-11">  }</span>
<span id="cb2-12">  out <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">f</span>(default.nix_file)</span>
<span id="cb2-13">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Then a bunch of things happen to it</span></span>
<span id="cb2-14">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">writeLines</span>(out, path) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># this is what's written</span></span>
<span id="cb2-15">}</span></code></pre></div>
</div>
<p>On line 5, I get the option <code>"TESTTHAT_DEFAULT.NIX"</code> and if it doesn’t exist, <code>stub_default.nix</code> will be set to <code>NULL</code>. So if it’s <code>NULL</code> it’s business as usual, if not, then that <code>default.nix</code> file dedicated for testing gets passed further down. In a sense, I injected the variable I needed in the spot I needed.</p>
<p>Then, my tests looks like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1">testthat<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">test_that</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"remove_duplicate_entries(), don't remove duplicates if skip"</span>, {</span>
<span id="cb3-2"></span>
<span id="cb3-3"></span>
<span id="cb3-4">  dups_entries_default.nix <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste0</span>(</span>
<span id="cb3-5">    testthat<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">test_path</span>(),</span>
<span id="cb3-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/testdata/default-nix_samples/dups-entries_default.nix"</span>)</span>
<span id="cb3-7"></span>
<span id="cb3-8">  tmpdir <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tempdir</span>()</span>
<span id="cb3-9"></span>
<span id="cb3-10">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This copies the file I need in the right path</span></span>
<span id="cb3-11">  destination_file <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.path</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tempdir</span>(), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">basename</span>(dups_entries_default.nix))</span>
<span id="cb3-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.copy</span>(dups_entries_default.nix, destination_file, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">overwrite =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span>
<span id="cb3-13"></span>
<span id="cb3-14">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">on.exit</span>(</span>
<span id="cb3-15">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unlink</span>(tmpdir, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">recursive =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">force =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>),</span>
<span id="cb3-16">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">add =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span></span>
<span id="cb3-17">  )</span>
<span id="cb3-18"></span>
<span id="cb3-19">  removed_dups <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span>(destination_file) {</span>
<span id="cb3-20"></span>
<span id="cb3-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the option to the file path and clean the option afterwards</span></span>
<span id="cb3-22">    op <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">options</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"TESTTHAT_DEFAULT.NIX"</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> destination_file)</span>
<span id="cb3-23">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">on.exit</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">options</span>(op), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">add =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">after =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span>
<span id="cb3-24"></span>
<span id="cb3-25">    out <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rix</span>(</span>
<span id="cb3-26">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">date =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2025-02-10"</span>,</span>
<span id="cb3-27">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">project_path =</span> tmpdir,</span>
<span id="cb3-28">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">overwrite =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>,</span>
<span id="cb3-29">      <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">skip_post_processing =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># &lt;- this is actually want I wanted to test</span></span>
<span id="cb3-30">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">file.path</span>(destination_file)</span>
<span id="cb3-31">  }</span>
<span id="cb3-32"></span>
<span id="cb3-33"></span>
<span id="cb3-34">  testthat<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">expect_snapshot_file</span>(</span>
<span id="cb3-35">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">path =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">removed_dups</span>(destination_file),</span>
<span id="cb3-36">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">name =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"skip-dups-entries_default.nix"</span>,</span>
<span id="cb3-37">  )</span>
<span id="cb3-38">})</span></code></pre></div>
</div>
<p>On line 22, I set the option and on line 23 I write code to remove that option once the test is done, to not mess up subsequent tests. This is a snapshot test, so now I can take a look at the resulting file, and indeed make sure that post-processing was skipped, as expected.</p>
<p>How would you have done this?</p>



 ]]></description>
  <category>R</category>
  <category>data-science</category>
  <guid>https://b-rodrigues.github.io/posts/2025-02-13-testthat.html</guid>
  <pubDate>Thu, 13 Feb 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>New year, new blog</title>
  <link>https://b-rodrigues.github.io/posts/2025-01-31-new_blog.html</link>
  <description><![CDATA[ 




<div style="text-align: center;">
<p>
<a href="https://www.youtube.com/watch?v=n__GJuqLb00"> <img src="https://b-rodrigues.github.io/assets/img/shadow.png" style="width: 40%; height: auto;"> </a>
</p>
</div>
<p>Happy new year! The blog has a new look! Well it’s not that different on the surface. But under the hood, it is quite different indeed!</p>
<p>My previous setup was: GitHub to host the code, on each push the build process would get started on Netlify and then it would be hosted there. The engine was Hugo.</p>
<p>This blog now still uses GitHub to host the code, but now also uses GitHub pages for hosting and the engine is <a href="https://quarto.org/docs/websites/website-blog.html">Quarto</a>. The blog also gets built on GitHub Actions inside of a Nix environment: so I just need to push and everything gets built! <a href="https://github.com/b-rodrigues/blog/blob/master/.github/workflows/build_publish.yaml">Here’s the workflow that achieves this</a>.</p>
<p>What’s really amazing with Nix, is that I can preview my blog locally using <em>exactly</em> the same environment as the one that will be used for building it on GitHub actions. So if it <em>works on my machine</em> it’s going to <em>work anywhere</em>.</p>
<p>You’ll notice that the last step uses the <code>rstats-on-nix/quarto-nix-actions/publish@main</code> action that is a fork of the <a href="https://github.com/quarto-dev/quarto-actions">quarto-dev/quarto-actions</a> actions that just makes them work inside of a Nix shell! This fork is hosted on the <code>rstats-on-nix</code> organization: I have a lot to say about this organization, but that’s for a future blog post!</p>
<p>Migrating the pages was a rather long process, as I needed to make sure everything was rendering correctly: because the folder structure of Quarto blogs is different than the structure of Hugo blogs, I had to update many paths. This was quite tedious and I didn’t want to use a script for this as I also wanted to take this opportunity to make some adjustments, such as centering images properly and correcting some typos if I saw some. It was also quite interesting to re-read some of my old blog posts.</p>
<p>One neat thing about Quarto is the possibility to use pre- and post-render scripts that can be written in R. I’m using one to correctly sort the blog posts in the main page, as for some reason they weren’t being sorted properly. <a href="https://github.com/b-rodrigues/blog/blob/master/order_posts.R">Here’s the post-render script in question.</a></p>
<p>Now I can go back to working on <a href="https://docs.ropensci.org/rix/">rix</a>.</p>



 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2025-01-31-new_blog.html</guid>
  <pubDate>Fri, 31 Jan 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 13 – {rix} is on CRAN!</title>
  <link>https://b-rodrigues.github.io/posts/2024-09-27-nix_part_13.html</link>
  <description><![CDATA[ 




<div data-align="center">
<p>
<a href="https://docs.ropensci.org/rix"> <img src="https://b-rodrigues.github.io/assets/img/rix-logo.png" width="100%" height="auto"> </a>
</p>
</div>
<p>
<em>Simplifies the creation of reproducible data science environments using the ‘Nix’ package manager, as described in Dolstra (2006) <a href="https://dspace.library.uu.nl/handle/1874/7540">&lt;ISBN 90-393-4130-3&gt;</a>. The included ‘rix()’ function generates a complete description of the environment as a ‘default.nix’ file, which can then be built using ‘Nix’. This results in project specific software environments with pinned versions of R, packages, linked system dependencies, and other tools. Additional helpers make it easy to run R code in ‘Nix’ software environments for testing and production.</em>
</p>
<p>
After 15 months of coding, 1364 commits, 143 closed issues, 175 closed PRs, an rOpenSci pre-review, an rOpenSci review, <code>{rix}</code> is finally on <a href="https://cran.r-project.org/web/packages/rix/index.html">CRAN</a>!
</p>
<p>
You can now install <code>{rix}</code> using good old <code>install.packages()</code>. Soon, <code>{rix}</code> will also be included into the <code>nixpkgs</code> collection of packages, meaning that you will be able to install <code>{rix}</code> with Nix.
</p>
<p>
Important sidenote: as it so happened, there is currently a bug in the released CRAN version that we thought we had solved, which we did, but only partially. When running <code>rix::rix()</code> two files should be generated: a <code>default.nix</code> and an <code>.Rprofile</code> for your project. It turns out that this file can be empty. If it is, run <code>rix::rix_init(rprofile_action = “overwrite”)</code> to generate a proper <code>.Rprofile</code>. This is important, especially on Mac or if you have a system-wide library of packages! We will submit a fix asap.
</p>
<p>
If you want to watch a 5-Minute video introduction:
</p>
<div data-align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/OOu6gjQ310c?si=tQ-s9ZgEBxak8k8G" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</div>
<p>
Btw, here is what <a href="https://github.com/boyter/scc">scc</a> has to say about the estimated cost of the project:
</p>
<p>
<code>scc –format=html-table –avg-wage 100000 .</code>
</p>
<div data-align="center">
<table class="table">
<colgroup>
<col width="15%">
<col width="11%">
<col width="11%">
<col width="11%">
<col width="13%">
<col width="10%">
<col width="16%">
<col width="11%">
</colgroup>
<thead>
<tr class="header">
<th>
<strong>Language</strong>
</th>
<th align="right">
<strong>Files</strong>
</th>
<th align="right">
<strong>Lines</strong>
</th>
<th align="right">
<strong>Blank</strong>
</th>
<th align="right">
<strong>Comment</strong>
</th>
<th align="right">
<strong>Code</strong>
</th>
<th align="right">
<strong>Complexity</strong>
</th>
<th align="right">
<strong>Bytes</strong>
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
YAML
</td>
<td align="right">
61
</td>
<td align="right">
2798
</td>
<td align="right">
320
</td>
<td align="right">
174
</td>
<td align="right">
2304
</td>
<td align="right">
0
</td>
<td align="right">
69187
</td>
</tr>
<tr class="even">
<td>
R
</td>
<td align="right">
33
</td>
<td align="right">
4515
</td>
<td align="right">
483
</td>
<td align="right">
1225
</td>
<td align="right">
2807
</td>
<td align="right">
389
</td>
<td align="right">
153288
</td>
</tr>
<tr class="odd">
<td>
Nix
</td>
<td align="right">
10
</td>
<td align="right">
781
</td>
<td align="right">
95
</td>
<td align="right">
0
</td>
<td align="right">
686
</td>
<td align="right">
32
</td>
<td align="right">
18644
</td>
</tr>
<tr class="even">
<td>
Markdown
</td>
<td align="right">
5
</td>
<td align="right">
1371
</td>
<td align="right">
339
</td>
<td align="right">
0
</td>
<td align="right">
1032
</td>
<td align="right">
0
</td>
<td align="right">
63758
</td>
</tr>
<tr class="odd">
<td>
JSON
</td>
<td align="right">
1
</td>
<td align="right">
147
</td>
<td align="right">
0
</td>
<td align="right">
0
</td>
<td align="right">
147
</td>
<td align="right">
0
</td>
<td align="right">
4637
</td>
</tr>
<tr class="even">
<td>
Plain Text
</td>
<td align="right">
1
</td>
<td align="right">
41
</td>
<td align="right">
0
</td>
<td align="right">
0
</td>
<td align="right">
41
</td>
<td align="right">
0
</td>
<td align="right">
2269
</td>
</tr>
<tr class="odd">
<td>
<strong>Total</strong>
</td>
<td align="right">
<strong>111</strong>
</td>
<td align="right">
<strong>9653</strong>
</td>
<td align="right">
<strong>1237</strong>
</td>
<td align="right">
<strong>1399</strong>
</td>
<td align="right">
<strong>7017</strong>
</td>
<td align="right">
<strong>421</strong>
</td>
<td align="right">
<strong>311783</strong>
</td>
</tr>
</tbody>
</table>
</div>
<p>
Estimated Cost to Develop (organic) $371,264 - Estimated Schedule Effort (organic) 7.59 months - Estimated People Required (organic) 2.45
</p>
<p>
Don’t hesitate to give <code>{rix}</code> a try and let us know how it goes!
</p>



 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2024-09-27-nix_part_13.html</guid>
  <pubDate>Fri, 27 Sep 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 12 – Nix as a polyglot build automation tool for data science</title>
  <link>https://b-rodrigues.github.io/posts/2024-08-28-nix_for_r_part_12.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/guess_we_doin_pdfs.png" width="60%">
</p>
</div>
<p>
Nix is not only a package manager, but also a build automation tool, and you can use it to build polyglot data science pipelines in a completely reproducible way.
</p>
<p>
For example, suppose that you need to mix Python, R and maybe some others tools for a project (by the way, some believe this will become the norm in the coming years, use your favourite search engine to look for “polyglot data science” and you’ll see), and suppose that you want to define your project as a nice reproducible pipeline, and not simply a series of scripts. What are the options available to you?
</p>
<p>
One option would be to use the <code>{targets}</code> package for R, which allows you to do lay out your project as pipeline. But as amazing as <code>{targets}</code> is, it only works with R. If you also need Python, you would then need to also use the <code>{reticulate}</code> package to interface with it. But what do you do if you need some other command line tools? Well, you could wrap them in an R function using <code>system()</code> or <code>system2()</code>. But what if you need yet another language, like Julia? There might be a way to call Julia from R, but as you see, the more diverse tools you need, the more complex it gets. And it doesn’t really matter if you switch from <code>{targets}</code> to another such package that exists for, say, Python, you would always need to write wrappers or use packages that allow you to call the other programming languages that you need.
</p>
<p>
Another possibility is to use good old <code>make</code>. <code>make</code> is a tool from the GNU project that allows you to define <em>targets</em>, which would be the outputs of a script or call to some cli tool by writing so-called <code>Makefiles</code>. For an example of a <code>Makefile</code> in research, take a look at <a href="https://github.com/grantmcdermott/skeptic-priors/blob/master/Makefile">this one</a> from a <a href="https://link.springer.com/article/10.1007/s10584-021-03089-x">paper</a> by <a href="https://mastodon.social/@gmcd">Grant McDermott</a>. You can use <code>make</code> as a to orchestrate several programming languages or cli tools, but you will need to write code to pass data from one script to the other. <code>{targets}</code> deals with that transparently by serialising all the targets’ outputs using <code>saveRDS()</code> but this only works because only R is supported. But if you’re trying to make R, Python, and whatever else work together, you will need to deal with this manually and find a common interface to pass data around.
</p>
<p>
Despite this, using <code>make</code>, or some other tool on top of the required programming languages (and not tied to either one), is likely the best solution and it turns out that Nix can be used just like that! But why use Nix and not <code>make</code> then? Well, using Nix guarantees that whatever you produce will be completely reproducible. With <code>make</code>, you would need to either run it inside a Docker image or… inside a development environment built with Nix! I did something similar in <a href="../posts/2023-07-19-nix_for_r_part2.html">this blog post</a> where I ran a <code>{targets}</code> pipeline inside a Nix environment to make the analysis reproducible.
</p>
<p>
But if I’m already defining a reproducible development environment using Nix, why not go all the way and build a complete project using Nix? After all, Nix allows you to package <em>software</em> and what is <em>software</em> but 0’s and 1’s? And what is a trained model, a paper or report in the PDF format, predictions exported into a CSV file, etc, if not 0’s and 1’s?
</p>
<p>
Just like with any other build automation tool, Nix will only rebuild the project if something changes, and will only rebuild the parts that need to be rebuilt. So if you change a file somewhere, only whatever depends on this file will get rebuilt, just like with <code>{targets}</code>, or <code>make</code>.
</p>
<p>
In the <a href="https://github.com/b-rodrigues/nixbat/tree/master">following repository</a> you can find an example of this.
</p>
<p>
This is a very simple project: two functions are defined in the <code>python_functions.py</code> script. These functions are nothing special, and could be used interactively. One function reads a <code>.csv</code> file from the Internet and returns it, the other does some basic cleaning. Here are these two functions included in the <code>python_functions.py</code> file:
</p>
<pre><code>from pandas import read_csv

def download_iris(iris_csv_url):
    # Read the CSV file
    df = read_csv(iris_csv_url)

    return df

def process_iris(iris_csv_path):
    # Read the CSV file
    df = read_csv(iris_csv_path)

    # Replace the species numbers with their corresponding names
    species_mapping = {0: "setosa", 1: "virginica", 2: "versicolor"}
    df['species'] = df['species'].replace(species_mapping)

    return df</code></pre>
<p>
Then, I want to use <code>{ggplot2}</code> to plot this data. You will notice the lack of R script in the repo. I did this on purpose, because I wanted to show how you could directly write R code inside of a Nix expression. But in practice, it is better to have Python code in a Python script, R code in an R script, and then use Nix to orchestrate the whole thing. But I just wanted to show you that you could, if you wanted to, have a completely self-contained Nix expression that encapsulates the business logic as well.
</p>
<p>
There’s also a <code>.Qmd</code> file: this is the file that will get compiled into a PDF document, and is the output of the whole project. It could be anything else! As I stated above, this is just 0’s and 1’s so it could very well be some other output, it doesn’t really matter.
</p>
<p>
Let’s now take a look at the <code>default.nix</code> that builds the whole thing. Let’s start by the top-level definitions:
</p>
<pre><code>let
  pkgs =
    import
      (fetchTarball "https://github.com/NixOS/nixpkgs/archive/27285241da3bb285155d549a11192e9fdc3a0d04.tar.gz")
      { };

  tex = (
    pkgs.texlive.combine {
      inherit (pkgs.texlive) scheme-small;
    }
  );

  # Because building happens in sandbox that cannot connect to the internet
  # we need to download assets beforehand
  iris_path = pkgs.fetchurl {
    url = "https://raw.githubusercontent.com/b-rodrigues/nixbat/7c319bcdbe15e7f7182e7685b8de176a40d0bde9/iris.csv";
    hash = "sha256-2H6THCXKxIt4yxnDDY+AZRmbxqs7FndCp4MqaAR1Cpw=";
  };

  # Common python dependencies to use in my intermediary inputs
  pythonEnv = pkgs.python312.withPackages (ps: with ps; [ pandas ]);

  # Common python sources
  python_src = pkgs.lib.fileset.toSource {
    root = ./.;
    fileset = ./python_functions.py;
  };</code></pre>
<p>
Some variables are defined there:
</p>
<ul>
<li>
<code>pkgs</code>: this is the set of Nix packages to be used. All the dependencies of the project will get built using the Nix expressions available in the <code>nixpkgs</code> Github repository at a specific commit. This ensures that the output of this expression will always be exactly the same.
</li>
<li>
<code>tex</code>: defines the set of LaTeX packages I need to compile the PDF.
</li>
<li>
<code>iris_path</code>: the Python function I use to load the data takes a path, or url, to read the iris dataset. Because building a derivation happens in a sandbox, I need to download assets beforehand. This is what the <code>fetchurl</code> function does. I can then refer to the file path using <code>${iris_path}</code> later on.
</li>
<li>
<code>pythonEnv</code>: This lists the dependencies I will need to run my Python functions.
</li>
<li>
<code>pythonSrc</code>: Defines the path to the <code>python_functions.py</code> file.
</li>
</ul>
<p>
Then, I want to call each of my functions separately, and I want them to produce a single output. So for this, I now build a derivation, one per output. I start with the first one:
</p>
<pre><code>downloadCsv = pkgs.stdenv.mkDerivation {
  name = "download-csv";
  buildInputs =  [ pythonEnv ];
  src = pythonSrc;
  buildPhase = ''
      python -c "
import pandas as pd
from python_functions import download_iris

iris_raw = download_iris('${iris_path}')

iris_raw.to_csv('iris_raw.csv', index=False)
      "
    '';
  installPhase = ''
    mkdir -p $out
    cp iris_raw.csv $out/
  '';
  };</code></pre>
<p>
At first sight, there might seem that a lot is going on, but let’s take a closer look:
</p>
<ul>
<li>
first I give it a name: <code>name = “download-csv”</code>
</li>
<li>
second, I list its dependencies in <code>buildInputs</code>. This is what’s required to build the target!
</li>
<li>
then, I provide the source, in this case the <code>python_functions.py</code> file
</li>
</ul>
<p>
Then, I need to run the code, and this is what happens in the <code>buildPhase</code>. This is exactly the code you would write if you were using a script to glue your functions together. See how I use <code><img src="https://latex.codecogs.com/png.latex?%7Biris_path%7D%3C/code%3E%20to%20refer%20to%20the%20path%20to%20the%0Afile%20defined%20above.%20Finally,%20in%20the%20%3Ccode%3EinstallPhase%3C/code%3E%20I%20copy%20the%20%3Ccode%3E.csv%3C/code%3E%20file%20to%0A%3Ccode%3E">out/</code>, which essentially copies the file into the Nix store, making it available for the next derivations.
</p>
<p>
In the next derivation, I now use the second Python function to clean the data:
</p>
<pre><code>cleanCsv = pkgs.stdenv.mkDerivation {
    name = "clean-csv";
    buildInputs =  [ pythonEnv ];
    src = pythonSrc;
    buildPhase = ''
      python -c "
import pandas as pd
from python_functions import process_iris

iris = process_iris('${downloadCsv}/iris_raw.csv')

iris.to_csv('iris.csv', index=False)
      "
    '';
    installPhase = ''
      mkdir -p $out
      cp iris.csv $out/
    '';
  };</code></pre>
<p>
This is not very different than what I did before. Just notice how I refer to the output of the first derivation: <code>${downloadCsv}/iris_raw.csv</code>.
</p>
<p>
Now comes the last intermediary derivation, the one that uses R to create a plot:
</p>
<pre><code>generatePlot = pkgs.stdenv.mkDerivation {
    name = "generate-plot";
    buildInputs = with pkgs; [
      R
      rPackages.ggplot2
      rPackages.janitor
    ];
    dontUnpack = true;
    buildPhase = ''
            Rscript -e "

      library(ggplot2)
      library(janitor)

      iris &lt;- read.csv('${cleanCsv}/iris.csv') |&gt;
        clean_names() |&gt;
        transform(species = as.character(species))

      p &lt;- ggplot(iris,
                  aes(x = sepal_length, y = sepal_width, color = species)) +
          geom_point(size = 3) +
          labs(title = 'Sepal Length vs Sepal Width',
               x = 'Sepal Length',
               y = 'Sepal Width') +
          theme_minimal() +
          theme(plot.title = element_text(hjust = 0.5))


      ggsave('plot.png', plot = p, width = 6, height = 4, dpi = 300)

      "
    '';
    installPhase = ''
      mkdir -p $out
      cp plot.png $out/
    '';
  };</code></pre>
<p>
As I said above, to make this better, it would need to be a function defined in its own R script, as this way there’s a nice separation of concerns. On one hand, there’s the business logic in Python and R scripts, and on the other there’s the orchestration in Nix. Putting R code in the Nix expression makes this less flexible, but I wanted to show you that this is also a possibility!
</p>
<p>
Now comes the last part of the Nix expression, the actual thing I want to build, a PDF that uses the generated plot as an input:
</p>
<pre><code>in
# Derivation to generate the PDF report from Markdown
pkgs.stdenv.mkDerivation {
  name = "generate-report";
  buildInputs = [
    pkgs.quarto
    tex
  ];
  src = pkgs.lib.fileset.toSource {
        root = ./.;
        # Only include report.Qmd in the source
        fileset = ./report.Qmd;
  };
  buildPhase = ''

    cp ${generatePlot}/plot.png .

    # Deno needs to add stuff to $HOME/.cache
    # so we give it a home to do this
    mkdir home
    export HOME=$PWD/home
    quarto render report.Qmd --to pdf

  '';

  installPhase = ''
    mkdir -p $out
    cp report.pdf $out/
  '';
}</code></pre>
<p>
Notice the dependencies of this derivation: <code>quarto</code> and <code>tex</code> (<code>tex</code> is the variable I defined right at the beginning that lists LaTeX packages). I then need to specify <code>report.Qmd</code> as the source of this derivation, and copy the plot generated before in R into the working/build directory. There’s also a idiosyncrasy where a dependency of Quarto, Deno, needs to have a directory to save some stuff in it. Nix being Nix, we need to manually define such a home directory for reproducibility purposes. If it would be using my <code>home/</code> directory on my machine, this wouldn’t be reproducible! We finish the <code>buildPhase</code> by rendering the document, and then <em>install</em> it into <code>$out/</code>. To build this project, you need to have Nix installed and then type <code>nix-build</code>, or alternatively, <code>nix-build -Q</code> which hides all the output of the build phases (so you don’t see any warnings or messages thrown by either Python or R).
</p>
<p>
This will build the PDF, which you can then find in the Nix store. You’ll notice a file called <code>result</code> appear next to all your other files from the project. In a terminal, call <code>readlink result</code> and this will show you the path to the generated PDF, which you can now read!
</p>
<p>
In conclusion, I think that this is a really useful way to orchestrate code written in different programming languages, but I would not use this for monolingual projects. For R, I’ll keep using <code>{targets}</code> together with a Nix shell to ensure reproducibility. Also, to really benefit from this, your code needs, ideally, to be written as a series of functions, each outputting a single object. Instead, if you write a script to orchestrate the whole thing in R or Python, and then put a Nix expression on top of it, I’m not sure it’s really worth it. Might as well just use a Nix shell then and execute your scripts in it.
</p>
<p>
Also, let me state that this is my first attempt at using Nix for such a purpose, and there might be a better/more elegant way of doing it, so if you have any input, don’t hesitate!
</p>
<p>
<em>Thanks to <a href="https://discourse.nixos.org/t/derivation-gets-always-rebuilt/51246/3">the amazing Nix community for helping out!</a></em>
</p>



 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2024-08-28-nix_for_r_part_12.html</guid>
  <pubDate>Wed, 28 Aug 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 11 – build and cache binaries with Github Actions and Cachix</title>
  <link>https://b-rodrigues.github.io/posts/2024-04-04-nix_for_r_part_11.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/own_cache.jpg" width="60%">
</p>
</div>
<section id="intro" class="level2">
<h2 class="anchored" data-anchor-id="intro">
Intro
</h2>
<p>
I have this package on CRAN called <code>{chronicler}</code> and last month I got an email from CRAN telling me that building the package was failing, and I had two weeks to fix it.
</p>
<p>
I immediately thought that some dependency that my package depends on got updated, and somehow broke something. But when I checked the results of the build, I was surprised, to say the least:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/chronicler_check_results.png" width="80%">
</p>
</div>
<p>
How come my package was only failing on Fedora? Now that was really weird. There was no way this was right. Also, I couldn’t reproduce this bug on my local machine… but I could reproduce it on Github Actions, on Ubuntu (but it was ok on CRAN’s Debian which is really close to Ubuntu!), but couldn’t reproduce it either on Windows! What was going on? So I started digging, and my first idea was to look at the list of packages that got released on CRAN on that day (March 12th 2024) or just before, and saw something that caught my eye: a new version of <code>{tidyselect}</code> had just been released and even though my package doesn’t directly depend on it, I knew that this package was likely a dependency of some direct dependency of <code>{chronicler}</code>. So I looked into the release notes, and there it was:
</p>
<pre><code>* `eval_select()` out-of-bounds errors now use the verb "select" rather than
  "subset" in the error message for consistency with `dplyr::select()` (#271).</code></pre>
<p>
I knew this was what I was looking for, because the unit test that was failing to pass was a test that should error because <code>dplyr::select()</code> was being used on a column that didn’t exist. So the success of that test was defined as <em>finding the following error message in the log</em>, which contained the word <em>subset</em> but now it should be <em>select</em>.
</p>
<p>
But why was this failing only on Fedora on CRAN and on Ubuntu on Github Actions (but ok on Debian on CRAN)? And why couldn’t I reproduce the bug on my OpenSuse Linux computer, even though I was building a bleeding edge development environment using Nix?
</p>
<p>
And then it hit me like my older brother used to.
</p>
<p>
When building packages, CRAN doesn’t seem to use pre-compiled binaries on Fedora, so packages get built from source. This means that it takes longer to test on Fedora, as packages have to be built from source, but it also means that only the very latest releases of packages get used. On other platforms, pre-compiled binaries get used if available, and because <code>{tidyselect}</code> had just come out that very day, older binaries of <code>{tidyselect}</code> were being used on these platforms, but not on Fedora. And because these older binaries didn’t include this change, the unit test was still passing successfully on there.
</p>
<p>
On Github Actions, code coverage was computed using <code>covr::codecov()</code> which installs the package in a temporary directory and seems to pull its dependencies directly from CRAN. Because CRAN doesn’t offer Linux binaries packages got compiled from source, hence why the test was failing there, as the very latest version of <code>{tidyselect}</code> was being used (btw, use Dirk Eddelbuettel’s <a href="https://github.com/eddelbuettel/r2u">r2u</a> if you binaries for Ubuntu).
</p>
<p>
And on my local machine, even though I was using the latest commit of <code>nixpkgs</code> to have the most bleeding edge packages for my environment, I had forgotten that the R packages on <code>nixpkgs</code> always lag behind the CRAN releases.
</p>
<p>
This is because R packages on <code>nixpkgs</code> tend to get updated alongside a new release of R, and the reason is to ensure a certain level of quality. You see, the vast majority of CRAN (and Bioconductor) packages are made available through <code>nixpkgs</code> in a fully automated way. But some packages do require some manual intervention to work on Nix. And we only know this if we try to build these packages, but building packages requires quite a lot of resources. I go into more detail <a href="../posts/2024-02-29-nix_for_r_part_10.html">here</a>, but in summary we can’t build CRAN packages every single day to see if everything works well, so we only rebuild the whole tree whenever there’s a new release of R. Packages get built on a CI infrastructure called <em>Hydra</em>, and then get cached on <code>cache.nixos.org</code> so whenever someone wants to install a package, a pre-built binary gets pulled from the cache instead of getting installed from source. For packages that don’t need compiling this is not that big of a time save, but for packages that do need to get compiled it is huge. Depending on which packages you want to install, if you had to build everything from source, it could potentially take hours, but if you can install pre-built binaries it’s just a matter of how quick your internet connection is.
</p>
<p>
Anyways, I went back to my fork of <code>nixpkgs</code> and updated the expression defining the CRAN packages myself and installed the latest versions of packages from my fork.
</p>
<p>
Before the update, this was the error message I was testing against:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/cant_subset.png" width="80%">
</p>
</div>
<p>
and this was on version 1.2.0 of <code>{tidyselect}</code>:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/tidyselect_120.png" width="50%">
</p>
</div>
<p>
but after the update, this was the error message:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/cant_select.png" width="80%">
</p>
</div>
<p>
on version 1.2.1 of <code>{tidyselect}</code>:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/tidyselect_121.png" width="50%">
</p>
</div>
<p>
so I found the issue, and updated my unit testing accordingly, and pushed the update to CRAN. All is well that ends well, but… this made me think. I needed to have an easy way to have bleeding edge packages on hand from Nix at all moments, and so I started working on it.
</p>
</section>
<section id="github-actions-to-the-rescue" class="level2">
<h2 class="anchored" data-anchor-id="github-actions-to-the-rescue">
Github Actions to the rescue
</h2>
<p>
As described in my <a href="../posts/2024-02-29-nix_for_r_part_10.html">previous blog post</a> updating the Nix expressions defining the R packages on <code>nixpkgs</code> involves running an R script that generates a Nix expression which then builds the R packages when needed. So what I did was create a Github actions that would run this R script every 6 hours, and push the changes to a branch of my <code>nixpkgs</code> fork. This way, I would always have the possibility to use this branch if I needed bleeding edge packages. Because this can be of interest to others, <a href="https://github.com/philipp-baumann">Philipp Baumann</a> started a Github organisation hosting this fork of <code>nixpkgs</code> that gets updated daily which you can find <a href="https://github.com/rstats-on-nix">here</a>. Because this action needs to run several times a day, it should be on a schedule, but actions on a schedule can only run from master/main. But that’s not what we wanted, so instead, we are using another action, on another repository, that pushes a random file to the target repository to get the action going. You can find this repository <a href="https://github.com/b-rodrigues/trigger-r-updates">here</a> with complete instructions. So to summarise:
</p>
<ul>
<li>
An action on schedule runs from b-rodrigues/trigger-r-updates and pushes a file to rstats-on-nix/nixpkgs on the <code>r-daily-source</code> branch
</li>
<li>
This triggers an action that updates all of <code>nixpkgs</code>, including R packages, and pushes all the updates to the <code>r-daily</code> branch (you can find it <a href="https://github.com/rstats-on-nix/nixpkgs/blob/r-daily-source/.github/workflows/r-daily.yml">here</a>)
</li>
<li>
We can now use the <code>r-daily</code> branch to get bleeding edge R packages on Nix!
</li>
</ul>
<p>
This happens without any form of testing though, so packages could be in a broken state (hey, that’s the definition of bleeding edge, after all!), and also, if anyone would like to use this fork to build a development environment, they’d have to rebuild a lot of packages from source. Again, this is because these packages are defined in a fork of <code>nixpkgs</code> and they don’t get built on Hydra to populate the public cache that Nix uses by default. So while this fork is interesting because it provides bleeding edges packages, using it on a day-to-day basis can be quite tedious.
</p>
<p>
And this is where <a href="https://www.cachix.org/">Cachix</a> comes into play.
</p>
</section>
<section id="setting-up-your-own-binary-cache-on-cachix" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-your-own-binary-cache-on-cachix">
Setting up your own binary cache on Cachix
</h2>
<p>
<a href="https://www.cachix.org/">Cachix</a> is an amazing tool that makes it incredibly easy to set up your own cache. Simply build the packages once, and push the binaries to the cache. As long as these packages don’t get updated, they’ll get pulled from the cache instead of getting rebuilt.
</p>
<p>
So now, here is what I do with my packages: I define a <code>default.nix</code> file that defines a development environment that uses my fork of <code>nixpkgs</code> as the source for packages. For example, <a href="https://github.com/b-rodrigues/rix/blob/master/default.nix">here</a> is this file that defines the environment for my <code>{rix}</code> package. I can use this environment to work on my package, and make sure that anyone else that wants to contribute, contributes using the same environment. As you can see on line 2, the <code>rstats-on-nix</code> bleeding edge fork gets used:
</p>
<pre><code> pkgs = import (fetchTarball "https://github.com/rstats-on-nix/nixpkgs/archive/refs/heads/r-daily.tar.gz") {};</code></pre>
<p>
Then, still on <code>{rix}</code>’s repository, I define a new action that builds this environment periodically, but using the binary cache I set up with Cachix. You can find this action <a href="https://github.com/b-rodrigues/rix/blob/master/.github/workflows/cachix-dev-env.yml">here</a>. So the <code>r-daily</code> branch of our <code>nixpkgs</code> fork gets updated every 6 hour and this environment gets updated every 12 hours, 30 minutes past the hour.
</p>
<p>
Now, every time I want to work on my package, I simply use <code>nix-build</code> on my computer to update the development environment. This is what I see:
</p>
<pre><code>copying path '/nix/store/0l0iw4hz7xvykvhsjg8nqkvyl31js96l-r-stringr-1.5.1' from 'https://b-rodrigues.cachix.org'...
copying path '/nix/store/cw3lc7b0zydsricl5155jbmldm1vcyvr-r-tibble-3.2.1' from 'https://b-rodrigues.cachix.org'...
copying path '/nix/store/y32kpp09l34cdgksnr89cyvz6p5s94z8-r-tidyselect-1.2.1' from 'https://b-rodrigues.cachix.org'...
copying path '/nix/store/sw24yx1jwy9xzq8ai5m2gzaamvyi5r0h-r-rematch2-2.1.2' from 'https://b-rodrigues.cachix.org'...
copying path '/nix/store/z6b4vii7hvl9mc53ykxrwks1lkfzgmr4-r-dplyr-1.1.4' from 'https://b-rodrigues.cachix.org'...</code></pre>
<p>
as you can see, packages get pulled from my cache. Packages that are already available from the usual, public, <code>cache.nixos.org</code> don’t get rebuilt nor cached in mine; they simply continue getting pulled directly from there. This makes using the development environment very easy, and guarantees I’m always mirroring the state of packages released on CRAN. The other interesting thing is that I can use that cache with other actions. For example, <a href="https://github.com/b-rodrigues/rix/blob/master/.github/workflows/tests-r-via-nix.yaml">here</a> is the action that runs the unit tests included in the package in an environment that has Nix installed on it (some unit tests need Nix to be available to run). On line 25 you can see that we install Nix and set our fork as the repository to use:
</p>
<pre><code>nix_path: nixpkgs=https://github.com/rstats-on-nix/nixpkgs/archive/refs/heads/r-daily.tar.gz</code></pre>
<p>
and just below, we set up the cache:
</p>
<pre><code>- uses: cachix/cachix-action@v14
  with:
    name: b-rodrigues # this is the name of my cache</code></pre>
<p>
By using my cache, I make sure that the test runs with the freshest possible packages, and don’t run the risk of having a test succeed on an outdated environment. And you might have noticed that I am not authenticating to Cachix: to simply pull binaries, to authentication is needed!
</p>
<p>
Cachix has a free plan of up to 5Gb which is more than enough to set up several development environments like this, and is really, really, easy to set up, and it works on your computer and on Github Actions, as shown. If you want to use this development environment to contribute to <code>{rix}</code>, check out the instructions on <a href="https://github.com/b-rodrigues/rix/blob/master/CONTRIBUTING.md#development-environment">Contributing.md</a> file.
</p>
<p>
You can use the same approach to always have development environments ready for your different projects, and I will likely add the possibility to use this fork of <code>nixpkgs</code> with my <code>{rix}</code> package.
</p>
<p>
<em>Thanks to <a href="https://github.com/philipp-baumann">Philipp Baumann</a> for nudging me into the direction of using Cachix and showing the way!</em>
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2024-04-04-nix_for_r_part_11.html</guid>
  <pubDate>Thu, 04 Apr 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 10 – contributing to nixpkgs</title>
  <link>https://b-rodrigues.github.io/posts/2024-02-29-nix_for_r_part_10.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/nix_parents.jpg" width="60%">
</p>
</div>
<p>
I’ve very recently started contributing to the <code>nixpkgs</code> repository of packages, which contains all the packages you can install from the Nix package manager. My contributions are fairly modest: I help fix R packages that need some tweaking to make them successfully build for Nix. Most of these fixes are very simple one-liners.
</p>
<p>
Most users of any free and open source tool rarely contribute to the development of this tool: I don’t think it is due to lack of skills and/or time or interest, but mostly because starting to contribute to a tool requires some knowledge that is rarely written down (even more so for an entire ecosystem). These tools and ecosystems grow organically, and if you’re not in the right spot at the right time or are not lucky enough to have kind people taking time to explain things to you, contributing might feel completely overwhelming.
</p>
<p>
Thankfully, I was very lucky to have found the small but very active community of R contributors to <code>nixpkgs</code> on <a href="https://matrix.to/#/#r:nixos.org">Matrix</a> which very kindly took the time to bring me up to speed!
</p>
<p>
I wanted to share my experiences in this blog post: but this blog post is not just going to be about me contributing to <code>nixpkgs</code> from the perspective of an R user (and giving you some pointers on how to start yourself), but also about how I built a report (let’s call it like that) to keep track of which R packages got fixed. This report is built using R, Nix, Github Actions and lists all the failed R package builds from Hydra (more on this later). The report gets updated every day automatically at midnight, and is accessible <a href="https://raw.githack.com/b-rodrigues/nixpkgs-r-updates-fails/targets-runs/output/r-updates-fails.html">here</a>. I also used a very minimalistic approach to build this: no <code>{tidyverse}</code> packages, and no Quarto. Why? Mostly just to keep dependencies at a minimum to accelerate CI/CD, but also for fun. And honestly, I must admit that base R is more than capable on its own and had forgotten that.
</p>
<section id="contributing-to-nixpkgs" class="level2">
<h2 class="anchored" data-anchor-id="contributing-to-nixpkgs">
Contributing to nixpkgs
</h2>
<p>
As explained in <a href="../posts/2023-12-19-nix_for_r_part_8.html">part 8</a>, <code>nixpkgs</code> is “nothing but” a huge GitHub repository containing thousands of Nix expressions. These expressions are then used to actually build the software that then gets installed by Nix. For example, <a href="https://github.com/NixOS/nixpkgs/blob/nixpkgs-unstable/pkgs/development/libraries/quarto/default.nix">this is the expression for Quarto</a>. As you can see, it starts by downloading the pre-compiled binary, and then applying “patches”. Essentially making sure that Quarto installed by Nix is able to find the other pieces installed by Nix that Quarto needs (Deno, Pandoc, Typst and so on). It then continues by installing Quarto itself (because we’re downloading a pre-compiled binary, <em>installation</em> consists in moving files in the right spot), finally some tests are executed (<code>quarto check</code>) and then some metadata is defined. Not every package is defined like this, with a single Nix expression, though. For example, individual R packages are not defined like this. Instead, every package from CRAN and Bioconductor gets built using only a handful of files that can be found <a href="https://github.com/NixOS/nixpkgs/tree/nixpkgs-unstable/pkgs/development/r-modules">here</a>.
</p>
<p>
(By the way, you can look for packages and find their associated Nix expressions on the <a href="https://search.nixos.org/packages?channel=unstable&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=quarto">NixOS package search</a>).
</p>
<p>
The way this works, is that periodically the <a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/r-modules/generic-builder.nix"><code>generate-r-packages.R</code></a> script is run and generates the <a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/r-modules/cran-packages.nix"><code>cran-packages.nix</code></a> file (and the equivalent Bioconductor files). For each package on CRAN, a line gets written in the script with the package’s name, its current version on CRAN, and very importantly its dependencies. For example, here is the line for <code>{dplyr}</code>:
</p>
<pre><code>dplyr = derive2 { name="dplyr"; version="1.1.4";
   sha256="1jsq8pj12bngy66xms486j8a65wxvyqs944q9rxkiaylsla08wyg";
   depends=[cli generics glue lifecycle magrittr pillar R6 rlang tibble tidyselect vctrs]; };</code></pre>
<p>
These dependencies are actually the packages that can be found in the <a href="https://github.com/tidyverse/dplyr/blob/main/DESCRIPTION"><code>DESCRIPTION</code></a> file under <code>Imports</code>. <a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/r-modules/cran-packages.nix"><code>cran-packages.nix</code></a> (and the same goes for the Bioconductor equivalents, <code>bioc-packages.nix</code>, <code>bioc-annotation-packages.nix</code> and <code>bioc-experiment-packages.nix</code>) get imported in the <a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/r-modules/default.nix"><code>default.nix</code></a> file. In it, another file, <code>generic-builder.nix</code> gets also imported, which contains a function that will attempt building the package. Most of the time this succeeds, but some packages require further tweaks. Packages that have a field <code>NeedsCompilation</code> in their DESCRIPTION files are usually candidates for further tweaking: these packages require system-level dependencies, which are often listed under <code>SystemRequirements</code> (but not always, which complicates matters). For example, the <code>{terra}</code> package has these system requirements listed in itself DESCRIPTION file:
</p>
<pre><code>SystemRequirements:  C++17, GDAL (&gt;= 2.2.3), GEOS (&gt;= 3.4.0), PROJ (&gt;= 4.9.3), sqlite3</code></pre>
<p>
so these also need to be added if we want to build them on Nix. But if we look at the line for <code>{terra}</code> in <code>cran-packages.nix</code>, this is what we see:
</p>
<pre><code>terra = derive2 { name="terra"; version="1.7-65"; 
  sha256="0m9s5am8l6il1q0skab614cx0qjsb1i9xcv6nm0sdzj7p9lrzkfl"; 
  depends=[Rcpp]; };</code></pre>
<p>
Only <code>{Rcpp}</code> is listed, which is a dependency, yes, but an R package dependency, not a system-level requirement. System-level requirements need to be added in the <code>default.nix</code> file manually. In the <code>default.nix</code>, you’ll find a long list of packages called <code>packagesWithNativeBuildInputs</code> and <code>packagesWithBuildInputs</code>. <em>NativeBuildInputs</em> and <em>BuildInputs</em> are Nix jargon for dependencies the package needs, at compile-time and then at run-time specifically. For example, <code>{Rcpp}</code> is a <em>BuildInput</em> of <code>{terra}</code>, while the system-level requirements are <em>NativeBuildInputs</em> (in the context of R packages though, this rarely matters. If you want more details, refer to <a href="https://gist.github.com/b-rodrigues/c677b59126d05d43347ed9623ddd5b0c">this Gist</a> I’ve forked).
</p>
<p>
For <code>{terra}</code>, this means that we need to add this line to the list <code>{packagesWithNativeBuildInputs}</code> (I simplified the syntax here a bit):
</p>
<pre><code>terra = [ gdal proj geos ];</code></pre>
<p>
<code>gdal</code>, <code>proj</code> and <code>geos</code> are the system requirements that need to be added for <code>{terra}</code> to build successfully on Hydra.
</p>
</section>
<section id="hydra" class="level2">
<h2 class="anchored" data-anchor-id="hydra">
Hydra
</h2>
<p>
<em>Hydra is a tool for continuous integration testing and software release that uses a purely functional language to describe build jobs and their dependencies</em> (source: <a href="https://hydra.nixos.org/build/248007843/download/1/hydra/#introduction">the Hydra Manual</a>)
</p>
<p>
If you’re coming from R, think of Hydra as <a href="https://builder.r-hub.io/">R-hub</a>, which will check and build your R package before submitting to CRAN. Hydra periodically tries to rebuild packages. If that package fails, then the log gets hosted. When it comes to R packages, we can check which packages built successfully or not on <a href="https://hydra.nixos.org/jobset/nixpkgs/r-updates">here</a>.
</p>
<p>
As of writing, the latest evaluation was in mid-January. A new release of R is going to get released on the 29th of February (or maybe was already released, I’m not sure when this blog post is going to get posted), and this is when new evaluations will likely be executed. Evaluations are the processes by which Nix expressions get… evaluated and used to actually build packages. So if we look into the results of the evaluation of the 17th of January, we see that 757 jobs failed:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/hydra_failing_jobs.jpg" width="80%">
</p>
</div>
<p>
One job doesn’t strictly correspond to one package though: packages get built for different architectures, and each architecture gets its build process. If we log into the details of the first package whose build failed <code>{AIUQ}</code>, we see this:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/hydra_failed.jpg" width="80%">
</p>
</div>
<p>
From the log we see that actually what failed one of its dependencies, <code>{SuperGauss}</code>, so fixing <code>{SuperGauss}</code> will likely fix <code>{AIUQ}</code> (I say likely because maybe another needed dependency also fails). So we could try to fix <code>{SuperGauss}</code> first. Let’s see why <code>{SuperGauss}</code>, by clicking on <code>raw</code>:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/hydra_failed_raw.jpg" width="80%">
</p>
</div>
<p>
Here is what we see:
</p>
<pre><code>Running phase: unpackPhase
unpacking source archive /nix/store/615bdvjchxrd7wp5m7dhg4g04yv7ncza-SuperGauss_2.0.3.tar.gz
source root is SuperGauss
setting SOURCE_DATE_EPOCH to timestamp 1645735202 of file SuperGauss/MD5
Running phase: patchPhase
Running phase: updateAutotoolsGnuConfigScriptsPhase
Running phase: configurePhase
Running phase: buildPhase
Running phase: checkPhase
Running phase: installPhase
* installing *source* package 'SuperGauss' ...
** package 'SuperGauss' successfully unpacked and MD5 sums checked
** using staged installation
checking for gcc... /nix/store/xq8920m5mbd83vdlydwli7qsh67gfm5v-gcc-wrapper-13.2.0/bin/cc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether /nix/store/xq8920m5mbd83vdlydwli7qsh67gfm5v-gcc-wrapper-13.2.0/bin/cc accepts -g... yes
checking for /nix/store/xq8920m5mbd83vdlydwli7qsh67gfm5v-gcc-wrapper-13.2.0/bin/cc option to accept ISO C89... none needed
checking for pkg-config... no
checking for FFTW... configure: error: in `/build/SuperGauss':
configure: error: The pkg-config script could not be found or is too old.  Make sure it
is in your PATH or set the PKG_CONFIG environment variable to the full
path to pkg-config.

Alternatively, you may set the environment variables FFTW_CFLAGS
and FFTW_LIBS to avoid the need to call pkg-config.
See the pkg-config man page for more details.

To get pkg-config, see &lt;http://pkg-config.freedesktop.org/&gt;.
See `config.log' for more details
ERROR: configuration failed for package 'SuperGauss'
* removing '/nix/store/jxv5p85x24xmfcnifw2ibvx9jhk9f2w4-r-SuperGauss-2.0.3/library/SuperGauss'</code></pre>
<p>
This is essentially what we would see if we tried to install <code>{SuperGauss}</code> on Linux. The error message is quite clear here: a system-level dependency, <code>pkg-config</code> is missing. Looks like we found our first package to fix!
</p>
</section>
<section id="fixing-a-package" class="level2">
<h2 class="anchored" data-anchor-id="fixing-a-package">
Fixing a package
</h2>
<p>
The first step is to fork and clone the <code>nixpkgs</code> GitHub repository to your computer (be patient, the repository is huge so the download will take some time):
</p>
<pre><code>git clone git@github.com:b-rodrigues/nixpkgs.git</code></pre>
<p>
It’s also a good idea to add the original <code>nixpkgs</code> as an <code>upstream</code>:
</p>
<pre><code>git remote add upstream https://github.com/NixOS/nixpkgs</code></pre>
<p>
This way, you can pull changes from the original <code>nixpkgs</code> repository into your fork easily with:
</p>
<pre><code>git fetch upstream master
git merge upstream/master</code></pre>
<p>
These two commands synchronize your local copy of the repository with upstream. So now we can create a new branch to try to fix <code>{SuperGauss}</code>:
</p>
<pre><code>git branch -b fix_supergauss</code></pre>
<p>
and then we should try to build <code>{SuperGauss}</code> locally. This is because it might have been fixed in the meantime by someone else, so let’s try to build it with (run the following command in a terminal at the root of your local copy of the <code>nixpkgs</code> repository):
</p>
<pre><code>nix-build -A rPackages.SuperGauss</code></pre>
<p>
but I often prefer to use this instead, because this will build the package and drop me into a shell where I can start R, load the package, and try it by running some of its examples:
</p>
<pre><code>nix-shell -I nixpkgs=/path/to/my/nixpkgs -p rPackages.SuperGauss R</code></pre>
<p>
If any of the commands above fail with the same error message as on Hydra, we know that it hasn’t been fixed yet. So the fix consists in opening the <code>pkgs/development/r-modules/default.nix</code> and add the following line:
</p>
<pre><code>SuperGauss = [ pkg-config ];</code></pre>
<p>
in either the lists <code>packagesWithBuildInputs</code> or <code>packagesWithNativeBuildInputs</code> (as explained above, it doesn’t really matter). Trying to rebuild <code>SuperGauss</code> again will result in a new error message. Another dependecy needs to be added:
</p>
<pre><code>SuperGauss = [ pkg-config fftw.dev ];</code></pre>
<p>
Then, building succeeds! We can now commit, push, and open a pull request. Commit messages need to be formatted in a certain way, as per <code>nixpkgs</code> <a href="https://github.com/NixOS/nixpkgs/blob/master/CONTRIBUTING.md">contributing guide</a>, so:
</p>
<pre><code>git add .
git commit -m "rPackages.SuperGauss: add dependencies"</code></pre>
<p>
also, there should only be one commit per fix. So if in the process of fixing a package you commited several times, you will need to use <code>git rebase</code> to squash all the commits into one. Once you open the pull request, a maintainer will get pinged, and merge the PR if everything is alright (which is usually the case for these one-liners). You can see the PR for <code>{SuperGauss}</code> <a href="https://github.com/NixOS/nixpkgs/pull/287209">here</a>.
</p>
<p>
The process is relatively simple once you did it once or twice, but there are some issues: there is no easy way to find out on which packages we should focus on. For example, is <code>{SuperGauss}</code> really that important? The fix was very simple, so it’s ok, but if it took more effort, should we spend the limited time we have on it, or should we focus on another package? Also, if someone has already opened a PR to fix a package, but that PR hasn’t been merged yet, if I try to also fix the same package and try to build the package, it would still fail. So I might think that no one is taking care of it, and waste time duplicating efforts instead of either focusing on another package, or reviewing the open PR to accelerate the process of merging.
</p>
<p>
Discussing this with other contributors, <a href="https://fosstodon.org/deck/@kupac@functional.cafe">László Kupcsik</a> suggested we could use <code>{packageRank}</code> to find out which packages are getting a lot of downloads from CRAN, and so we could focus on fixing these packages first. This is a great idea and it gave me the idea to build some kind of report that would do this automatically for us, and also list opened and merged PRs so we wouldn’t risk duplicating efforts.
</p>
<p>
This report can be found <a href="https://raw.githack.com/b-rodrigues/nixpkgs-r-updates-fails/targets-runs/output/r-updates-fails.html">here</a> and now I’ll explain how I built it.
</p>
</section>
<section id="which-packages-to-fix-and-keeping-track-of-prs" class="level2">
<h2 class="anchored" data-anchor-id="which-packages-to-fix-and-keeping-track-of-prs">
Which packages to fix and keeping track of PRs
</h2>
<p>
So the main idea was to know on which packages to focus on. So essentially, we wanted this table:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/hydra_failing_jobs.jpg" width="80%">
</p>
</div>
<p>
but with <code>{packageRank}</code> added to it. So the first step was to scrape this table, using <code>{rvest}</code>. This is what you can find on lines 11 to 63 of this <a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/_targets.R">{targets} workflow</a> (alongside some basic cleaning). I won’t go too much into detail, but if something’s not clear, ping me on <a href="https://twitter.com/brodriguesco">twitter</a> or <a href="https://fosstodon.org/@brodriguesco">Mastodon</a> or even open an issue on the report’s <a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/issues">repository</a>.
</p>
<p>
Next I also get the reason the package failed building. So in the example from before, <code>{AIUQ}</code> failed because <code>{SuperGauss}</code> failed. On Hydra, you should be clicking to see this, but here I scrape it as well automatically, and add this information in a column called <code>fails_because_of</code>. This is what you can read on lines <a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/_targets.R#L65">65 to 77</a>. I use a function called <code>safe_get_failed_deps()</code>, which you can find in the <code>functions.R</code> script <a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/functions.R#L41C1-L68C2">on here</a>. <code>safe_get_failed_deps()</code> wraps the main function, <code>get_failed_deps()</code>, with <code>tryCatch()</code>. This is because if anything goes wrong, I want my function to return <code>NULL</code> instead of an error, which would crash the whole pipeline.
</p>
<p>
Next, I add the packages’ rank using a function that wraps <code>packageRank::packageRank()</code> called <code>safe_packageRank()</code> on <a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/_targets.R#L97">line 97</a>.
</p>
<p>
<code>safe_packageRank()</code> uses <code>tryCatch()</code> to return <code>NULL</code> in case there’s an error. This is needed because <code>packageRank()</code> will only work on CRAN packages, but Hydra also tries to build Bioconductor packages: when these packages’ names get passed to <code>packageRank()</code>, an error gets returned because these are not CRAN packages:
</p>
<pre class="r"><code>packageRank("haha")
Error: haha: misspelled or not on CRAN/Archive.</code></pre>
<p>
but instead of an error that would stop the pipeline, I prefer it simply returns <code>NULL</code>, hence <code>tryCatch()</code>. Also, I compute the rank of the package listed under the <code>fails_because_of</code> column and not the <code>package</code> column. If we go back to our example from before, <code>{AIUQ}</code> failed because <code>{SuperGauss}</code> failed, I’m actually interested in the rank of <code>{SuperGauss}</code>, and not <code>{AIUQ}</code> (which I way I went to all the trouble to scrape the failing dependency).
</p>
<p>
So, for now, when comparing to the table on Hydra, we have two further columns with the dependency that actually fails (or not, if the package fails on its own and not because of a dependency), and the rank of either the dependency that fails or the package itself.
</p>
<p>
Next, I’d like to see if PRs have already been opened and merged. For this, I use the <code>gh</code> tool, which is a command line tool to interact with GitHub repositories. I wrote the <code>get_prs()</code> wrapper around <code>gh</code> to list the opened or the merged PRs of the <code>nixpkgs</code> repository. This is what it looks like (and is defined <a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/functions.R#L8C1-L21C2">here</a>):
</p>
<pre><code>get_prs &lt;- function(state){

  output_path &lt;- paste0(state, "_prs.json")

  # Run the command
  system(paste0(
    "gh pr list --state=", state,
    " --search=rPackages -R NixOS/nixpkgs --json title,updatedAt,url &gt; ",
    output_path
  ))

  # Return path for targets
  output_path
}</code></pre>
<p>
Because the PRs follow the contributing guidelines, I can easily process the PRs titles to get the name of the package (I essentially need to go from the string “rPackages.SuperGauss: fixing build” to “SuperGauss”) using regular expressions. This is what happens in the <code>clean_prs()</code> function <a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/functions.R#L23">here</a>.
</p>
<p>
Most of what follows is merging the right data frames and ensuring that I have something clean to show. Finally, an <code>.Rmd</code> document gets compiled, which you can find <a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/r-updates-fails.Rmd">here</a>. This will get compiled to an <code>.html</code> file which is what you see when you click <a href="https://raw.githack.com/b-rodrigues/nixpkgs-r-updates-fails/targets-runs/output/r-updates-fails.html">here</a>.
</p>
<p>
This runs every day at midnight using GitHub actions (<a href="https://github.com/b-rodrigues/nixpkgs-r-updates-fails/blob/0fe273dd234f0d32e5fae86630173ff42cce2d9f/.github/workflows/compile_table.yaml">the workflow is here</a>) and then I use the <code>raw.githack.com</code> <a href="https://raw.githack.com/">here</a> to serve the rendered HTML file. So every time I push, or at midnight, the action runs, computes the package rank, checks if new PRs are available or have been merged, and the rendered file is immediately available. How’s that for serverless CI/CD?
</p>
<p>
If you are interested in using Nix to make your analyses reproducible, check out <a href="https://b-rodrigues.github.io/blog/index.html#category=nix">the other blog posts in this series</a> and join our small but motivated community of R contributors to <code>nixpkgs</code> on <a href="https://matrix.to/#/#r:nixos.org">Matrix</a>. If you are interested in the history of Nix, checkout this super interesting <a href="https://economicsfromthetopdown.com/2024/02/17/nixing-technological-lock-in/">blog post</a> by <a href="https://mastodon.online/@blair_fix">Blair Fix</a>.
</p>
<p>
If you’re interested into using project-specific, and reproducible development environments, give <code>{rix}</code> and Nix a try! Learn more about <code>{rix}</code> on its Github repository <a href="https://github.com/b-rodrigues/rix">here</a> or <a href="https://docs.ropensci.org/rix/index.html">website</a>. We wrote many vignettes that are conveniently numbered, so don’t hesitate to <a href="https://docs.ropensci.org/rix/articles/a-getting-started.html">get started</a>!
</p>
<p>
<em>Thanks to the colleagues of the Matrix nixpkgs R channel for the fruitful discussions that helped shape this blog post and for proof-reading.</em>
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2024-02-29-nix_for_r_part_10.html</guid>
  <pubDate>Thu, 29 Feb 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 9 – rix is looking for testers!</title>
  <link>https://b-rodrigues.github.io/posts/2024-02-02-nix_for_r_part_9.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/kick_rix.png">
</p>
</div>
<p>
After 5 months of work, <a href="https://github.com/philipp-baumann">Philipp Baumann</a> and myself are happy to announce that our package, <code>{rix}</code> is getting quite close to being in a state we consider “done” (well, at least, for a first release). We plan on submit it first to <a href="https://ropensci.org/software-review/">rOpenSci</a> for review, and later to CRAN. But in the meantime, if you could test the package, we’d be grateful! We are especially interested to see if you find the documentation clear, and if you are able to run the features that require an installation of Nix, the <code>nix_build()</code> and <code>with_nix()</code> functions. And I would truly recommend you read this blog post to the end, because I guarantee you’ll have your mind blown! If that’s not the case, send an insult my way on social media.
</p>
<section id="what-is-rix" class="level2">
<h2 class="anchored" data-anchor-id="what-is-rix">
What is rix?
</h2>
<p>
<code>{rix}</code> is an R package that leverages Nix, a powerful package manager focusing on reproducible builds. With Nix, it is possible to create project-specific environments that contain a project-specific version of R and R packages (as well as other tools or languages, if needed). You can use <code>{rix}</code> and Nix to replace renv and Docker with one single tool. Nix is an incredibly useful piece of software for ensuring reproducibility of projects, in research or otherwise, or for running web applications like Shiny apps or plumber APIs in a controlled environment. The advantage of using Nix over Docker is that the environments that you define using Nix are not isolated from the rest of your machine: you can still access files and other tools installed on your computer.
</p>
<p>
For example, here is how you could use <code>{rix}</code> to generate a file called <code>default.nix</code>, which can then be used by Nix to actually build that environment for you:
</p>
<pre class="r"><code>library(rix)

path_default_nix &lt;- tempdir()

rix(r_ver = "latest",
    r_pkgs = c("dplyr", "ggplot2"),
    system_pkgs = NULL,
    git_pkgs = NULL,
    ide = "code",
    shell_hook = NULL,
    project_path = path_default_nix,
    overwrite = TRUE,
    print = TRUE)</code></pre>
<pre><code>## # This file was generated by the {rix} R package v0.5.1.9000 on 2024-02-02
## # with following call:
## # &gt;rix(r_ver = "5ad9903c16126a7d949101687af0aa589b1d7d3d",
## #  &gt; r_pkgs = c("dplyr",
## #  &gt; "ggplot2"),
## #  &gt; system_pkgs = NULL,
## #  &gt; git_pkgs = NULL,
## #  &gt; ide = "code",
## #  &gt; project_path = path_default_nix,
## #  &gt; overwrite = TRUE,
## #  &gt; print = TRUE,
## #  &gt; shell_hook = NULL)
## # It uses nixpkgs' revision 5ad9903c16126a7d949101687af0aa589b1d7d3d for reproducibility purposes
## # which will install R version latest
## # Report any issues to https://github.com/b-rodrigues/rix
## let
##  pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/5ad9903c16126a7d949101687af0aa589b1d7d3d.tar.gz") {};
##  rpkgs = builtins.attrValues {
##   inherit (pkgs.rPackages) dplyr ggplot2 languageserver;
## };
##    system_packages = builtins.attrValues {
##   inherit (pkgs) R glibcLocales nix ;
## };
##   in
##   pkgs.mkShell {
##     LOCALE_ARCHIVE = if pkgs.system == "x86_64-linux" then  "${pkgs.glibcLocales}/lib/locale/locale-archive" else "";
##     LANG = "en_US.UTF-8";
##     LC_ALL = "en_US.UTF-8";
##     LC_TIME = "en_US.UTF-8";
##     LC_MONETARY = "en_US.UTF-8";
##     LC_PAPER = "en_US.UTF-8";
##     LC_MEASUREMENT = "en_US.UTF-8";
## 
##     buildInputs = [  rpkgs  system_packages  ];
##       
##   }</code></pre>
<p>
You don’t need to have Nix installed to use <code>{rix}</code> and generate this expression! This is especially useful if you want to generate an expression that should then be used in a CI/CD environment for example.
</p>
<p>
But if you do have Nix installed, then you can use two great functions that Philipp implemented, which we are really excited to tell you about!
</p>
</section>
<section id="nix_build-and-with_nix" class="level2">
<h2 class="anchored" data-anchor-id="nix_build-and-with_nix">
nix_build() and with_nix()
</h2>
<p>
When you have a <code>default.nix</code> file that was generated by <code>rix::rix()</code>, and if you have Nix installed on your system, you can build the corresponding environment using the command line tool <code>nix-build</code>. But you can also build that environment straight from an R session, by using <a href="https://b-rodrigues.github.io/rix/reference/nix_build.html"><code>rix::nix_build()</code></a>!
</p>
<p>
But the reason <a href="https://b-rodrigues.github.io/rix/reference/nix_build.html"><code>nix_build()</code></a> is really useful, is because it gets called by <a href="https://b-rodrigues.github.io/rix/reference/with_nix.html"><code>with_nix()</code></a>. <a href="https://b-rodrigues.github.io/rix/reference/with_nix.html"><code>with_nix()</code></a> is a very interesting function, because it allows you to evaluate a single function within a so-called subshell. That subshell can have a whole other version of R and R packages than your main session, and you can use it to execute an arbitrary function (or a whole, complex expression), and then get the result back into your main session. You could use older versions of packages to get a result that might not be possible to get in a current version. Consider the following example: on a recent version of <code>{stringr}</code>, <code>stringr::str_subset(c(““,”a”), ““)</code> results in an error, but older versions would return <code>”a”</code>. Returning an error is actually what this should do, but hey, if you have code that relies on that old behaviour you can now execute that old code within a subshell that contains that older version of <code>{stringr}</code>. Start by creating a folder to contain everything needed for your subshell:
</p>
<pre class="r"><code>path_env_stringr &lt;- file.path(".", "_env_stringr_1.4.1")</code></pre>
<p>
Then, it is advised to use <a href="https://b-rodrigues.github.io/rix/reference/rix_init.html"><code>rix::rix_init()</code></a> to generate an <code>.Rprofile</code> for that subshell, which sets a number of environment variables. This way, when the R session in that subshell starts, we don’t have any interference between that subshell and the main R session, as the R packages that must be available to the subshell are only taken from the Nix store. The Nix store is where software installed by Nix is… stored, and we don’t want R to be confused and go look for R packages in the user’s library, which could happen without this specific <code>.Rprofile</code> file:
</p>
<pre class="r"><code>rix_init(
  project_path = path_env_stringr,
  rprofile_action = "overwrite",
  message_type = "simple"
)</code></pre>
<pre><code>## 
## ### Bootstrapping isolated, project-specific, and runtime-pure R setup via Nix ###
## 
## ==&gt; Created isolated nix-R project folder:
##  /home/cbrunos/six_to/dev_env/b-rodrigues.github.com/content/blog/_env_stringr_1.4.1 
## ==&gt; R session running via Nix (nixpkgs)
## * R session not running from RStudio
## ==&gt; Added `.Rprofile` file and code lines for new R sessions launched from:
## /home/cbrunos/six_to/dev_env/b-rodrigues.github.com/content/blog/_env_stringr_1.4.1
## 
## * Added the location of the Nix store to `PATH` environmental variable for new R sessions on host/docker RStudio:
## /nix/var/nix/profiles/default/bin</code></pre>
<p>
We now generate the <code>default.nix</code> file for that subshell:
</p>
<pre class="r"><code>rix(
  r_ver = "latest",
  r_pkgs = "stringr@1.4.1",
  overwrite = TRUE,
  project_path = path_env_stringr
)</code></pre>
<p>
Notice how we use the latest version of R (we could have used any other), but <code>{stringr}</code> on version 1.4.1. Finally, we use <code>with_nix()</code> to evaluate <code>stringr::str_subset(c(““,”a”), ““)</code> inside that subshell:
</p>
<pre class="r"><code>out_nix_stringr &lt;- with_nix(
  expr = function() stringr::str_subset(c("", "a"), ""),
  program = "R",
  exec_mode = "non-blocking",
  project_path = path_env_stringr,
  message_type = "simple"
)</code></pre>
<pre><code>## * R session not running from RStudio
## ### Prepare to exchange arguments and globals for `expr` between the host and Nix R sessions ###
## * checking code in `expr` for potential problems:
##  `codetools::checkUsage(fun = expr)`
## 
## * checking code in `expr` for potential problems:
## 
## * checking code in `globals_exprs` for potential problems:
## 
## ==&gt; Running deparsed expression via `nix-shell` in non-blocking mode:
## 
## 
## ==&gt; Process ID (PID) is 19688.
## ==&gt; Receiving stdout and stderr streams...
## 
## ==&gt; `expr` succeeded!
## ### Finished code evaluation in `nix-shell` ###
## 
## * Evaluating `expr` in `nix-shell` returns:
## [1] "a"</code></pre>
<p>
Finally, we can check if the result is really <code>“a”</code> or not:
</p>
<pre class="r"><code>identical("a", out_nix_stringr)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>
<code>with_nix()</code> should work whether you installed your main R session using Nix, or not, but we’re not sure this is true for Windows (or rather, WSL2): we don’t have a Windows license to test this on Windows, so if you’re on Windows and use WSL2 and want to test this, we would be very happy to hear from you!
</p>
<p>
If you’re interested into using project-specific, and reproducible development environments, give <code>{rix}</code> and Nix a try! Learn more about <code>{rix}</code> on its Github repository <a href="https://github.com/b-rodrigues/rix">here</a> or <a href="https://docs.ropensci.org/rix/">website</a>. We wrote many vignettes that are conveniently numbered, so don’t hesitate to <a href="https://docs.ropensci.org/rix/articles/a-getting-started.html">get started</a>!
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2024-02-02-nix_for_r_part_9.html</guid>
  <pubDate>Fri, 02 Feb 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 8 – nixpkgs, a tale of the magic of free and open source software and a call for charity</title>
  <link>https://b-rodrigues.github.io/posts/2023-12-19-nix_for_r_part_8.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/santa_tux.jpg" width="100%">
</p>
</div>
<p>
<em>This is part 8 of a series of blog posts about Nix. Check out the other parts <a href="https://b-rodrigues.github.io/blog/index.html#category=nix">here</a>. TLDR: free and open source software is one of the most important common goods with enormous positive externalities: if you want to help funding it, keep reading!</em>
</p>
<p>
I wanted to quickly discuss about <code>nixpkgs</code>, which is the collection of packages that can be installed using Nix. Why is a project like Nix and <code>nixpkgs</code> important, even if you don’t use Nix? In actuality, you may not realise it, but you very much benefit from projects like Nix even if you don’t use it. Let me explain.
</p>
<p>
<code>nixpkgs</code> is “just” a Github repository containing thousands upon thousands of Nix expressions. When installing a package, these expressions get evaluated, and the package in question gets installed. What <em>installed</em> means can vary: sometimes the package gets built from source, sometimes a pre-compiled binary package for your operating system gets downloaded and installed.
</p>
<p>
For example, <a href="https://github.com/NixOS/nixpkgs/blob/dce218f4f35440622d2056f93ddc335351763bb4/pkgs/development/libraries/quarto/default.nix">here</a> is the Nix expression that downloads and installs Quarto. This is an example of an expression that downloads the pre-compiled Quarto package from Quarto’s own Github repository, and then <em>installs</em> it. The installation process in this case is essentially making sure that Quarto is able to find its dependencies, which also get installed from Nix, and some R and Python packages to make Quarto work well with both languages also get installed.
</p>
<p>
Because Nix packages are “nothing but” Nix expressions hosted on Github, contributing to Nix is as simple as opening a PR. For example, <a href="https://github.com/NixOS/nixpkgs/pull/263108">here</a> is a draft PR I opened to prepare for the imminent release of Quarto <code>1.4</code>. My goal when I opened this draft PR was to get used to contributing to <code>nixpkgs</code> (this was my second or third PR to <code>nixpkgs</code>, and I did some rookie mistakes when opening my first ones) and also to make the latest version of Quarto available on Nix as quickly as possible. But this PR had an unexpected consequence: through it, we found a bug in Quarto, which was then fixed before the actual release of the next version!
</p>
<p>
You see, how these things work is that when software gets released, operating system specific packages get built downstream. In the case of Quarto, this is not entirely true though: the developers of Quarto release many pre-compiled packages for Windows, macOS and several Linux distribution themselves. But they don’t do so for many other operating systems (which is entirely normal: there’s just too many! So releasing pre-built binaries for the main operating systems is more than enough), so the maintainers of these other operating systems (or package managers) have to package the software themselves. In the case of scientific software like Quarto, this usually means that it must get packaged for the Conda package manager (popular among Python users) and Nix (and there’s certainly other package managers out there that provide Quarto for other <em>exotic</em> systems) (Note: in the case of Quarto, I think the Quarto devs themselves also package it for Conda, though).
</p>
<p>
Turns out that when trying to package the pre-releases of Quarto for Nix, we discovered a regression in the upstream code that would not only affect packaging for Nix, but also for other package managers. We opened an issue on <a href="https://github.com/quarto-dev/quarto-cli/issues/7344">Quarto’s issue tracker</a> and after some discussion, the bug was identified and adressed in a matter of hours. And now everyone gets to enjoy a better version of Quarto!
</p>
<p>
This type of thing happens quite a lot in the background of open source development. My mind always gets blown when I think about the enormous amount of hours that get put by hobbyists and paid developers into open source and how well everything works. Truly a Christmas miracle (but one that happens all around the year)!
</p>
<p>
But it’s not all good and perfect. Some software is more complex to package, and requires much more work. For example the RStudio IDE is one of these. It’s a complex piece of software with many dependencies, and while it is available on Nix, it can only be installed on Windows and Linux. If you’re a Nix user on macOS, you won’t be able to install RStudio, unfortunately. And, unfortunately also, if you install RStudio using the usual macOS installer, it won’t be able to find any version of R and R packages installed with Nix. This is because RStudio needs to be patched to make it work nicely with Nix (just like we have to patch and prepare Quarto to play well with Nix). And packaging Rstudio for Nix on macOS requires some expertise and hardware that we R users/contributers to Nix don’t have all have access to.
</p>
<p>
This is where I appeal to your generosity: I have contacted a company called Numtide which offers a packaging service. You tell them which software you want on Nix, they write the expression and open a PR to <code>nixpkgs</code>. But this costs money: so I started a Gofundme which you can find <a href="https://www.gofundme.com/f/package-rstudio-for-nix-on-macos-platforms">here</a> to fund this. The goal is 4500€, which would cover the work, plus Gofundme fees and interest rate risk. I stated in the Gofundme that if the goal was not reached until the end of the year, I would donate all the money to the R foundation, but I might extend it to end of January 2024 instead.
</p>
<p>
So here is my ask: if you want to help make free and open source software better, consider donating to this Gofundme! As explained above, even if you don’t use Nix, everyone can benefit from work that is done by everyone, be it upstream or downstream. And if the goal is not met, your donation will go to the R foundation anyways!
</p>
<p>
The link to the Gofundme is <a href="https://www.gofundme.com/f/package-rstudio-for-nix-on-macos-platforms">here</a>.
</p>
<p>
I hope you can help out with this and make free and open source available and better for everyone.
</p>
<p>
Many thanks, merry Christmas and happy new year!
</p>



 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2023-12-19-nix_for_r_part_8.html</guid>
  <pubDate>Tue, 19 Dec 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 7 – Building a Quarto book using Nix on Github Actions</title>
  <link>https://b-rodrigues.github.io/posts/2023-10-20-nix_for_r_part7.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/nix_users_press_both_buttons.png" width="50%">
</p>
</div>
<p>
Back in June I self-published a book on Amazon’s Kindle Direct Publishing service and wrote a blog post detailling how you could achieve that using Quarto, which you can read <a href="../posts/2023-06-29-book_quarto.html">here</a>. The book is about <a href="https://b-rodrigues.github.io/blog/books.html">building reproducible analytical pipelines with R</a>. For the purposes of this post I made a <a href="https://github.com/b-rodrigues/kdp_quarto">template on Github</a> that you could fork and use as a starting point to write your own book. The book also gets built using Github Actions each time you push new changes: a website gets built, an E-book for e-ink devices and a Amazon KDP-ready PDF for print get also built. That template used dedicated actions to install the required version of R, Quarto, and R packages (using <code>{renv}</code>).
</p>
<p>
Let’s take a look at the workflow file:
</p>
<pre><code>on:
  push:
    branches: main

name: Render and Publish

jobs:
  build-deploy:
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup pandoc
        uses: r-lib/actions/setup-pandoc@v2

      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.3.1'

      - name: Setup renv
        uses: r-lib/actions/setup-renv@v2

      - name: Set up Quarto
        uses: quarto-dev/quarto-actions/setup@v2
        with:
          # To install LaTeX to build PDF book 
          tinytex: true 
          # uncomment below and fill to pin a version
          #version: 1.3.353

      - name: Publish to GitHub Pages (and render)
        uses: quarto-dev/quarto-actions/publish@v2
        with:
          target: gh-pages
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # this secret is always available for github actions</code></pre>
<p>
As you can see, there are a lot of different moving pieces to get this to work. Since then I discovered Nix (if you’ve not been following my adventures, there’s 6 other parts to this series as of today), and now I wrote another template that uses Nix to handle the book’s dependencies instead of dedicated actions and <code>{renv}</code>. You can find the repository <a href="https://github.com/b-rodrigues/quarto_book_nix">here</a>.
</p>
<p>
Here is what the workflow file looks like:
</p>
<pre><code>name: Build book using Nix

on:
  push:
    branches:
      - main
      - master

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Code
      uses: actions/checkout@v3

    - name: Install Nix
      uses: DeterminateSystems/nix-installer-action@main
      with:
        logger: pretty
        log-directives: nix_installer=trace
        backtrace: full

    - name: Nix cache
      uses: DeterminateSystems/magic-nix-cache-action@main

    - name: Build development environment
      run: |
        nix-build

    - name: Publish to GitHub Pages (and render)
      uses: b-rodrigues/quarto-nix-actions/publish@main
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} </code></pre>
<p>
The first thing you should notice is that this file is much shorter.
</p>
<p>
The first step, <code>Checkout Code</code> makes the code available to the rest of the steps. I then install Nix on this runner using the Determinate Systems <code>nix-installer-action</code> and then I use another action from Determinate Systems, the <code>magic-nix-cache-action</code>. This action caches all the packages so that they don’t need to get re-built each time a change gets pushed, speeding up the process by a lot. The development environment gets then built using <code>nix-build</code>.
</p>
<p>
Finally, an action I defined runs, <code>quarto-nix-actions/publish</code>. This is a fork of the <code>quarto-actions/publish</code> action which you can find <a href="https://github.com/quarto-dev/quarto-actions/blob/main/publish/action.yml">here</a>. My fork simply makes sure that the <code>quarto render</code> and <code>quarto publish</code> commands run in the <a href="https://github.com/b-rodrigues/quarto-nix-actions/blob/f48f5a7813eb4978a2f557ff45bcc854526fb80b/publish/action.yml#L58">Nix environment defined for the project</a>.
</p>
<p>
You can see the book website <a href="https://b-rodrigues.github.io/quarto_book_nix/">here</a>; read it, it’s explains everything in much more details than this blog post! But if you’re busy, read continue reading this blog post instead.
</p>
<p>
The obvious next question is why bother with this second, Nix-centric, approach?
</p>
<p>
There are at least three reasons. The first is that it is possible to define so-called <code>default.nix</code> files that the Nix package manager then uses to build a fully reproducible development environment. This environment will contain all the packages that you require, and will not interfere with any other packages installed on your system. This essentially means that you can have project-specific <code>default.nix</code> files, each specifying the requirements for specific projects. This file can then be used as-is on any other platform to re-create your environment. The second reason is that when installing a package that requires system-level dependencies, <code>{rJava}</code> for example, all the lower-level dependencies get automatically installed as well. Forget about reading error messages of <code>install.packages()</code> to find which system development library you need to install first. The third reason is that you can pin a specific revision of <code>nixpkgs</code> to ensure reproducibility.
</p>
<p>
The <code>nixpkgs</code> mono-repository is “just” a Github repository which you can find here: <a href="https://github.com/NixOS/nixpkgs">https://github.com/NixOS/nixpkgs</a>. This repository contains Nix expressions to build and install more than 80’000 packages and you can search for installable Nix packages <a href="https://search.nixos.org/packages">here</a>.
</p>
<p>
Because <code>nixpkgs</code> is a “just” Github repository, it is possible to use a specific commit hash to install the packages as they were at a specific point in time. For example, if you use this commit, <code>7c9cc5a6e</code>, you’ll get the very latest packages as of the 19th of October 2023, but if you used this one instead: <code>976fa3369</code>, you’ll get packages from the 19th of August 2023.
</p>
<p>
This ability to deal with both underlying system-level dependencies and pin package versions at a specific commit is extremely useful on Git(Dev)Ops platforms like Github Actions. Debugging installation failures of packages can be quite frustrating, especially on Github Actions, and especially if you’re not already familiar with how Linux distributions work. Having a tool that handles all of that for you is amazing. The difficult part is writing these <code>default.nix</code> files that the Nix package manager requires to actually build these development environments. But don’t worry, with my co-author <a href="https://github.com/philipp-baumann">Philipp Baumann</a>, we developed an R package called <code>{rix}</code> which generates these <code>default.nix</code> files for you.
</p>
<p>
<code>{rix}</code> is an R package that makes it very easy to generate very complex <code>default.nix</code> files. These files can in turn be used by the Nix package manager to build project-specific environments. The book’s Github repository contains a file called <code>define_env.R</code> with the following content:
</p>
<pre class="r"><code>library(rix)

rix(r_ver = "4.3.1",
    r_pkgs = c("quarto"),
    system_pkgs = "quarto",
    tex_pkgs = c(
      "amsmath",
      "framed",
      "fvextra",
      "environ",
      "fontawesome5",
      "orcidlink",
      "pdfcol",
      "tcolorbox",
      "tikzfill"
    ),
    ide = "other",
    shell_hook = "",
    project_path = ".",
    overwrite = TRUE,
    print = TRUE)</code></pre>
<p>
<code>{rix}</code> ships the <code>rix()</code> function which takes several arguments. These arguments allow you to specify an R version, a list of R packages, a list of system packages, TeXLive packages and other options that allow you to specify your requirements. Running this code generates this <code>default.nix</code> file:
</p>
<pre><code># This file was generated by the {rix} R package v0.4.1 on 2023-10-19
# with following call:
# &gt;rix(r_ver = "976fa3369d722e76f37c77493d99829540d43845",
#  &gt; r_pkgs = c("quarto"),
#  &gt; system_pkgs = "quarto",
#  &gt; tex_pkgs = c("amsmath",
#  &gt; "framed",
#  &gt; "fvextra",
#  &gt; "environ",
#  &gt; "fontawesome5",
#  &gt; "orcidlink",
#  &gt; "pdfcol",
#  &gt; "tcolorbox",
#  &gt; "tikzfill"),
#  &gt; ide = "other",
#  &gt; project_path = ".",
#  &gt; overwrite = TRUE,
#  &gt; print = TRUE,
#  &gt; shell_hook = "")
# It uses nixpkgs' revision 976fa3369d722e76f37c77493d99829540d43845 for reproducibility purposes
# which will install R version 4.3.1
# Report any issues to https://github.com/b-rodrigues/rix
let
 pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz") {};
 rpkgs = builtins.attrValues {
  inherit (pkgs.rPackages) quarto;
};
  tex = (pkgs.texlive.combine {
  inherit (pkgs.texlive) scheme-small amsmath framed fvextra environ fontawesome5 orcidlink pdfcol tcolorbox tikzfill;
});
 system_packages = builtins.attrValues {
  inherit (pkgs) R glibcLocalesUtf8 quarto;
};
  in
  pkgs.mkShell {
    LOCALE_ARCHIVE = if pkgs.system == "x86_64-linux" then  "${pkgs.glibcLocalesUtf8}/lib/locale/locale-archive" else "";
    LANG = "en_US.UTF-8";
    LC_ALL = "en_US.UTF-8";
    LC_TIME = "en_US.UTF-8";
    LC_MONETARY = "en_US.UTF-8";
    LC_PAPER = "en_US.UTF-8";
    LC_MEASUREMENT = "en_US.UTF-8";

    buildInputs = [  rpkgs tex system_packages  ];
  }</code></pre>
<p>
This file defines the environment that is needed to build your book: be it locally on your machine, or on a GitOps platform like Github Actions. All that matters is that you have the Nix package manager installed (thankfully, it’s available for Windows –through WSL2–, Linux and macOS).
</p>
<p>
Being able to work locally on a specific environment, defined through code, and use that environment on the cloud as well, is great. It doesn’t matter that the code runs on Ubuntu on the Github Actions runner, and if that operating system is not the one you use as well. Thanks to Nix, your code will run on exactly the same environment. Because of that, you can use <code>ubuntu-latest</code> as your runner, because exactly the same packages will always get installed. This is not the case with my first template that uses dedicated actions and <code>{renv}</code>: there, the runner uses <code>ubuntu-22.04</code>, a fixed version of the Ubuntu operating system. The risk here, is that once these runners get decommissioned (Ubuntu 22.04 is a <em>long-term support</em> release of Ubuntu, so it’ll stop getting updated sometime in 2027), my code won’t be able to run anymore. This is because there’s no guarantee that the required version of R, Quarto, and all the other packages I need will be installable on that new release of Ubuntu. So for example, suppose I have the package <code>{foo}</code> at version 1.0 that requires the system-level development library <code>bar-dev</code> at version 0.4 to be installed on Ubuntu. This is not an issue now, as Ubuntu 22.04 ships version 0.4 of <code>bar-dev</code>. But it is very unlikely that the future version of Ubuntu from 2027 will ship that version, and there’s no guarantee my package will successfully build and work as expected with a more recent version of <code>bar-dev</code>. With Nix, this is not an issue; because I pin a specific commit of <code>nixpkgs</code>, not only will <code>{foo}</code> at version 1.0 get installed, its dependency <code>bar-dev</code> at version 0.4 will get installed by Nix as well, and get used to build <code>{foo}</code>. It doesn’t matter that my underlying operating system ships a more recent version of <code>bar-dev</code>. I really insist on this point, because this is not something that you can easily deal with, even with Docker. This is because when you use Docker, you need to be able to rebuild the image as many times as you need (the alternative is to store, forever, the built image), and just like for Github Actions runners, the underlying Ubuntu image will be decommissioned and stop working one day.
</p>
<p>
In other words, if you need long-term reproducibility, you should really consider using Nix, and even if you don’t need long-term reproducibility, you should really consider using Nix. This is because Nix makes things much easier. But there is one point where Nix is at a huge disadvantage when compared to the alternatives: the entry cost is quite high, as I’ve discussed in my <a href="../posts/2023-10-05-repro_overview.html">previous blog post</a>. But I’m hoping that through my blog posts, this entry cost is getting lowered for R users!
</p>



 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2023-10-20-nix_for_r_part7.html</guid>
  <pubDate>Fri, 20 Oct 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>An overview of what’s out there for reproducibility with R</title>
  <link>https://b-rodrigues.github.io/posts/2023-10-05-repro_overview.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/like_this.jpg" width="100%">
</p>
</div>
<p>
In this short blog post I’ll be summarizing what I learnt these past years about reproducibility with R. I’ll give some high-level explanations about different tools and then link to different blog posts of mine.
</p>
<p>
I see currently two main approaches with some commonalities, so let’s start with the commonalities.
</p>
<section id="commonalities" class="level2">
<h2 class="anchored" data-anchor-id="commonalities">
Commonalities
</h2>
<p>
These are aspects that I think will help you build reproducible projects, but that are not strictly necessary. These are:
</p>
<ul>
<li>
Git for code versioning;
</li>
<li>
unit tests (be it on your code or data);
</li>
<li>
literate programming;
</li>
<li>
packaging code;
</li>
<li>
build automation.
</li>
</ul>
<p>
I think that these aspects are really very important nice-to-haves, but depending on the project you might not have to use all these tools or techniques (but I would really recommend that you think very hard about these requirements and make sure that you actually, really, don’t need them).
</p>
<p>
What’s also important is how you organize the work if you’re in a team. Making sure that everyone is on the same page and uses the same tools and approaches is very important.
</p>
<p>
Now that we have the commonalities out of the way, let’s discuss the “two approaches”. Let’s start by the most popular one.
</p>
</section>
<section id="docker-and-something-else" class="level2">
<h2 class="anchored" data-anchor-id="docker-and-something-else">
Docker and “something else”
</h2>
<p>
Docker is a very popular containerisation solution. The idea is to build an <em>image</em> that contains everything needed to run and rebuild your project in a single command. You can add a specific version of R with the required packages in it, your project files and so on. You could even add the data directly into the image or provide the required data at run-time, it’s up to you.
</p>
<p>
The “something else” can be several things, but they all deal with the problem of providing the right packages for your analysis. You see, if you run an analysis today, you’ll be using certain versions of packages. The same versions of packages need to be made available inside that Docker image. To do so, a popular choice for R users is to use <a href="https://rstudio.github.io/renv/index.html">{renv}</a>, but there’s also <a href="https://groundhogr.com/">{groundhog}</a> and <a href="https://github.com/gesistsa/rang">{rang}</a>. You could also use CRAN snapshots from the <a href="https://packagemanager.posit.co/client/#/repos/cran/setup?snapshot=2023-09-25&amp;r_environment=other">Posit Public Package Manager</a>. Whatever you choose, Docker by itself is not enough: Docker provides a base where you can then add these other things on top.
</p>
<p>
To know more, read this:
</p>
<ul>
<li>
<a href="../posts/2022-11-19-raps.html">https://www.brodrigues.co/blog/2022-11-19-raps/</a>
</li>
<li>
<a href="../posts/2022-11-30-pipelines-as.html">https://www.brodrigues.co/blog/2022-11-30-pipelines-as/</a>
</li>
<li>
<a href="../posts/2023-05-08-dock_dev_env.html">https://www.brodrigues.co/blog/2023-05-08-dock_dev_env/</a>
</li>
<li>
<a href="2023-01-12-repro_r.qmd">https://www.brodrigues.co/blog/2023-01-12-repro_r/</a>
</li>
</ul>
<p>
By combining Docker plus any of the other packages listed above (or by using the PPPM) you can quite easily build reproducible projects, because what you end up doing, is essentially building something like a capsule that contains everything needed to run the project (this capsule is what is called an <em>image</em>). Then, you don’t run R and the scripts to build the project, you run the image, and within that image, R is executed on the provided scripts. This running instance of an image is called a <em>container</em>. This approach is by far the most popular and can even be used on Github Actions if your project is hosted on Github. On a scale from 1 to 10, I would say that the entry cost is about 3 if you already have some familiarity with Linux, but can go up to 7 if you’ve never touched Linux. What does Linux have to do with all this? Well, the Docker images that you are going to build will be based on Linux (most of the time the Ubuntu distribution) so familiarity with Linux or Ubuntu is a huge plus. You could use <code>{renv}</code>, <code>{rang}</code> or <code>{groundhog}</code> without Docker, directly on your PC, but the issue here is that your operating system and the version of R changes through time. And both of these can have an impact on the reproducibility of your project. Hence, why we use Docker to, in a sense, “freeze” both the underlying operating system and version of R inside that image, and then, every container executed from that image will have the required versions of software.
</p>
<p>
One issue with Docker is that if you build an image today, the underlying Linux distribution will get out of date at some point, and you won’t be able to rebuild the image. So you either need to build the image and store it forever, or you need to maintain your image and port your code to newer base Ubuntu images.
</p>
</section>
<section id="nix" class="level2">
<h2 class="anchored" data-anchor-id="nix">
Nix
</h2>
<p>
Nix is a package manager for Linux (and Windows through WSL) and macOS, but also a programming language that focuses on reproducibility of software builds, meaning that using Nix it’s possible to build software in a completely reproducible way. Nix is incredibly flexible, so it’s also possible to use it to build reproducible development environments, or run reproducible analytical pipelines. What Nix doesn’t easily allow, unlike <code>{renv}</code> for example, is to install a specific version of one specific package. But I also wrote a package called <a href="https://b-rodrigues.github.io/rix/">{rix}</a> (co-authored by Philipp Baumann) that makes it easier for R users to get started with Nix and also allows to install arbitrary versions of packages easily using the Nix package manager. So you can define an environment with any version of R, plus corresponding packages, and install specific versions of specific packages if needed as well. Packages that are hosted on Github can also get easily installed if needed. Let me make this clear: using Nix, you install both R and R packages so there’s no need to use <code>install.packages()</code> anymore. Everything is managed by Nix.
</p>
<p>
Using Nix, we can define our environment and build instructions as code, and have the build process always produce exactly the same result. This definition of the environment and build instructions are written using the Nix programming language inside a simple text file, which then gets used to actually realize the build. This means that regardless of “when” or “where” you rebuild your project, <em>exactly</em> the same packages (all the way down to the system libraries and compilers and all that stuff we typically never think about) will get installed to rebuild the project.
</p>
<p>
Essentially, using the Nix package manager, you can replace Docker + any of the other tools listed above to build reproducible projects. The issue with Nix however is that the entry cost is quite high: even if you’re already familiar with Linux and package managers, Nix is really an incredible deep tool. So I would say that the entry cost is around 9 out of 10…, but to bring this entry cost down, I have written 6 blog posts to get you started:
</p>
<ul>
<li>
<a href="../posts/2023-07-13-nix_for_r_part1.html">https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/</a>
</li>
<li>
<a href="../posts/2023-07-19-nix_for_r_part2.html">https://www.brodrigues.co/blog/2023-07-19-nix_for_r_part2/</a>
</li>
<li>
<a href="../posts/2023-07-30-nix_for_r_part3.html">https://www.brodrigues.co/blog/2023-07-30-nix_for_r_part3/</a>
</li>
<li>
<a href="../posts/2023-08-12-nix_for_r_part4.html">https://www.brodrigues.co/blog/2023-08-12-nix_for_r_part4/</a>
</li>
<li>
<a href="../posts/2023-09-15-nix_for_r_part5.html">https://www.brodrigues.co/blog/2023-09-15-nix_for_r_part5/</a>
</li>
<li>
<a href="../posts/2023-09-20-nix_for_r_part6.html">https://www.brodrigues.co/blog/2023-09-20-nix_for_r_part6/</a>
</li>
</ul>
<p>
Also, by the way, it is entirely possible to build a Docker image based on Ubuntu, install the Nix package manager on it, and then use Nix inside Docker to install the right software to build a reproducible project. This approach is extremely flexible, as it uses the best of both worlds in my opinion: we can take advantage of the popularity of Docker so that we can run containers anywhere, but use Nix to truly have reproducible builds. This also solves the issue I discussed before: if you’re using Nix inside Docker, it doesn’t matter if the base image gets outdated: simply use a newer base image, and Nix will take care of always installing the right versions of the needed pieces of software for your project.
</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">
Conclusion
</h2>
<p>
So which should you learn, Docker or Nix? While Docker is certainly more popular these days, I think that Nix is very interesting and not that hard to use <strong>once</strong> you learnt the basics (which does take some time). But the entry costs for any of these tools is in the end quite high and, very annoyingly, building reproducible projects does not get enough recognition, even in science where reproducibility is supposedly one of its corner stones. However, I think that you should definitely invest time in learning the tools and best practices required for building reproducible projects, because by making sure that a project is reproducible you end up increasing its quality as well. Furthermore, you avoid stressful situations where you get asked “hey, where did that graph/result/etc come from?” and you have no idea why the script that supposedly built that output does not reproduce the same output again.
</p>
<p>
If you read all the blog posts above but still want to learn and know more about reproducibility you can get my <a href="https://leanpub.com/raps-with-r/c/blog_reader">ebook at a discount</a> or get a physical copy on <a href="https://www.amazon.com/Building-reproducible-analytical-pipelines-R/dp/B0C87H6MGF/ref=sr_1_1?keywords=building+reproducible+analytical+pipelines&amp;sr=8-1">Amazon</a> or you can <a href="https://raps-with-r.dev/">read it for free</a>. That book does not discuss Nix, but I will very certainly be writing another book focusing this time on Nix during 2024.
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2023-10-05-repro_overview.html</guid>
  <pubDate>Thu, 05 Oct 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>ZSA Voyager review</title>
  <link>https://b-rodrigues.github.io/posts/2023-09-29-voyager.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<a href="https://www.youtube.com/watch?v=NlgmH5q9uNk"> <img src="https://b-rodrigues.github.io/assets/img/travelling_with_my_keyboard.png" title="Click for banger" width="80%" height="auto"></a>
</p>
</div>
<p>
Now for something completely different than our usual programming: today I’m sharing my thoughts on the latest ZSA mechanical keyboard, the <a href="https://www.zsa.io/voyager/buy/">Voyager</a>. First things first: this is in no way shape or form sponsored by ZSA. But Erez, if you’d like to send me money you’re more than welcome.
</p>
<p>
Here’s what the keyboard looks like:
</p>
<div style="text-align:center;">
<video width="854" height="480" controls="" autoplay="" muted="" loop="">
<source src="../assets/img/voyager.mp4" type="video/mp4">
Your browser does not support the video tag. </video>
</div>
<p>
Yes, it comes with RGB LEDs. Why do mechanical keyboards come with RGB LEDs? No idea, I usually don’t care for them, but unlike other keyboards from ZSA, you cannot order the Voyager without them. So now my keyboard looks like a Christmas tree. And by the way, yes, you can get the good old regular QWERTY layout instead of the dots. I chose to get blank keys because I don’t look at my keyboard when typing.
</p>
<p>
It’s quite small and there aren’t many keys on it. But it’s very comfortable to use. I’ll try to explain why.
</p>
<p>
If you don’t know anything about mechanical keyboards, I think you might find this blog post useful. I’ll explain the basics and also why you might want to consider one if you’re a programmer.
</p>
<p>
First of all, let me just get this out of the way: typing on a mechanical keyboard will not make you type any faster. I think that people that buy mechanical keyboards also tend to be people that spend some time learning how to touch-type, so yeah, they’ll type faster than most people that never bother to learn to touch-type, but two touch-typists, one that use a mechanical keyboard and another that uses a normal keyboard, will roughly type at the same speed.
</p>
<p>
So if not for speed, why bother with mechanical keyboards?
</p>
<p>
In my opinion, the main advantage of mechanical keyboards is customization. You can customize absolutely everything: not just how the keyboard looks, but also how it works. Many mechanical keyboards come with a firmware called QMK which enables you to program each key. So for instance I have a key that types “&lt;-” and another that types “%&gt;%”, very useful for an R programmer like myself. You can configure such things at the level of you favourite text editor, but it’s nice to also have the option at the level of the hardware, because it means that you can now easily type these programming symbols anywhere: on social media, an email, a forum… Configuring this firmware on keyboards made by ZSA, like the Voyager, is incredibly easy: there’s a web-application called Oryx that you can use for all they keyboards. Simply select the keys, change what you must and flash the new firmware to your keyboard! For example here, I’m configuring a key to output “,” when pressed, but to output “_” when double-tapped:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/oryx.png" width="80%" height="auto">
</p>
</div>
<p>
And for the flashing process you don’t even have to install anything on your computer: if you’re using a Chromium based browser like Google Chrome, you can flash it from the Web Browser. You can even browse other people’s configurations, for example here’s <a href="https://configure.zsa.io/voyager/layouts/l9eWG/ErJeQ/0">mine</a> (and you can even customize the RGB).
</p>
<p>
I use the French ergonomic BÉPO layout, the English equivalent would be Dvorak. You can add different layers, for example by holding one key, all the other keys now output something different when pressed (like holding down the SHIFT key produces capital letters), but you can make any key switch layers and then any other key output anything. For example I have a layer in which I configured keys to move my mouse and click. I don’t use that very often, but in case I forget my mouse if I’m traveling, I could also use my keyboard as a mouse now.
</p>
<p>
Hardware can also be customized: the color of the keyboard, but also the keycaps (I have the blank ones, as you’ve seen above) and also the switches. If you’re not into mechanical keyboard I guess this doesn’t mean anything. Keycaps are these:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/caps.jpg" width="80%" height="auto">
</p>
</div>
<p>
and switches are these:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/switches.jpg" width="80%" height="auto">
</p>
</div>
<p>
And you can change either the caps, the switches or both. The keyboard is <em>hot-swapable</em> meaning that you can actually replace the switches. Here is a switch with a keycap on it that I removed from my keyboard:
</p>
<div style="text-align:center;">
<video width="854" height="480" controls="" loop="">
<source src="../assets/img/pressing_switch.mp4" type="video/mp4">
Your browser does not support the video tag. </video>
</div>
<p>
Again, if you’re not into mechanical keyboard it’s difficult to see why this is really a nice thing: but being able to change caps and switches allows you to truly make the keyboard feel and sound just right for you.
</p>
<p>
Let me explain: there’s switches that make no sound and that are very easy to press: they’re called linear switches. Then there’s switches that make a nice clicky sound and that require more force to press, and there’s switches that make even more noise and that require a lot of force to press. The harder ones are so-called “clicky” switches and the intermediate ones “tactile”. There’s a lot more subtlety than that, but even I don’t know everything about switches. What matters is that you can swap these, and find the ones that are just right for you. My first mechanical keyboard, also one from ZSA, the Ergodox EZ (pictured below) came with red switches. At the time, I had no idea what switches I should get, so I bought the reds because they were silent, and I figured that I would prefer silent ones. Turns out that I absolutely hated them. It didn’t fill right because they were extremely light, and simply by resting my hands on the keyboard I would press keys by mistake. Then I bought clicky switches, and since then haven’t looked back. Clicky switches make a nice “click” sound when you press them, because there’s actually a little mechanism that produces this noise when you press them. It’s like pushing an actual button. Much more satisfying, and much better, in my opinion, for typing. So for this board I got the white ones, which are the clickiest. It’s also the one’s I had for my other mechanical keyboard, the Planck EZ, also by ZSA:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/planck.jpg" width="80%" height="auto">
</p>
</div>
<p>
I also experimented with heavier ones on my other board (an Idobao ID75, a somewhat overgrown Planck, not by ZSA but also very customizable through <a href="https://get.vial.today/">VIAL</a>):
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/idobao.jpg" width="80%" height="auto">
</p>
</div>
<p>
The switches there are heavier, and I enjoy them a lot as well.
</p>
<p>
Now, this keyboard isn’t cheap, but it does come with a lot of nice stuff in the box. You get 3 usb cables, 4 more switches, several keycaps more, and a carrying bag.
</p>
<p>
And as you can see, it’s a so-called low profile keyboard:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/low_voyager_1.jpg" width="80%" height="auto">
</p>
</div>
<p>
You can even remove these little feet from the keyboard (they’re magnetic):
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/magnetic_feet.jpg" width="80%" height="auto">
</p>
</div>
<p>
to get it even lower:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/low_voyager_2.jpg" width="80%" height="auto">
</p>
</div>
<p>
I’ve never had such a keyboard in the past and I must say that it’s really comfortable to use. I don’t need to use any wrist rests anymore, which is kinda nice. Because it’s low-profile the switches and keycaps are different from the usual ones you get for other mechanical keyboards:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/mx_vs_choc.jpg" width="80%" height="auto">
</p>
</div>
<p>
Anyways, I really enjoy this form factor, not just that it’s low profile, but also that it doesn’t have a lot of keys. I like this, because my hands don’t need to move at all. If I need numbers for example, I switch layers, and now the keys that would usually be directly under my fingers will output numbers when pressed. So instead of my fingers going to the keys, they keys go to my fingers. It gets some time to get used to this, but once you know how to do that, it’s just great.
</p>
<p>
So, should you buy a Voyager? I might not advise it to you for a first mechanical keyboard. There’s much cheaper ones that you can get and see if mechanical keyboards are for you. If you can, try some out in a store, I think it’s especially important to find the right switches for your style. As I’ve written above, I started with linear reds which I hated, thankfully I tried clicky whites before abandoning my mechanical keyboard adventure. If you’re already a hardened mechanical keyboard user, and are looking for a light keyboard that you can take with you on your travels, I think that it’s hard to overlook the Voyager. There are other nice, very transportable keyboards out there, but the build quality of ZSA and the firmware customization tool they provide, Oryx, is hard to beat.
</p>


 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2023-09-29-voyager.html</guid>
  <pubDate>Fri, 29 Sep 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 6 – CI/CD has never been easier</title>
  <link>https://b-rodrigues.github.io/posts/2023-09-20-nix_for_r_part6.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/gymnastics.png" width="50%">
</p>
</div>
<p>
<em>Warning: I highly recommend you read this <a href="../posts/2023-07-19-nix_for_r_part2.html">blog post</a> first, which will explain how to run a pipeline inside Nix in detail. This blog post will assume that you’ve read that one, and it would also help if you’re familiar with Github Actions, if not, read this <a href="../posts/2022-11-19-raps.html">other blog post of mine as well</a></em>
</p>
<p>
This is getting ridiculous. The meme that I’m using as a header for this blog post perfectly summaries how I feel.
</p>
<p>
This will be a short blog post, because Nix makes things so easy that there’s not much to say. I wanted to try how I could use Nix on Github Actions to run a reproducible pipeline. This pipeline downloads some data, prepares it, and fits a machine learning model. It is code that I had laying around from an old video on the now deprecated <code>{drake}</code> package, <code>{targets}</code> predecessor.
</p>
<p>
You can find the pipeline <a href="https://github.com/b-rodrigues/nix_ml_cicd_demo/tree/main">here</a> and you can also take a look at the same pipeline but which uses Docker <a href="https://github.com/b-rodrigues/mlops_demo">here</a> for comparison purposes.
</p>
<p>
What I wanted to achieve was the following: I wanted to set up a reproducible environment with Nix on my computer, work on my pipeline locally, and then have it run on Github Actions as well. But I wanted my pipeline to run exactly on the same environment as the one I was using to develop it. In a world without Nix, this means using a mix of <code>{renv}</code> (or <code>{groundhog}</code> or <code>{rang}</code>) and a Docker image that ships the right version of R. I would then need to write a Github Actions workflow file that builds that Docker image, then runs it and saves the outputs as artifacts. Also, in practice that image would not be exactly the same as my local environment: I would have the same version of R and R packages, but every other system-level dependency would be a different version unless I use that Dockerized environment to develop locally, something I suggested you should do merely <a href="../posts/2023-05-08-dock_dev_env.html">4 months ago</a> (oooh, how blind was I!).
</p>
<p>
With Nix, not only can I take care of the version of R and R packages with one single tool but also every underlying system-level dependency gets handled by Nix. So if I use a package that requires, say, Java, or GDAL, or any other of these usual suspects that make installing their R bindings so tricky, Nix will handle this for me without any intervention on my part. I can also use this environment to develop locally, and then, once I’m done working locally, <em>exactly</em> this environment, <em>exactly</em> every bit of that environment, will get rebuilt and used to run my code on Github Actions.
</p>
<p>
So <a href="https://github.com/b-rodrigues/nix_ml_cicd_demo">this is the repository</a> where you can find the code. There’s a <code>{targets}</code> script that defines the pipeline and a <code>functions/</code> folder with some code that I wrote for said pipeline. What’s unfamiliar to you (unless you’ve been reading my Nix adventures since the beginning) is the <code>default.nix</code> file:
</p>
<pre><code>let
 pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz") {};
 rpkgs = builtins.attrValues {
  inherit (pkgs.rPackages) tidymodels vetiver targets xgboost;
};
 system_packages = builtins.attrValues {
  inherit (pkgs) R;
};
in
 pkgs.mkShell {
  buildInputs = [  rpkgs system_packages  ];
 }</code></pre>
<p>
This few lines of code define an environment that pulls packages from revision <code>976fa3369d722e76f37c77493d99829540d43845</code> of <code>nixpkgs</code>. It installs the packages <code>{tidymodels}</code>, <code>{vetiver}</code>, <code>{targets}</code> and <code>{xgboost}</code> (actually, I’m not using <code>{vetiver}</code> for this <em>yet</em>, so it could even be removed). Then it also installs R. Because we’re using that specific revision of Nix, exactly the same packages (and their dependencies) will get installed, regardless of when we build this environment. I want to insist that this file is 12 lines long and it defines a complete environment. The equivalent <code>Dockerfile</code> is much longer, and not even completely reproducible, and I would have needed external tools like <code>{renv}</code> (or use the Posit CRAN mirror dated snapshots) as you can check out <a href="https://github.com/b-rodrigues/mlops_demo">here</a>.
</p>
<p>
Let’s now turn our attention to the workflow file:
</p>
<pre><code>name: train_model

on:
  push:
    branches: [main]

jobs:
  targets:
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
    steps:

      - uses: actions/checkout@v3

      - name: Install Nix
        uses: DeterminateSystems/nix-installer-action@main
        with:
          logger: pretty
          log-directives: nix_installer=trace
          backtrace: full

      - name: Nix cache
        uses: DeterminateSystems/magic-nix-cache-action@main

      - name: Build development environment
        run: |
          nix-build

      - name: Check if previous runs exists
        id: runs-exist
        run: git ls-remote --exit-code --heads origin targets-runs
        continue-on-error: true

      - name: Checkout previous run
        if: steps.runs-exist.outcome == 'success'
        uses: actions/checkout@v2
        with:
          ref: targets-runs
          fetch-depth: 1
          path: .targets-runs

      - name: Restore output files from the previous run
        if: steps.runs-exist.outcome == 'success'
        run: |
          nix-shell default.nix --run "Rscript -e 'for (dest in scan(\".targets-runs/.targets-files\", what = character())) {
            source &lt;- file.path(\".targets-runs\", dest)
            if (!file.exists(dirname(dest))) dir.create(dirname(dest), recursive = TRUE)
            if (file.exists(source)) file.rename(source, dest)
          }'"

      - name: Run model
        run: |
          nix-shell default.nix --run "Rscript -e 'targets::tar_make()'"

      - name: Identify files that the targets pipeline produced
        run: git ls-files -mo --exclude=renv &gt; .targets-files

      - name: Create the runs branch if it does not already exist
        if: steps.runs-exist.outcome != 'success'
        run: git checkout --orphan targets-runs

      - name: Put the worktree in the runs branch if the latter already exists
        if: steps.runs-exist.outcome == 'success'
        run: |
          rm -r .git
          mv .targets-runs/.git .
          rm -r .targets-runs

      - name: Upload latest run
        run: |
          git config --local user.name "GitHub Actions"
          git config --local user.email "actions@github.com"
          rm -r .gitignore .github/workflows
          git add --all -- ':!renv'
          for file in $(git ls-files -mo --exclude=renv)
          do
            git add --force $file
          done
          git commit -am "Run pipeline"
          git push origin targets-runs

      - name: Prepare failure artifact
        if: failure()
        run: rm -rf .git .github .targets-files .targets-runs

      - name: Post failure artifact
        if: failure()
        uses: actions/upload-artifact@main
        with:
          name: ${{ runner.os }}-r${{ matrix.config.r }}-results
          path: .</code></pre>
<p>
The workflow file above is heavily inspired from the one you get when you run <code>targets::tar_github_actions()</code>. Running this puts the following <a href="https://github.com/ropensci/targets/blob/22103e19584ea15ae44328c07bc9d2699b004a47/inst/templates/github_actions.yaml">file</a> on the root of your <code>{targets}</code> project. This file is a Github Actions workflow file, which means that each time you push your code on Github, the pipeline will run in the cloud. However it needs you to use <code>{renv}</code> with the project so that the right packages get installed. You’ll also see a step called <code>Install Linux dependencies</code> which you will have to adapt to your project.
</p>
<p>
All of this can be skipped when using Nix. All that must be done is installing Nix itself, using the <code>nix-installer-action</code> from Determinate Systems, then using the <code>magic-nix-cache-action</code> which caches the downloaded packages so we don’t need to wait for the environment to build each time we push (unless we changed the environment of course) and that’s about it. We then build the environment on Github Actions using <code>nix-build</code> and then run the pipeline using <code>nix-shell default.nix –run “Rscript -e ‘targets::tar_make()’”</code>. All the other steps are copied almost verbatim from the linked file above and make sure that the computed targets only get recomputed if I edit anything that impacts them, and also that they get pushed into a branch called <code>targets-runs</code>. I say <em>copied almost verbatim</em> because some steps must run inside R, so we need to specify that we want to use the R that is available through the Nix environment we just built.
</p>
<p>
Now, each time we push, the following happens:
</p>
<ul>
<li>
if we didn’t change anything to <code>default.nix</code>, the environment gets retrieved from the cache. If we did change something, then environment gets rebuilt (or rather, only the parts that need to be rebuilt, the rest will still get retrieved from the cache)
</li>
<li>
if we didn’t change anything to the <code>_targets.R</code> pipeline itself, then every target will get skipped. If not, only the targets that need to get recomputed will get recomputed.
</li>
</ul>
<p>
One last thing that I didn’t mention: on line 9 you’ll see this:
</p>
<pre><code>runs-on: ubuntu-latest</code></pre>
<p>
this means that the Github Actions will run on the latest available version of Ubuntu, which is obviously not fixed. When the next LTS gets released in April 2024, this pipeline will be running on Ubuntu 24.04 instead of the current LTS, version 22.04. This is not good practice because we don’t want the underlying operating system to be changing, because this could have an impact on the reproducibility of our pipeline. But with Nix, this <strong>does not matter</strong>. Remember that we are using a specific revision of <code>nixpkgs</code> for our pipeline, so the <em>exact</em> same version of not only R and R packages gets installed, but every underlying piece of software that needs to be available will be installed as well. We could be running this in 50 years on Ubuntu LTS 74.04 and it would still install the same stuff and run the same code and produce exactly the same results.
</p>
<p>
This is really bonkers.
</p>
<p>
Nix is an incredibly powerful tool. I’ve been exploring and using it for 3 months now, but if something impresses me more than how useful it is, is how terribly unknown it still is. I hope that this series of blog posts will motivate other people to learn it.
</p>



 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2023-09-20-nix_for_r_part6.html</guid>
  <pubDate>Wed, 20 Sep 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 5 – Reproducible literate programming with Nix and Quarto</title>
  <link>https://b-rodrigues.github.io/posts/2023-09-15-nix_for_r_part5.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/ayylmao.png" max-width="100%">
</p>
</div>
<p>
<em>This blog post is a copy-paste from <a href="https://b-rodrigues.github.io/rix/articles/building-an-environment-for-literate-programming.html">this vignette</a></em>
</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">
Introduction
</h2>
<p>
This vignette will walk you through setting up a development environment with <code>{rix}</code> that can be used to compile Quarto documents into PDFs. We are going to use the <a href="https://github.com/quarto-journals/jss">Quarto template for the JSS</a> to illustrate the process. The first section will show a simple way of achieving this, which will also be ideal for interactive development (writing the doc). The second section will discuss a way to build the document in a completely reproducible manner once it’s done.
</p>
</section>
<section id="starting-with-the-basics-simple-but-not-entirely-reproducible" class="level2">
<h2 class="anchored" data-anchor-id="starting-with-the-basics-simple-but-not-entirely-reproducible">
Starting with the basics (simple but not entirely reproducible)
</h2>
<p>
This approach will not be the most optimal, but it will be the simplest. We will start by building a development environment with all our dependencies, and we can then use it to compile our document interactively. But this approach is not quite reproducible and requires manual actions. In the next section we will show you to build a 100% reproducible document in a single command.
</p>
<p>
Since we need both the <code>{quarto}</code> R package as well as the <code>quarto</code> engine, we add both of them to the <code>r_pkgs</code> and <code>system_pkgs</code> of arguments of <code>{rix}</code>. Because we want to compile a PDF, we also need to have <code>texlive</code> installed, as well as some LaTeX packages. For this, we use the <code>tex_pkgs</code> argument:
</p>
<pre class="r"><code>library(rix)

path_default_nix &lt;- tempdir()

rix(r_ver = "4.3.1",
    r_pkgs = c("quarto"),
    system_pkgs = "quarto",
    tex_pkgs = c("amsmath"),
    ide = "other",
    shell_hook = "",
    project_path = path_default_nix,
    overwrite = TRUE,
    print = TRUE)</code></pre>
<pre><code>## # This file was generated by the {rix} R package v0.4.1 on 2023-12-19
## # with following call:
## # &gt;rix(r_ver = "976fa3369d722e76f37c77493d99829540d43845",
## #  &gt; r_pkgs = c("quarto"),
## #  &gt; system_pkgs = "quarto",
## #  &gt; tex_pkgs = c("amsmath"),
## #  &gt; ide = "other",
## #  &gt; project_path = path_default_nix,
## #  &gt; overwrite = TRUE,
## #  &gt; print = TRUE,
## #  &gt; shell_hook = "")
## # It uses nixpkgs' revision 976fa3369d722e76f37c77493d99829540d43845 for reproducibility purposes
## # which will install R version 4.3.1
## # Report any issues to https://github.com/b-rodrigues/rix
## let
##  pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz") {};
##  rpkgs = builtins.attrValues {
##   inherit (pkgs.rPackages) quarto;
## };
##   tex = (pkgs.texlive.combine {
##   inherit (pkgs.texlive) scheme-small amsmath;
## });
##  system_packages = builtins.attrValues {
##   inherit (pkgs) R glibcLocalesUtf8 quarto;
## };
##   in
##   pkgs.mkShell {
##     LOCALE_ARCHIVE = if pkgs.system == "x86_64-linux" then  "${pkgs.glibcLocalesUtf8}/lib/locale/locale-archive" else "";
##     LANG = "en_US.UTF-8";
##     LC_ALL = "en_US.UTF-8";
##     LC_TIME = "en_US.UTF-8";
##     LC_MONETARY = "en_US.UTF-8";
##     LC_PAPER = "en_US.UTF-8";
##     LC_MEASUREMENT = "en_US.UTF-8";
## 
##     buildInputs = [  rpkgs tex system_packages  ];
##       
##   }</code></pre>
<p>
(Save these lines into a script called <code>build_env.R</code> for instance, and run the script into a new folder made for this project.)
</p>
<p>
By default, <code>{rix}</code> will install the “small” version of the <code>texlive</code> distribution available on Nix. To see which <code>texlive</code> packages get installed with this small version, you can click <a href="https://search.nixos.org/packages?channel=unstable&amp;show=texlive.combined.scheme-small&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=scheme-small">here</a>. We start by adding the <code>amsmath</code> package then build the environment using:
</p>
<pre class="r"><code>nix_build()</code></pre>
<p>
Then, drop into the Nix shell with <code>nix-shell</code>, and run <code>quarto add quarto-journals/jss</code>. This will install the template linked above. Then, in the folder that contains <code>build_env.R</code>, the generated <code>default.nix</code> and <code>result</code> download the following files from <a href="https://github.com/quarto-journals/jss/">here</a>:
</p>
<ul>
<li>
article-visualization.pdf
</li>
<li>
bibliography.bib
</li>
<li>
template.qmd
</li>
</ul>
<p>
and try to compile <code>template.qmd</code> by running:
</p>
<pre><code>quarto render template.qmd --to jss-pdf</code></pre>
<p>
You should get the following error message:
</p>
<pre><code>Quitting from lines 99-101 [unnamed-chunk-1] (template.qmd)
Error in `find.package()`:
! there is no package called 'MASS'
Backtrace:
 1. utils::data("quine", package = "MASS")
 2. base::find.package(package, lib.loc, verbose = verbose)
Execution halted
</code></pre>
<p>
So there’s an R chunk in <code>template.qmd</code> that uses the <code>{MASS}</code> package. Change <code>build_env.R</code> to generate a new <code>default.nix</code> file that will now add <code>{MASS}</code> to the environment when built:
</p>
<pre class="r"><code>rix(r_ver = "4.3.1",
    r_pkgs = c("quarto", "MASS"),
    system_pkgs = "quarto",
    tex_pkgs = c("amsmath"),
    ide = "other",
    shell_hook = "",
    project_path = path_default_nix,
    overwrite = TRUE,
    print = TRUE)</code></pre>
<pre><code>## # This file was generated by the {rix} R package v0.4.1 on 2023-12-19
## # with following call:
## # &gt;rix(r_ver = "976fa3369d722e76f37c77493d99829540d43845",
## #  &gt; r_pkgs = c("quarto",
## #  &gt; "MASS"),
## #  &gt; system_pkgs = "quarto",
## #  &gt; tex_pkgs = c("amsmath"),
## #  &gt; ide = "other",
## #  &gt; project_path = path_default_nix,
## #  &gt; overwrite = TRUE,
## #  &gt; print = TRUE,
## #  &gt; shell_hook = "")
## # It uses nixpkgs' revision 976fa3369d722e76f37c77493d99829540d43845 for reproducibility purposes
## # which will install R version 4.3.1
## # Report any issues to https://github.com/b-rodrigues/rix
## let
##  pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz") {};
##  rpkgs = builtins.attrValues {
##   inherit (pkgs.rPackages) quarto MASS;
## };
##   tex = (pkgs.texlive.combine {
##   inherit (pkgs.texlive) scheme-small amsmath;
## });
##  system_packages = builtins.attrValues {
##   inherit (pkgs) R glibcLocalesUtf8 quarto;
## };
##   in
##   pkgs.mkShell {
##     LOCALE_ARCHIVE = if pkgs.system == "x86_64-linux" then  "${pkgs.glibcLocalesUtf8}/lib/locale/locale-archive" else "";
##     LANG = "en_US.UTF-8";
##     LC_ALL = "en_US.UTF-8";
##     LC_TIME = "en_US.UTF-8";
##     LC_MONETARY = "en_US.UTF-8";
##     LC_PAPER = "en_US.UTF-8";
##     LC_MEASUREMENT = "en_US.UTF-8";
## 
##     buildInputs = [  rpkgs tex system_packages  ];
##       
##   }</code></pre>
<p>
Trying to compile the document results now in another error message:
</p>
<pre><code>compilation failed- no matching packages
LaTeX Error: File `orcidlink.sty' not found</code></pre>
<p>
This means that the LaTeX <code>orcidlink</code> package is missing, and we can solve the problem by adding <code>“orcidlink”</code> to the list of <code>tex_pkgs</code>. Rebuild the environment and try again to compile the template. Trying again yields a new error:
</p>
<pre><code>compilation failed- no matching packages
LaTeX Error: File `tcolorbox.sty' not found.</code></pre>
<p>
Just as before, add the <code>tcolorbox</code> package to the list of <code>tex_pkgs</code>. You will need to do this several times for some other packages. There is unfortunately no easier way to list the dependencies and requirements of a LaTeX document.
</p>
<p>
This is what the final script to build the environment looks like:
</p>
<pre class="r"><code>rix(r_ver = "4.3.1",
    r_pkgs = c("quarto", "MASS"),
    system_pkgs = "quarto",
    tex_pkgs = c(
      "amsmath",
      "environ",
      "fontawesome5",
      "orcidlink",
      "pdfcol",
      "tcolorbox",
      "tikzfill"
    ),
    ide = "other",
    shell_hook = "",
    project_path = path_default_nix,
    overwrite = TRUE,
    print = TRUE)</code></pre>
<pre><code>## # This file was generated by the {rix} R package v0.4.1 on 2023-12-19
## # with following call:
## # &gt;rix(r_ver = "976fa3369d722e76f37c77493d99829540d43845",
## #  &gt; r_pkgs = c("quarto",
## #  &gt; "MASS"),
## #  &gt; system_pkgs = "quarto",
## #  &gt; tex_pkgs = c("amsmath",
## #  &gt; "environ",
## #  &gt; "fontawesome5",
## #  &gt; "orcidlink",
## #  &gt; "pdfcol",
## #  &gt; "tcolorbox",
## #  &gt; "tikzfill"),
## #  &gt; ide = "other",
## #  &gt; project_path = path_default_nix,
## #  &gt; overwrite = TRUE,
## #  &gt; print = TRUE,
## #  &gt; shell_hook = "")
## # It uses nixpkgs' revision 976fa3369d722e76f37c77493d99829540d43845 for reproducibility purposes
## # which will install R version 4.3.1
## # Report any issues to https://github.com/b-rodrigues/rix
## let
##  pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz") {};
##  rpkgs = builtins.attrValues {
##   inherit (pkgs.rPackages) quarto MASS;
## };
##   tex = (pkgs.texlive.combine {
##   inherit (pkgs.texlive) scheme-small amsmath environ fontawesome5 orcidlink pdfcol tcolorbox tikzfill;
## });
##  system_packages = builtins.attrValues {
##   inherit (pkgs) R glibcLocalesUtf8 quarto;
## };
##   in
##   pkgs.mkShell {
##     LOCALE_ARCHIVE = if pkgs.system == "x86_64-linux" then  "${pkgs.glibcLocalesUtf8}/lib/locale/locale-archive" else "";
##     LANG = "en_US.UTF-8";
##     LC_ALL = "en_US.UTF-8";
##     LC_TIME = "en_US.UTF-8";
##     LC_MONETARY = "en_US.UTF-8";
##     LC_PAPER = "en_US.UTF-8";
##     LC_MEASUREMENT = "en_US.UTF-8";
## 
##     buildInputs = [  rpkgs tex system_packages  ];
##       
##   }</code></pre>
<p>
The template will now compile with this environment. To look for a LaTeX package, you can use the <a href="https://ctan.org/pkg/orcidlink?lang=en">search engine on CTAN</a>.
</p>
<p>
As stated in the beginning of this section, this approach is not the most optimal, but it has its merits, especially if you’re still working on the document. Once the environment is set up, you can simply work on the doc and compile it as needed using <code>quarto render</code>. In the next section, we will explain how to build a 100% reproducible document.
</p>
</section>
<section id="reproducible-literate-programming" class="level2">
<h2 class="anchored" data-anchor-id="reproducible-literate-programming">
100% reproducible literate programming
</h2>
<p>
Let’s not forget that Nix is not just a package manager, but also a programming language. The <code>default.nix</code> files that <code>{rix}</code> generates are written in this language, which was made entirely for the purpose of building software. If you are not a developer, you may not realise it but the process of compiling a Quarto or LaTeX document is very similar to the process of building any piece of software. So we can use Nix to compile a document in a completely reproducible environment.
</p>
<p>
First, let’s fork the repo that contains the Quarto template we need. We will fork <a href="https://github.com/quarto-journals/jss">this repo</a>. This repo contains the <code>template.qmd</code> file that we can change (which is why we fork it, in practice we would replace this <code>template.qmd</code> by our own, finished, source <code>.qmd</code> file). Now we need to change our <code>default.nix</code>:
</p>
<pre><code>let
 pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz") {};
 rpkgs = builtins.attrValues {
   inherit (pkgs.rPackages) quarto MASS;
 };
 tex = (pkgs.texlive.combine {
   inherit (pkgs.texlive) scheme-small amsmath environ fontawesome5 orcidlink pdfcol tcolorbox tikzfill;
 });
 system_packages = builtins.attrValues {
   inherit (pkgs) R quarto;
 };
 in
 pkgs.mkShell {
   buildInputs = [  rpkgs tex system_packages  ];
 }</code></pre>
<p>
to the following:
</p>
<pre><code>let
 pkgs = import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/976fa3369d722e76f37c77493d99829540d43845.tar.gz") {};
 rpkgs = builtins.attrValues {
  inherit (pkgs.rPackages) quarto MASS;
 };
 tex = (pkgs.texlive.combine {
  inherit (pkgs.texlive) scheme-small amsmath environ fontawesome5 orcidlink pdfcol tcolorbox tikzfill;
 });
 system_packages = builtins.attrValues {
  inherit (pkgs) R quarto;
 };
 in
 pkgs.stdenv.mkDerivation {
   name = "my-paper";
   src = pkgs.fetchgit {
       url = "https://github.com/b-rodrigues/my_paper/";
       branchName = "main";
       rev = "715e9f007d104c23763cebaf03782b8e80cb5445";
       sha256 = "sha256-e8Xg7nJookKoIfiJVTGoJkvCuFNTT83YZ6SK3GT2T8g=";
     };
   buildInputs = [  rpkgs tex system_packages  ];
   buildPhase =
     ''
     # Deno needs to add stuff to $HOME/.cache
     # so we give it a home to do this
     mkdir home
     export HOME=$PWD/home
     quarto add --no-prompt $src
     quarto render $PWD/template.qmd --to jss-pdf
     '';
   installPhase =
     ''
     mkdir -p $out
     cp template.pdf $out/
     '';
 }</code></pre>
<p>
So we changed the second part of the file, we’re not building a shell anymore using <code>mkShell</code>, but a <em>derivation</em>. <em>Derivation</em> is Nix jargon for package, or software. So what is our derivation? First, we clone the repo we forked just before (I forked the repository and called it <code>my_paper</code>):
</p>
<pre><code>pkgs.stdenv.mkDerivation {
  name = "my-paper";
  src = pkgs.fetchgit {
      url = "https://github.com/b-rodrigues/my_paper/";
      branchName = "main";
      rev = "715e9f007d104c23763cebaf03782b8e80cb5445";
      sha256 = "sha256-e8Xg7nJookKoIfiJVTGoJkvCuFNTT83YZ6SK3GT2T8g=";
    };</code></pre>
<p>
This repo contains our quarto template, and because we’re using a specific commit, we will always use exactly this release of the template for our document. This is in contrast to before where we used <code>quarto add quarto-journals/jss</code> to install the template. Doing this interactively makes our project not reproducible because if we compile our Quarto doc today, we would be using the template as it is today, but if we compile the document in 6 months, then we would be using the template as it would be in 6 months (I should say that it is possible to install specific releases of Quarto templates using following notation: <code>quarto add quarto-journals/jss@v0.9.2</code> so this problem can be mitigated).
</p>
<p>
The next part of the file contains following lines:
</p>
<pre><code>buildInputs = [  rpkgs tex system_packages  ];
buildPhase =
  ''
  # Deno needs to add stuff to $HOME/.cache
  # so we give it a home to do this
  mkdir home
  export HOME=$PWD/home
  quarto add --no-prompt $src
  quarto render $PWD/template.qmd --to jss-pdf
  '';</code></pre>
<p>
The <code>buildInputs</code> are the same as before. What’s new is the <code>buildPhase</code>. This is actually the part in which the document gets compiled. The first step is to create a <code>home</code> directory. This is because Quarto needs to save the template we want to use in <code>/home/.cache/deno</code>. If you’re using <code>quarto</code> interactively, that’s not an issue, since your home directory will be used. But with Nix, things are different, so we need to create an empty directory and specify this as the home. This is what these two lines do:
</p>
<pre><code>mkdir home
export HOME=$PWD/home</code></pre>
<p>
(<code>$PWD</code> —Print Working Directory— is a shell variable referring to the current working directory.)
</p>
<p>
Now, we need to install the template that we cloned from Github. For this we can use <code>quarto add</code> just as before, but instead of installing it directly from Github, we install it from the repository that we cloned. We also add the <code>–no-prompt</code> flag so that the template gets installed without asking us for confirmation. This is similar to how when building a Docker image, we don’t want any interactive prompt to show up, or else the process will get stuck. <code>$src</code> refers to the path of our downloaded Github repository. Finally we can compile the document:
</p>
<pre><code>quarto render $PWD/template.qmd --to jss-pdf</code></pre>
<p>
This will compile the <code>template.qmd</code> (our finished paper). Finally, there’s the <code>installPhase</code>:
</p>
<pre><code>installPhase =
  ''
  mkdir -p $out
  cp template.pdf $out/
  '';</code></pre>
<p>
<code>$out</code> is a shell variable defined inside the build environment and refers to the path, so we can use it to create a directory that will contain our output (the compiled PDF file). So we use <code>mkdir -p</code> to recursively create all the directory structure, and then copy the compiled document to <code>$out/</code>. We can now build our document by running <code>nix_build()</code>. Now, you may be confused by the fact that you won’t see the PDF in your working directory. But remember that software built by Nix will always be stored in the Nix store, so our PDF is also in the store, since this is what we built. To find it, run:
</p>
<pre><code>readlink result</code></pre>
<p>
which will show the path to the PDF. You could use this to open the PDF in your PDF viewer application (on Linux at least):
</p>
<pre><code>xdg-open $(readlink result)/template.pdf</code></pre>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">
Conclusion
</h2>
<p>
This vignette showed two approaches, both have their merits: the first approach that is more interactive is useful while writing the document. You get access to a shell and can work on the document and compile it quickly. The second approach is more useful once the document is ready and you want to have a way of quickly rebuilding it for reproducibility purposes. This approach should also be quite useful in a CI/CD environment.
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2023-09-15-nix_for_r_part5.html</guid>
  <pubDate>Fri, 15 Sep 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 4 – So long, {renv} and Docker, and thanks for all the fish</title>
  <link>https://b-rodrigues.github.io/posts/2023-08-12-nix_for_r_part4.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/friendship ended with docker.png" width="100%">
</p>
</div>
<p>
For this blog post, I also made a youtube video that goes over roughly the same ideas, but the blog post is more detailed as I explain the contents of <code>default.nix</code> files, which I don’t do in the video. Watch the video <a href="https://www.youtube.com/watch?v=c1LhgeTTxaI">here</a>.
</p>
<p>
This is the fourth post in a series of posts about Nix. <em>Disclaimer:</em> I’m a super beginner with Nix. So this series of blog posts is more akin to notes that I’m taking while learning than a super detailed Nix tutorial. So if you’re a Nix expert and read something stupid in here, that’s normal. This post is going to focus on R (obviously) but the ideas are applicable to any programming language.
</p>
<p>
If you’ve never heard of Nix, take a look at <a href="../posts/2023-07-13-nix_for_r_part1.html">part 1</a>.
</p>
<p>
In this blog post I will go over many, nitty-gritty details and explain, line by line, what a Nix expression you can use to build an environment for your projects contains. In practice, building such an environment allows you to essentially replace <code>{renv}</code>+Docker, but writing the right expressions to achieve it is not easy. So this blog post will also go over the features of <code>{rix}</code>, an <a href="https://docs.ropensci.org/rix/">R package</a> by <a href="https://github.com/philipp-baumann">Philipp Baumann</a> and myself.
</p>
<p>
Let me also address the click-bait title directly. Yes, the title is click-bait and I got you. I don’t believe that <code>{renv}</code> and Docker are going away any time soon and you should not hesitate to invest the required time to get to know and use these tools (I wrote <a href="https://raps-with-r.dev/">something by the way</a>). But I am more and more convinced that Nix is an amazing alternative that offers many possibilities, albeit with a high entry cost. By writing <code>{rix}</code>, we aimed at decreasing this entry cost as much as possible. However, more documentation, examples, etc., need to be written and more testing is required. This series of blog posts is a first step to get the word out and get people interested in the package and more broadly in Nix. So if you’re interested or intrigued, don’t hesitate to get in touch!
</p>
<p>
This will be a long and boring post. Unless you really want to know how all of this works go watch the Youtube video, which is more practical instead. I needed to write this down, as it will likely serve as documentation. I’m essentially beta testing it with you, so if you do take the time to read, and even better, to try out the code, please let us know how it went! Was it clear, was it simple, was it useful? Many thanks in advance.
</p>
<section id="part-1-starting-a-new-project-with-nix" class="level2">
<h2 class="anchored" data-anchor-id="part-1-starting-a-new-project-with-nix">
Part 1: starting a new project with Nix
</h2>
<p>
Let’s suppose that you don’t even have R installed on your computer yet. Maybe you bought a new computer, or changed operating system, whatever. Maybe you even have R already, which you installed from the installer that you can download from the R project website. It doesn’t matter, as we are going to install a (somewhat) isolated version of R using Nix for the purposes of this blog post. If you don’t know where to start, it’s simple: first, use the <a href="https://zero-to-nix.com/start/install">installer from Determinate Systems</a>. This installer will make it easy to install Nix on Linux, macOS or Windows (with WSL2). Once you have Nix installed, you can use it to install R and <code>{rix}</code> to start building reproducible development environments. To help you get started, you can run this line here (as documented in <code>{rix}</code>’s Readme), which will <em>drop you into a Nix shell</em> with R and <code>{rix}</code> available. Run the line inside a terminal (if you’re running Windows, run this in a Linux distribution that you installed for WSL2):
</p>
<pre><code>nix-shell --expr "$(curl -sl https://raw.githubusercontent.com/b-rodrigues/rix/master/inst/extdata/default.nix)"</code></pre>
<p>
This will take a bit to run, and then you will be inside an R session. This environment is not suited for development, but is only provided as an easy way for you to start using <code>{rix}</code>. Using <code>{rix}</code>, you can now use it to create a more complex environment suited for a project that you would like to start. Let’s start by loading <code>{rix}</code>:
</p>
<pre class="r"><code>library(rix)</code></pre>
<p>
Now you can run the following command to create an environment with the latest version of R and some packages (change the R version and list of packages to suit your needs):
</p>
<pre class="r"><code>path_default_nix &lt;- "path/to/my/project"

rix(r_ver = "current",
    r_pkgs = c("dplyr", "ggplot2"),
    other_pkgs = NULL,
    git_pkgs = list(package_name = "housing",
                    repo_url = "https://github.com/rap4all/housing",
                    branch_name = "fusen",
                    commit = "1c860959310b80e67c41f7bbdc3e84cef00df18e"),
    ide = "rstudio",
    project_path = path_default_nix,
    overwrite = TRUE)</code></pre>
<p>
Running the code above will create the following <code>default.nix</code> file in <code>path/to/my/project</code>:
</p>
<pre><code># This file was generated by the {rix} R package on Sat Aug 12 22:18:55 2023
# with following call:
# &gt;rix(r_ver = "cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd",
#  &gt; r_pkgs = c("dplyr",
#  &gt; "ggplot2"),
#  &gt; other_pkgs = NULL,
#  &gt; git_pkgs = list(package_name = "housing",
#  &gt; repo_url = "https://github.com/rap4all/housing",
#  &gt; branch_name = "fusen",
#  &gt; commit = "1c860959310b80e67c41f7bbdc3e84cef00df18e"),
#  &gt; ide = "rstudio",
#  &gt; project_path = path_default_nix,
#  &gt; overwrite = TRUE)
# It uses nixpkgs' revision cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd for reproducibility purposes
# which will install R as it was as of nixpkgs revision: cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd
# Report any issues to https://github.com/b-rodrigues/rix
{ pkgs ? import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd.tar.gz") {} }:

with pkgs;

let
  my-r = rWrapper.override {
    packages = with rPackages; [
        dplyr
        ggplot2
        (buildRPackage {
          name = "housing";
          src = fetchgit {
          url = "https://github.com/rap4all/housing";
          branchName = "fusen";
          rev = "1c860959310b80e67c41f7bbdc3e84cef00df18e";
          sha256 = "sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=";
          };
          propagatedBuildInputs = [
            dplyr
            ggplot2
            janitor
            purrr
            readxl
            rlang
            rvest
            stringr
            tidyr
            ];
          })
        ];
    };
  my-rstudio = rstudioWrapper.override {
    packages = with rPackages; [
        dplyr
        ggplot2
        (buildRPackage {
          name = "housing";
          src = fetchgit {
          url = "https://github.com/rap4all/housing";
          branchName = "fusen";
          rev = "1c860959310b80e67c41f7bbdc3e84cef00df18e";
          sha256 = "sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=";
          };
          propagatedBuildInputs = [
            dplyr
            ggplot2
            janitor
            purrr
            readxl
            rlang
            rvest
            stringr
            tidyr
            ];
          })
        ];
    };
in
 mkShell {
   LOCALE_ARCHIVE = "${glibcLocales}/lib/locale/locale-archive";
     buildInputs = [
        my-r
        my-rstudio
      ];
 }</code></pre>
<p>
Let’s go through it. The first thing you will notice is that this file is written in a language that you might not know: this language is called Nix as well! So <em>Nix</em> can both refer to the package manager, but also to the programming language. The Nix programming language was designed for creating and composing <em>derivations</em>. A derivation is Nix jargon for a package (not necessarily an R package; any piece of software that you can install through Nix is a package). To know more about the language itself, you can <a href="https://nixos.org/manual/nix/stable/language/index.html">RTFM</a>.
</p>
<p>
Let’s go back to our <code>default.nix</code> file. The first lines state the revision of <code>nixpkgs</code> used that is being used in this expression, as well as which version of R gets installed through it. <code>nixpkgs</code> is Nix’s repository which contains all the software that we will be installing. This is important to understand: since all the expressions that build all the software available through <code>nixpkgs</code> are versioned on <a href="https://github.com/NixOS/nixpkgs/tree/master/pkgs">Github</a>, it is possible to choose a particular commit, or revision, and use that particular release of <code>nixpkgs</code>. So by judiciously choosing the right commit, it’s possible to install any version of R (well any version until 3.0.2). <code>{rix}</code> takes care of this for you: state the version of R that is needed, and the right revision will be returned (the list of R versions and revisions can be found <a href="https://lazamar.co.uk/nix-versions/?channel=nixpkgs-unstable&amp;package=r">here</a>).
</p>
<p>
The call that was used to generate the <code>default.nix</code> file is also saved, but if you look at the argument <code>r_ver</code>, the <code>nixpkgs</code> revision is specified instead of <code>“current”</code>. This is because if you re-run this call but keep <code>r_ver = “current”</code>, another, more recent <code>nixpkgs</code> revision will get used instead, which will break reproducibility. To avoid this, the expression gets changed, so if you re-run it, you’re sure to find the exact same environment.
</p>
<p>
Then comes this line:
</p>
<pre><code>{ pkgs ? import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd.tar.gz") {} }:</code></pre>
<p>
This actually defines a function with argument <code>pkgs</code> that is optional (hence the <code>?</code>). All that follows, <code>import (fetchTarball … ) {}</code> is the default value for <code>pkgs</code> if no argument is provided when you run this (which will always be the case). So here, if I call this function without providing any <code>pkgs</code> argument, the release of <code>nixpkgs</code> at that commit will be used. Then comes:
</p>
<pre><code>with pkgs;

let
  my-pkgs = rWrapper.override {
    packages = with rPackages; [
      dplyr
      ggplot2</code></pre>
<p>
The <code>with pkgs</code> statement makes all the imported packages available in the scope of the function. So I can write <code>quarto</code> if I want to install Quarto (the program that compiles <code>.qmd</code> files, not the <code>{quarto}</code> R package that provides bindings to it) instead of <code>nixpkgs.quarto</code>. Actually, R also has <code>with()</code>, so you can write this:
</p>
<pre class="r"><code>with(mtcars, plot(mpg ~ hp))</code></pre>
<p>
<img src="https://b-rodrigues.github.io/assets/img/nix_for_r_part4-3-1.png" width="672">
</p>
<p>
instead of this:
</p>
<pre class="r"><code>plot(mtcars$mpg ~ mtcars$hp)</code></pre>
<p>
Then follows a <code>let … in</code>. This is how a variable gets defined locally, for example, this is a valid Nix statement:
</p>
<pre><code>let x = 1; y = 2; in x + y</code></pre>
<p>
which will obviously return <code>3</code>. So here we are defining a series of packages that will ultimately be available in our environment. These packages are named <code>my-pkgs</code> and are a list of R packages. You can see that I use a wrapper called <code>rWrapper</code> which changes certain options to make R installed through Nix work well. This wrapper has a <code>packages</code> attribute which I override using its <code>.override</code> method, and then I redefine <code>packages</code> as a list of R packages. Just like before, I use <code>with rPackages</code> before listing them, which allows me to write <code>dplyr</code> instead of <code>rPackages.dplyr</code> to refer to the <code>{dplyr}</code> packages. R packages that have a <code>.</code> character in their name must be written using <code>_</code>, so if you need <code>{data.table}</code> you’ll need to write <code>data_table</code> (but <code>{rix}</code> does this for you as well, so don’t worry). Then follows the list of R packages available through <code>nixpkgs</code> (which is the entirety of CRAN:
</p>
<pre><code>packages = with rPackages; [
          dplyr
          ggplot2</code></pre>
<p>
Each time you need to add a package, add it here, and rebuild your environment, do not run <code>install.packages(blabla)</code> to install the <code>{blabla}</code> package, because it’s likely not going to work anyways, and it’s not reproducible. Your projects need to be entirely defined as code. This also means that packages that have helper functions that install something, for example <code>tinytex::install_tinytex()</code>, cannot be used anymore. Instead, you will need to install <code>texlive</code> (by putting it in <code>other_pkgs</code>) and rebuild the expression. We plan to write vignettes documenting all these use-cases. For example, my blog is still built using Hugo (and will likely stay like this forever). I’m using a very old version of Hugo to generate it (I don’t want to upgrade and have to deal with potential issues), so I install the right version I need using Nix, instead of using <code>blogdown::install_hugo()</code>.
</p>
<p>
Then comes the expression that installs a package from Github:
</p>
<pre><code>(buildRPackage {
  name = "housing";
  src = fetchgit {
  url = "https://github.com/rap4all/housing";
  branchName = "fusen";
  rev = "1c860959310b80e67c41f7bbdc3e84cef00df18e";
  sha256 = "sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=";
  };
  propagatedBuildInputs = [
    dplyr
    ggplot2
    janitor
    purrr
    readxl
    rlang
    rvest
    stringr
    tidyr
    ];
})</code></pre>
<p>
As you can see it’s quite a mouthful, but it was generated from this R code only:
</p>
<pre class="r"><code>git_pkgs = list(package_name = "housing",
                repo_url = "https://github.com/rap4all/housing",
                branch_name = "fusen",
                commit = "1c860959310b80e67c41f7bbdc3e84cef00df18e"),</code></pre>
<p>
If you want to install more than one package, you can also provide a list of lists, for example:
</p>
<pre class="r"><code>git_pkgs = list(
  list(package_name = "housing",
       repo_url = "https://github.com/rap4all/housing/",
       branch_name = "fusen",
       commit = "1c860959310b80e67c41f7bbdc3e84cef00df18e"),
  list(package_name = "fusen",
       repo_url = "https://github.com/ThinkR-open/fusen",
       branch_name = "main",
       commit = "d617172447d2947efb20ad6a4463742b8a5d79dc")
),
...</code></pre>
<p>
and the right expressions will be generated. There’s actually a lot going on here, so let me explain. The first thing is the <code>sha256</code> field. This field contains a hash that gets generated by Nix, and that must be provided by the user. But users rarely, if ever, know this value, so instead what they do is they try to build the expression without providing it. An error message like this one gets returned:
</p>
<pre><code>error: hash mismatch in fixed-output derivation '/nix/store/449zx4p6x0yijym14q3jslg55kihzw66-housing-1c86095.drv':
         specified: sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=
            got:    sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=</code></pre>
<p>
The <code>sha256</code> can now get copy-and-pasted into the expression. This approach is called “Trust On First Use”, or TOFU for short. Because this is quite annoying, <code>{rix}</code> provides a “private” function, called <code>get_sri_hash_deps()</code> that generates this hash for you. The issue is that this hash cannot be computed easily if you don’t have Nix installed, and since I don’t want to force users to install Nix to use <code>{rix}</code>, what I did is that I set up a server with Nix installed and a <code>{plumber}</code> api. <code>get_sri_hash_deps()</code> makes a call to that api and gets back the <code>sha256</code>, and also a list of packages (more on this later).
</p>
<p>
You can try making a call to the api if you have <code>curl</code> installed on your system:
</p>
<pre><code>curl -X GET "http://git2nixsha.dev:1506/hash?repo_url=https://github.com/rap4all/housing/&amp;branchName=fusen&amp;commit=1c860959310b80e67c41f7bbdc3e84cef00df18e" -H "accept: */*"</code></pre>
<p>
This is what you will get back:
</p>
<pre><code>{
  "sri_hash" : ["sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4="],
  "deps"     : ["dplyr ggplot2 janitor purrr readxl rlang rvest stringr tidyr"]
}</code></pre>
<p>
The reason computing <code>sri_hash</code> is not easy is because it gets computed on the folder containing the source code (after having deleted the <code>.git</code> folder in the case of a Github repo) after it was <em>serialised</em>. You are certainly familiar with serialisations such as the ZIP or TAR serialisation (in other words, zipping a folder is “serialising” it). But these serialisation algorithms come with certain shortcomings that I won’t discuss here, but if you’re interested check out section <em>5.2. The Nix store</em> from Eelco Dolstra’s Phd thesis which you can find <a href="https://archive.is/S9meY">here</a>. Instead, a Nix-specific serialisation algorithm was developed, called NAR. So to compute this hash, I either had to implement this serialisation algorithm in R, or write an api that does that for me by using the implementation that ships with Nix. Since I’m not talented enough to implement such an algorithm in R, I went for the api. But who knows, maybe in the future this could be done. There are implementation of this algorithm in other programming languages like Rust, so maybe packaging the Rust binary could be an option.
</p>
<p>
This gets then further processed by <code>rix()</code>. The second thing that gets returned is a list of packages. These get scraped from the <code>Imports</code> and <code>LinkingTo</code> sections of the <code>DESCRIPTION</code> file from the package and are then provided as the <code>propagatedBuildInputs</code> in the Nix expression. These packages are dependencies that must be available to your package at build and run-time.
</p>
<p>
You should know that as of today (<code>{rix}</code> commit <code>15cadf7f</code>) GitHub packages that use the <code>Remotes</code> field (so that have dependencies that are also on Github) are not handled by <code>{rix}</code>, but supporting this is planned. What <code>{rix}</code> supports though is installing packages from the CRAN archives, so you can specify a version of a package and have that installed. For example:
</p>
<pre class="r"><code>rix(r_ver = "current",
    r_pkgs = c("dplyr@0.8.0", "ggplot2@3.1.1"),
    other_pkgs = NULL,
    git_pkgs = NULL,
    ide = "other",
    path = path_default_nix,
    overwrite = TRUE)</code></pre>
<p>
The difference with the <code>default.nix</code> file from before is that these packages get downloaded off the CRAN archives, so <code>fetchzip()</code> is used to download them instead of <code>fetchgit()</code> (both Nix functions). Here is what the generated Nix code looks like:
</p>
<pre><code>(buildRPackage {
  name = "dplyr";
  src = fetchzip {
  url = "https://cran.r-project.org/src/contrib/Archive/dplyr/dplyr_0.8.0.tar.gz";
  sha256 = "sha256-f30raalLd9KoZKZSxeTN71PG6BczXRIiP6g7EZeH09U=";
  };
  propagatedBuildInputs = [
    assertthat
    glue
    magrittr
    pkgconfig
    R6
    Rcpp
    rlang
    tibble
    tidyselect
    BH
    plogr
    Rcpp
    ];
})
(buildRPackage {
  name = "ggplot2";
  src = fetchzip {
  url = "https://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_3.1.1.tar.gz";
  sha256 = "sha256-0Qv/5V/XMsFBcGEFy+3IAaBJIscRMTwGong6fiP5Op0=";
  };
  propagatedBuildInputs = [
    digest
    gtable
    lazyeval
    MASS
    mgcv
    plyr
    reshape2
    rlang
    scales
    tibble
    viridisLite
    withr
    ];
})</code></pre>
<p>
Here’s what this looks like:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/new_r_old_pkgs.png" width="100%">
</p>
</div>
<p>
This feature should ideally be used sparingly. If you want to reconstruct an environment as it was around a specific date (for example to run an old project), use the version of R that was current at that time. This will ensure that every package that gets installed is at a version compatible with that version of R, which might not be the case if you need to install a very old version of one particular package. But this feature is quite useful if you want to install a package that is not available on CRAN anymore, but that is archived, like <a href="https://cran.r-project.org/web/packages/ZeligChoice/index.html">{ZeligChoice}</a>.
</p>
<p>
Then a second list of packages gets defined, this time using the <code>rstudioWrapper</code> wrapper. This is because I specified that I wanted to use RStudio, but RStudio is a bit peculiar. It redefines many paths and so if you have RStudio installed in your system, it won’t be able to “see” the R installed through Nix. So you have to install RStudio through Nix as well (this is not necessary for VS Code nor Emacs, and likely not for other editors as well). However, it is still necessary to provide each package, again, to the <code>rstudioWrapper</code>. This is because the RStudio installed through Nix is also not able to “see” the R installed through Nix as well. But don’t worry, this does not take twice the space, since the packages simply get symlinked.
</p>
<p>
The last part of the expression uses <code>mkShell</code> which builds a shell with the provided <code>buildInputs</code> (our list of packages). There is also a line to define the location of the locale archive, which should properly configure the locale of the shell (so language, time zone and units):
</p>
<pre><code>in
 mkShell {
   LOCALE_ARCHIVE = "${glibcLocales}/lib/locale/locale-archive";
     buildInputs = [
        my-r
        my-rstudio
      ];
 }</code></pre>
<p>
With this file in hand, we can now build the environment and use it.
</p>
</section>
<section id="part-2-using-your-environment" class="level2">
<h2 class="anchored" data-anchor-id="part-2-using-your-environment">
Part 2: using your environment
</h2>
<p>
So let’s suppose that you have a <code>default.nix</code> file and you wish to build the environment. To do so, you need to have Nix installed, and, thanks to the contributions of <a href="https://github.com/philipp-baumann">Philipp Baumann</a>, you can use <code>rix::nix_build()</code> to build the environment as well:
</p>
<pre class="r"><code>nix_build(project_path = path_default_nix, exec_mode = "blocking")</code></pre>
<p>
If you prefer, you can use Nix directly as well; navigate to the project folder containing the <code>default.nix</code> file and run the command line tool <code>nix-build</code> that gets installed with Nix:
</p>
<pre><code>nix-build</code></pre>
<p>
This will take some time to run, depending on whether cached binary packages can be pulled from <a href="https://cache.nixos.org/" class="uri">https://cache.nixos.org/</a> or not. Once the build process is done, you should see a file called <code>result</code> next to the <code>default.nix</code> file. You can now <em>drop</em> into the Nix shell by typing this into your operating system’s terminal (after you navigated to the folder containing the <code>default.nix</code> and <code>result</code> files):
</p>
<pre><code>nix-shell</code></pre>
<p>
(this time, you really have to leave your current R session! But Philipp and myself are thinking about how we could also streamline this part as well…).
</p>
<p>
The environment that you just built is not an entirely isolated environment: you can still interact with your computer, unlike with Docker. For example, you can still use programs that are installed on your computer. This means that you can run your usual editor as well, but starting it from the Nix shell will make your editor be able to “see” the R installed in that environment. You need to be careful with this, because sometimes this can lead to surprising behavior. For example, if you already have R installed with some packages, these packages could interfere with your Nix environment. There are two ways of dealing with this: you either only use Nix-based environments to work (which would be my primary recommendation, as there can be no interference between different Nix environments), or you call <code>nix-shell –pure</code> instead of just <code>nix-shell</code>. This will ensure that only whatever is available in the environment gets used, but be warned that Nix environments are very, very lean, so you might need to add some tools to have something completely functional.
</p>
<p>
We can take advantage of the fact that environments are not completely isolated to use our IDEs. For example, if you use VS Code or Emacs, you can use the one that is installed directly on your system, as explained before. As already explained, but to drive the point home, if you’re an RStudio user, you need to specify the <code>ide = “rstudio”</code> argument to <code>rix()</code>, because in the case of RStudio, it needs to be installed by Nix as well (the current available RStudio version installed by Nix is now out of date, but efforts are ongoing to update it). This is because RStudio looks for R runtimes in very specific paths, and these need to be patched to see Nix-provided R versions. Hence the version that gets installed by Nix gets patched so that RStudio is able to find the correct runtimes.
</p>
<p>
Once you dropped into the shell, simply type <code>rstudio</code> to launch RStudio in that environment (or <code>code</code> if you use VS Code or <code>other</code> if you use Emacs, or any other editor). On Linux, RStudio may fail to launch with this error message:
</p>
<pre><code>Could not initialize GLX
Aborted (core dumped)</code></pre>
<p>
change your <code>default.nix</code> file from this:
</p>
<pre><code>mkShell {
  LOCALE_ARCHIVE = "${glibcLocales}/lib/locale/locale-archive";
    buildInputs = [
       my-r
       my-rstudio
     ];
}</code></pre>
<p>
to this:
</p>
<pre><code>mkShell {
  LOCALE_ARCHIVE = "${glibcLocales}/lib/locale/locale-archive";
    buildInputs = [
       my-r
       my-rstudio
     ];
  shellHook = ''
    export QT_XCB_GL_INTEGRATION=none
  '';
}</code></pre>
<p>
which should solve the issue, which is related to hardware acceleration as far as I can tell.
</p>
<p>
<code>shellHook</code>s are a nice feature which I haven’t discussed a lot yet (I did so in part 2 of this series, to run a <code>{targets}</code> pipeline each time I dropped into the shell). Whatever goes into the <code>shellHook</code> gets executed as soon as one drops into the Nix shell. I personally have to add the <code>export QT_XCB_GL_INTEGRATION=none</code> line in on virtual machines and on my desktop computer as well, but I’ve had problems in the past with my graphics drivers, and I think it’s related. I’m planning also to add an option to <code>rix()</code> to add this automatically.
</p>
<p>
If you need to add packages, best is to call <code>rix::rix()</code> again, but this time, provide the <code>nixpkgs</code> revision as the argument to <code>r_ver</code>. Copy and paste the call from the generated <code>default.nix</code> to an R console and rerun it:
</p>
<pre class="r"><code>rix(r_ver = "cf73a86c35a84de0e2f3ba494327cf6fb51c0dfd",
    r_pkgs = c("dplyr", "ggplot2", "tidyr", "quarto"),
    other_pkgs = "quarto",
    git_pkgs = list(package_name = "housing",
                    repo_url = "https://github.com/rap4all/housing",
                    branch_name = "fusen",
                    commit = "1c860959310b80e67c41f7bbdc3e84cef00df18e"),
    ide = "rstudio",
    path = path_default_nix,
    overwrite = TRUE)</code></pre>
<p>
In the call above I’ve added the <code>{tidyr}</code> and <code>{quarto}</code> packages, as well as the <code>quarto</code> command line utility to generate <code>.qmd</code> files. For <code>r_ver</code> I’m this time using the <code>nixpkgs</code> revision from my original <code>default.nix</code> file. This will ensure that my environment stays the same.
</p>
<p>
So if you have read up until this point, let me first thank you, and secondly humbly ask you to test <code>{rix}</code>! I’m looking for testers, especially on Windows and macOS, and would be really grateful if you could provide some feedback on the package. To report anything, simply open issue <a href="https://github.com/b-rodrigues/rix/issues">here</a>.
</p>
<p>
<em>Thanks to Philipp for proof-reading this post.</em>
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2023-08-12-nix_for_r_part4.html</guid>
  <pubDate>Sat, 12 Aug 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 3 – frictionless {plumber} api deployments with Nix</title>
  <link>https://b-rodrigues.github.io/posts/2023-07-30-nix_for_r_part3.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/i_use_nix_for_all_my_package_management_needs.png" width="60%">
</p>
</div>
<p>
This is the third post in a series of posts about Nix. Disclaimer: I’m a super beginner with Nix. So this series of blog posts is more akin to notes that I’m taking while learning than a super detailed tutorial. So if you’re a Nix expert and read something stupid in here, that’s normal. This post is going to focus on R (obviously) but the ideas are applicable to any programming language.
</p>
<p>
This blog post is part tutorial on creating an api using the <code>{plumber}</code> R package, part an illustration of how Nix makes developing and deploying a breeze.
</p>
<section id="part-1-getting-it-to-work-locally" class="level2">
<h2 class="anchored" data-anchor-id="part-1-getting-it-to-work-locally">
Part 1: getting it to work locally
</h2>
<p>
So in <a href="../posts/2023-07-13-nix_for_r_part1.html">part 1</a> I explained what Nix was and how you could use it to build reproducible development environments. In <a href="../posts/2023-07-19-nix_for_r_part2.html">part 2</a> I talked about running a <code>{targets}</code> pipeline in a reproducible environment set up with Nix, and in this blog post I’ll talk about how I made an api using {plumber} and how Nix made going from my development environment to the production environment (on Digital Ocean) the simplest ever. Originally I wanted to focus on interactive work using Nix, but that’ll be very likely for part 4, maybe even part 5 (yes, I really have a lot to write about).
</p>
<p>
Let me just first explain what <code>{plumber}</code> is before continuing. I already talked about <code>{plumber}</code> <a href="../posts/2021-06-04-own_knit_server.html">here</a>, but in summary, <code>{plumber}</code> allows you to build an api. What is an api? Essentially a service that you can call in different ways and which returns something to you. For example, you could send a Word document to this api and get back the same document converted in PDF. Or you could send some English text and get back a translation. Or you could send some data and get a prediction from a machine learning model. It doesn’t matter: what’s important is that apis completely abstract the programming language that is being used to compute whatever should be computed. With <code>{plumber}</code>, you can create such services using R. This is pretty awesome, because it means that whatever it is you can make with R, you could build a service around it and make it available to anyone. Of course you need a server that actually has R installed and that gets and processes the requests it receives, and this is where the problems start. And by problems I mean THE single biggest problem that you have to deal with whenever you develop something on your computer, and then have to make it work somewhere else: deployment. If you’ve had to deal with deployments you might not understand why it’s so hard. I certainly didn’t really get it until I’ve wanted to deploy my first Shiny app, many moons ago. And this is especially true whenever you don’t want to use any “off the shelf” services like <em>shinyapps.io</em>. In the <a href="../posts/2021-06-04-own_knit_server.html">blog post I mentioned above</a>, I used Docker to deploy the api. But Docker, while an amazing tool, is also quite heavy to deal with. Nix offers an alternative to Docker which I think you should know and think about. Let me try to convince you.
</p>
<p>
So let’s make a little <code>{plumber}</code> api and deploy that in the cloud. For this, I’m using Digital Ocean, but any other service that allows you to spin a virtual machine (VM) with Ubuntu on it will do. If you don’t have a Digital Ocean account, you can use my <a href="https://m.do.co/c/b68adc727710">referral link</a> to get 200$ in credit for 60 days, more than enough to experiment. A VM&nbsp;serving a <code>{plumber}</code> api needs at least 1 gig of RAM, and the cheapest one with 1 gig of ram is 6$ a month (if you spend 25$ of that credit, I’ll get 25$ too, so don’t hesitate to experiment, you’ll be doing me a solid as well).
</p>
<p>
I won’t explain what my api does, this doesn’t really matter for this blog post. But I’ll have to explain it in a future blog post, because it’s related to a package I’m working on, called <a href="https://github.com/b-rodrigues/rix">{rix}</a> which I’m writing to ease the process of building reproducible environments for R using Nix. So for this blog post, let’s make something very simple: let’s take the classic machine learning task of predicting survival of the passengers of the Titanic (which was not that long ago in the news again…) and make a service out of it.
</p>
<p>
What’s going to happen is this: users will make a request to the api giving some basic info about themselves: a simple ML model (I’ll go with logistic regression and call it “machine learning” just to make the statisticians reading this seethe lmao), the machine learning model is going to use this to compute a prediction and the result will be returned to the user. Now to answer a question that comes up often when I explain this stuff: <em>why not use Shiny? Users can enter their data and get a prediction and there’s a nice UI and everything?!</em>. Well yes, but it depends on what it is you actually want to do. An api is useful mostly in situations where you need that request to be made by another machine and then that machine will do something else with that prediction it got back. It could be as simple as showing it in a nice interface, or maybe the machine that made the request will then use that prediction and insert it somewhere for archiving for example. So think of it this way: use an api when machines need to interact with other machines, a Shiny app for when humans need to interact with a machine.
</p>
<p>
Ok so first, because I’m using Nix, I’ll create an environment that will contain everything I need to build this api. I’m doing that in the most simple way possible, simply by specifying an R version and the packages I need inside a file called <code>default.nix</code>. Writing this file if you’re not familiar with Nix can be daunting, so I’ve developed a package, called <code>{rix}</code> to write these files for you. Calling this:
</p>
<pre class="r"><code>rix::rix(r_ver = "4.2.2",
         r_pkgs = c("plumber", "tidymodels"),
         other_pkgs = NULL,
         git_pkgs = NULL,
         ide = "other",
         path = "titanic_api/", # you might need to create this folder
         overwrite = TRUE)</code></pre>
<p>
generates this file for me:
</p>
<pre><code># This file was generated by the {rix} R package on Sat Jul 29 15:50:41 2023
# It uses nixpkgs' revision 8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8 for reproducibility purposes
# which will install R version 4.2.2
# Report any issues to https://github.com/b-rodrigues/rix
{ pkgs ? import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8.tar.gz") {} }:

  with pkgs;

  let
  my-r = rWrapper.override {
    packages = with rPackages; [
      plumber tidymodels
    ];
  };
  in
  mkShell {
    buildInputs = [
      my-r
      ];
  }</code></pre>
<p>
(for posterity’s sake: this is using <a href="https://github.com/b-rodrigues/rix/tree/935fb194b38adfb085a5bda9ebe5dc5bb504f2cb">this version of {rix}</a>. Also, if you want to learn more about <code>{rix}</code> take a look at its <a href="https://b-rodrigues.github.io/rix/">website</a>. It’s still in very early development, comments and PR more than welcome!)
</p>
<p>
To build my api I’ll have to have <code>{plumber}</code> installed. I also install the <code>{tidymodels}</code> package. I actually don’t need <code>{tidymodels}</code> for what I’m doing (base R can fit logistic regressions just fine), but the reason I’m installing it is to mimic a “real-word example” as closely as possible (a project with some dependencies).
</p>
<p>
When I called <code>rix::rix()</code> to generate the <code>default.nix</code> file, I specified that I wanted R version 4.2.2 (because let’s say that this is the version I need. It’s also possible to get the current version of R by passing “current” to <code>r_ver</code>). You don’t see any reference to this version of R in the <code>default.nix</code> file, but this is the version that will get installed because it’s the version that comes with that particular revision of the <code>nixpkgs</code> repository:
</p>
<pre><code>"https://github.com/NixOS/nixpkgs/archive/8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8.tar.gz"</code></pre>
<p>
This url downloads that particular revision on <code>nixpkgs</code> containing R version 4.2.2. <code>{rix}</code> finds the right revision for you (using <a href="https://lazamar.co.uk/nix-versions/?channel=nixpkgs-unstable&amp;package=r">this handy service</a>).
</p>
<p>
While <code>{rix}</code> doesn’t require your system to have Nix installed, if you want to continue you’ll have to install Nix. To install Nix, I recommend you don’t use the official installer, even if it’s quite simple to use. Instead, the <a href="https://zero-to-nix.com/start/install">Determinate Systems</a> installer seems better to me. On Windows, you will need to enable WSL2. An alternative is to run all of this inside a Docker container (but more on this later if you’re thinking something along the lines of <em>isn’t the purpose of Nix to not have to use Docker?</em> then see you in the conclusion). Once you have Nix up and running, go inside the <code>titanic_api/</code> folder (which contains the <code>default.nix</code> file above) and run the following command inside a terminal:
</p>
<pre><code>nix-build</code></pre>
<p>
This will build the environment according to the instructions in the <code>default.nix</code> file. Depending on what you want/need, this can take some time. Once the environment is done building, you can “enter” into it by typing:
</p>
<pre><code>nix-shell</code></pre>
<p>
Now this is where you would use this environment to work on your api. As I stated above, I’ll discuss interactive work using a Nix environment in a future blog post. Leave the terminal with this Nix shell open and create an empty text wile next to <code>default.nix</code> and call it <code>titanic_api.R</code> and put this in there using any text editor of your choice:
</p>
<pre class="r"><code>#* Would you have survived the Titanic sinking?
#* @param sex Character. "male" or "female"
#* @param age Integer. Your age.
#* @get /prediction
function(sex, age) {

  trained_logreg &lt;- readRDS("trained_logreg.rds")

  dataset &lt;- data.frame(sex = sex, age = as.numeric(age))

  parsnip::predict.model_fit(trained_logreg,
                             new_data = dataset)

}</code></pre>
<p>
This script is a <code>{plumber}</code> api. It’s a simple function that uses an already <em>trained</em> logistic regression (lol) by loading it into its scope using the <code>readRDS()</code> function. It then returns a prediction. The script that I wrote to train the model is this one:
</p>
<pre class="r"><code>library(parsnip)

titanic_raw &lt;- read.csv("https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv")

titanic &lt;- titanic_raw |&gt;
  subset(select = c(Survived,
                    Sex,
                    Age))

names(titanic) &lt;- c("survived", "sex", "age")

titanic$survived = as.factor(titanic$survived)

logreg_spec &lt;- logistic_reg() |&gt;
  set_engine("glm")

trained_logreg &lt;- logreg_spec |&gt;
  fit(survived ~ ., data = titanic)

saveRDS(trained_logreg, "trained_logreg.rds")</code></pre>
<p>
If you’re familiar with this Titanic prediction task, you will have noticed that the script above is completely stupid. I only kept two variables to fit the logistic regression. But the reason I did this is because this blog post is not about fitting models, but about apis. So bear with me. Anyways, once you’re run the script above to generate the file <code>trained_logreg.rds</code> containing the trained model, you can locally test the api using <code>{plumber}</code>. Go back to the terminal that is running your Nix shell, and now type <code>R</code> to start R in that session. You can then run your api inside that session using:
</p>
<pre class="r"><code>plumber::pr("titanic_api.R") |&gt;
  plumber::pr_run(port = "8000")</code></pre>
<p>
Open your web browser and visit <a href="http://localhost:8000/__docs__/">http://localhost:8000/<strong>docs</strong>/</a> to see the Swagger interface to your api (Swagger is a nice little tool that makes testing your apis way easier).
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/swagger_plumber.png" width="60%">
</p>
</div>
<p>
Using Swagger you can try out your api, click on (1) then on (2). You can enter some mock data in (3) and (4) and then run the computation by clicking on “Execute” (5). You’ll see the result in (7). (6) gives you a <code>curl</code> command to run exactly this example from a terminal. Congrats, your <code>{plumber}</code> api is running on your computer! Now we need to deploy it online and make it available to the world.
</p>
</section>
<section id="deploying-your-api" class="level2">
<h2 class="anchored" data-anchor-id="deploying-your-api">
Deploying your api
</h2>
<p>
So if you have a Digital Ocean account log in (and if you don’t, use my <a href="https://m.do.co/c/b68adc727710">referral link</a> to get 200$ to test things out) and click on the top-right corner on the “Create” button, and then select “Droplet” (a fancy name for a VM):
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/digital_ocean_1.png" width="60%">
</p>
</div>
<p>
In the next screen, select the region closest to you and then select Ubuntu as the operating system, “Regular” for the CPU options, and then the 4$ (or the 6<img src="https://latex.codecogs.com/png.latex?(,%20it%20doesn't%20matter%20at%20this%20stage)%20a%20month%20Droplet.%20We%20will%20need%20to%20upgrade%20it%20immediately%20after%20having%20created%20it%20in%20order%20to%20actually%20build%20the%20environment.%20This%20is%20because%20building%20the%20environment%20requires%20some%20more%20RAM%20than%20what%20the%206)"> option offers, but starting from the cheapest option ensures that we will then be able to downsize back to it, after the build process is done.
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/digital_ocean_2.png" width="60%">
</p>
</div>
<p>
Next comes how you want to authenticate to your VM. There are two options, one using an SSH key, another using a password. If you’re already using Git, you can use the same SSH key. Click on “New SSH Key” and paste the public key in the box (you should find the key under <code>~/.ssh/id_rsa.pub</code> if you’re using Linux). If you’re not using Git and have no idea what SSH keys are, my first piece of advice is to start using Git and then to generate an SSH key and login using it. This is much more secure than a password. Finally, click on “Create Droplet”. This will start building your VM. Once the Droplet is done building, you can check out its IP address:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/digital_ocean_3.png" width="100%">
</p>
</div>
<p>
Let’s immediately resize the Droplet to a larger size. As I said before, this is only required to build our production environment using Nix. Once the build is done, we can downsize again to the cheapest Droplet:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/digital_ocean_4.png" width="100%">
</p>
</div>
<p>
Choose a Droplet with 2 gigs of RAM to be on the safe side, and also enable the reserved IP option (this is a static IP that will never change):
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/digital_ocean_5.png" width="80%">
</p>
</div>
<p>
Finally, turn on your Droplet, it’s time to log in to it using SSH.
</p>
<p>
Open a terminal on your computer and connect to your Droplet using SSH (starting now, <code>user@local_computer</code> refers to a terminal opened on your computer and <code>root@droplet</code> to an active ssh session inside your Droplet):
</p>
<pre><code>user@local_computer &gt; ssh root@IP_ADDRESS_OF_YOUR_DROPLET</code></pre>
<p>
and add a folder that will contain the project’s files:
</p>
<pre><code>root@droplet &gt; mkdir titanic_api</code></pre>
<p>
Great, let’s now copy our files to the Droplet using <code>scp</code>. Open a terminal on your computer, and navigate to where the <code>default.nix</code> file is. If you prefer doing this graphically, you can use Filezilla. Run the following command to copy the <code>default.nix</code> file to the Droplet:
</p>
<pre><code>user@local_computer &gt; scp default.nix root@IP_ADDRESS_OF_YOUR_DROPLET:/root/titanic_api/</code></pre>
<p>
Now go back to the terminal that is logged into your Droplet. We now need to install Nix. For this, follow the instructions from the <a href="https://zero-to-nix.com/start/install">Determinate Systems</a> installer, and run this line in the Droplet:
</p>
<pre><code>root@droplet &gt; curl --proto '=https' --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install</code></pre>
<p>
Pay attention to the final message once the installation is done:
</p>
<pre><code>Nix was installed successfully!
To get started using Nix, open a new shell or run `. /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh`</code></pre>
<p>
So run <code>. /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh</code> to start the Nix daemon. Ok so now comes the magic of Nix. You can now build the exact same environment that you used to build the pipeline on your computer in this Droplet. Simply run <code>nix-build</code> for the build process to start. I don’t really know how to describe how easy and awesome this is. You may be thinking <em>well installing R and a couple of packages is not that hard</em>, but let me remind you that we are using a Droplet that is running Ubuntu, which is likely NOT the operating system that you are running. Maybe you are on Windows, maybe you are on macOS, or maybe you’re running another Linux distribution. Whatever it is you’re using, it will be different from that Droplet. Even if you’re running Ubuntu on your computer, chances are that you’ve changed the CRAN repositories from the default Ubuntu ones to the Posit ones, or maybe you’re using <a href="https://github.com/eddelbuettel/r2u">r2u</a>. Basically, the chances that you will have the exact same environment in that Droplet than the one running on your computer is basically 0. And if you’re already familiar with Docker, I think that you will admit that this is much, much easier than dockerizing your <code>{plumber}</code> api. If you don’t agree, please shoot me an <a href="mailto:bruno@brodrigues.co">email</a> and tell me why, I’m honestly curious. Also, let me stress again that if you needed to install a package like <code>{xlsx}</code> that requires Java to be installed, Nix would install the right version of Java for you.
</p>
<p>
Once the environment is done building, you can downsize your Droplet. Go back to your Digital Ocean account, select that Droplet and choose “Resize Droplet”, and go back to the 6$ a month plan.
</p>
<p>
SSH back into the Droplet and copy the trained model <code>trained_logreg.rds</code> and the api file, <code>titanic_api.R</code> to the Droplet using <code>scp</code> or Filezilla. It’s time to run the api. To do so, the obvious way would be simply to start an R session and to execute the code to run the api. However, if something happens and the R session dies, the api won’t restart. Instead, I’m using a CRON job and an utility called <code>run-one</code>. This utility, pre-installed in Ubuntu, runs one (1) script at a time, and ensures that only one instance of said script is running. So by putting this in a CRON job (CRON is a scheduler, so it executes a script as often as you specify), <code>run-one</code> will try to run the script. If it’s still running, nothing happens, if the script is not running, it runs it.
</p>
<p>
So go back to your local computer, and create a new text file, call it <code>run_api.sh</code> and write the following text in it:
</p>
<pre><code>#!/bin/bash
while true
do
nix-shell /root/titanic_api/default.nix --run "Rscript -e 'plumber::pr_run(plumber::pr(\"/root/titanic_api/titanic_api.R\"), host = \"0.0.0.0\", port=80)'"
 sleep 10
done</code></pre>
<p>
then copy this to your VM using <code>scp</code> or Filezilla, to <code>/root/titanic_api/run_api.sh</code>. Then SSH back into your Droplet, go to where the script is using <code>cd</code>:
</p>
<pre><code>root@droplet &gt; cd /root/titanic_api/</code></pre>
<p>
and make the script executable:
</p>
<pre><code>root@droplet &gt; chmod +x run_api.sh</code></pre>
<p>
We’re almost done. Now, let’s edit the <code>crontab</code>, to specify that we want this script to be executed every hour using <code>run-one</code> (so if it’s running, nothing happens, if it died, it gets restarted). To edit the <code>crontab</code>, type <code>crontab -e</code> and select the editor you’re most comfortable with. If you have no idea, select the first option, <code>nano</code>. Using your keyboard keys, navigate all the way down and type:
</p>
<pre><code>*/60 * * * * run-one /root/titanic_api/run_api.sh</code></pre>
<p>
save the file by typing <code>CTRL-X</code>, and then type <code>Y</code> when asked <code>Save modified buffer?</code>, and then type the <code>ENTER</code> key when prompted for <code>File name to write</code>.
</p>
<p>
We are now ready to start the api. Make sure CRON restarts by running:
</p>
<pre><code>root@droplet &gt; service cron reload</code></pre>
<p>
and then run the script using <code>nohup</code> followed by <code>run-one</code>:
</p>
<pre><code>root@droplet &gt; nohup run-one /root/titanic_api/run_api.sh &amp;</code></pre>
<p>
<code>run-one</code> will now run the script and will ensure that only one instance of the script is running (the <code>&amp;</code> character at the end means “run this in the background” an <code>nohup</code>, which stands for “no hang-up”, ensures the command will continue running even when you close the terminal). If for any reason the process dies, CRON will restart an instance of the script. We can now call our api using this <code>curl</code> command:
</p>
<pre><code>user@local_computer &gt; curl -X GET "http://IP_ADDRESS_OF_YOUR_DROPLET/prediction?sex=female&amp;age=45" -H "accept: */*"</code></pre>
<p>
If you don’t have <code>curl</code> installed, you can use <a href="https://reqbin.com/curl">this webservice</a>. You should see this answer:
</p>
<pre><code>[{
    ".pred_class": "1"
}]</code></pre>
<p>
I’ll leave my Droplet running for a few days after I post this, so if you want you can try it out run this:
</p>
<pre><code>curl -X GET "http://142.93.164.182/prediction?sex=female&amp;age=45" -H "accept: */*"</code></pre>
<p>
The answer is in the JSON format, and can now be ingested by some other script which can now process it further.
</p>
</section>
<section id="conclusion" class="level1">
<h1>
Conclusion
</h1>
<p>
This was a long blog post. While it is part of my Nix series of blog posts, I almost didn’t talk about it, and this is actually the neat part. Nix made something that is usually difficult to solve trivially simple. Without Nix, the alternative would be to bundle the api with all its dependencies and an R interpreter using Docker or install everything by hand on the server. But the issue with Docker is that it’s not necessarily much easier than Nix, and you still have to make sure building the image is reproducible. So you have to make sure to use an image that ships with the right version of R and use <code>{renv}</code> to restore your packages. If you have system-level dependencies that are required, you also have to deal with those. Nix takes care of all of this for you, so that you can focus on all the other aspects of deployment, which take the bulk of the effort and time.
</p>
<p>
In the post I mentioned that you could also run Nix inside a Docker container. If you are already invested in Docker, Nix is still useful because you can use base NixOS images (NixOS is a Linux distribution that uses Nix as its package manager) or you could install Nix inside an Ubuntu image and then benefit from the reproducibility offered by Nix. Simply add <code>RUN nix-build</code> to your Dockerfile, and everything you need gets installed. You can even use Nix to build Docker images instead of writing a Dockerfile. The possibilities are endless!
</p>
<p>
Now, before you start building apis using R, you may want to read this blog post <a href="https://matthewrkaye.com/posts/2023-06-29-lessons-learned-from-running-r-in-production/lessons-learned-from-running-r-in-production.html">here</a> as well. I found it quite interesting: it discusses the shortcomings of using R to build apis like I showed you here, which I think you need to know. If you have needs like the author of this blog post, then maybe R and <code>{plumber}</code> is not the right solution for you.
</p>
<p>
Next time, in part 4, I’ll either finally discuss how to do interactive work using a Nix environment, or I’ll discuss my package, <code>{rix}</code> in more detail. We’ll see!
</p>


</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2023-07-30-nix_for_r_part3.html</guid>
  <pubDate>Sun, 30 Jul 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 2 – running {targets} pipelines with Nix</title>
  <link>https://b-rodrigues.github.io/posts/2023-07-19-nix_for_r_part2.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/pipeline_nix.jpg" width="100%">
</p>
</div>
<p>
This is the second post in a series of posts about Nix. Disclaimer: I’m a super beginner with Nix. So this series of blog posts is more akin to notes that I’m taking while learning than a super detailed tutorial. So if you’re a Nix expert and read something stupid in here, that’s normal. This post is going to focus on R (obviously) but the ideas are applicable to any programming language.
</p>
<p>
So in <a href="../posts/2023-07-13-nix_for_r_part1.html">part 1</a> I explained what Nix was and how you could use it to build reproducible development environments. Now, let’s go into more details and actually set up some environments and run a <code>{targets}</code> pipeline using it.
</p>
<p>
Obviously the first thing you should do is install Nix. A lot of what I’m showing here comes from the <a href="https://nix.dev/tutorials/">Nix.dev</a> so if you want to install Nix, then look at the instructions <a href="https://nix.dev/tutorials/install-nix">here</a>. If you’re using Windows, you’ll have to have WSL2 installed. If you don’t want to install Nix just yet, you can also play around with a NixOS Docker image. NixOS is a Linux distribution that uses the concepts of Nix for managing the whole operating system, and obviously comes with the Nix package manager installed. But if you’re using Nix inside Docker you won’t be able to work interactively with graphical applications like RStudio, due to how Docker works (but more on working interactively with IDEs in part 3 of this series, which I’m already drafting).
</p>
<p>
Assuming you have Nix installed, you should be able to run the following command in a terminal:
</p>
<pre><code>nix-shell -p sl</code></pre>
<p>
This will launch a Nix shell with the <code>sl</code> package installed. Because <code>sl</code> is not available, it’ll get installed on the fly, and you will get “dropped” into a Nix shell:
</p>
<pre><code>[nix-shell:~]$</code></pre>
<p>
You can now run <code>sl</code> and marvel at what it does (I won’t spoil you). You can quit the Nix shell by typing <code>exit</code> and you’ll go back to your usual terminal. If you try now to run <code>sl</code> it won’t work (unless you installed on your daily machine). So if you need to go back to that Nix shell and rerun <code>sl</code>, simply rerun:
</p>
<pre><code>nix-shell -p sl</code></pre>
<p>
This time you’ll be dropped into the Nix shell immediately and can run <code>sl</code>. So if you need to use R, simply run the following:
</p>
<pre><code>nix-shell -p R</code></pre>
<p>
and you’ll be dropped in a Nix shell with R. This version of R will be different than the one potentially already installed on your system, and it won’t have access to any R packages that you might have installed. This is because Nix environment are isolated from the rest of your system (well, not quite, but again, more on this in part 3). So you’d need to add packages as well (exit the Nix shell and run this command to add packages):
</p>
<pre><code>nix-shell -p R rPackages.dplyr rPackages.janitor</code></pre>
<p>
You can now start R in that Nix shell and load the <code>{dplyr}</code> and <code>{janitor}</code> packages. You might be wondering how I knew that I needed to type <code>rPackages.dplyr</code> to install <code>{dplyr}</code>. You can look for this information <a href="https://search.nixos.org/packages">online</a>. By the way, if a package uses the <code>.</code> character in its name, you should replace that <code>.</code> character by <code>_</code> so to install <code>{data.table}</code> write <code>rPackages.data_table</code>.
</p>
<p>
So that’s nice and dandy, but not quite what we want. Instead, what we want is to be able to declare what we need in terms of packages, dependencies, etc, inside a file, and have Nix build an environment according to these specifications which we can then use for our daily needs. To do so, we need to write a so-called <code>default.nix</code> file. This is what such a file looks like:
</p>
<pre><code>{ pkgs ? import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/e11142026e2cef35ea52c9205703823df225c947.tar.gz") {} }:

with pkgs;

let
  my-pkgs = rWrapper.override {
    packages = with rPackages; [dplyr ggplot2 R];
  };
in
mkShell {
  buildInputs = [my-pkgs];
}</code></pre>
<p>
I wont discuss the intricate details of writing such a file just yet, because it’ll take too much time and I’ll be repeating what you can find on the <a href="https://nix.dev/">Nix.dev</a> website. I’ll give some pointers though. But for now, let’s assume that we already have such a <code>default.nix</code> file that we defined for our project, and see how we can use it to run a <code>{targets}</code> pipeline. I’ll explain how I write such files.
</p>
<section id="running-a-targets-pipeline-using-nix" class="level2">
<h2 class="anchored" data-anchor-id="running-a-targets-pipeline-using-nix">
Running a {targets} pipeline using Nix
</h2>
<p>
Let’s say I have this, more complex, <code>default.nix</code> file:
</p>
<pre><code>{ pkgs ? import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8.tar.gz") {} }:

with pkgs;

let
  my-pkgs = rWrapper.override {
    packages = with rPackages; [
      targets
      tarchetypes
      rmarkdown
    (buildRPackage {
      name = "housing";
      src = fetchgit {
        url = "https://github.com/rap4all/housing/";
        branchName = "fusen";
        rev = "1c860959310b80e67c41f7bbdc3e84cef00df18e";
        sha256 = "sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=";
      };
    propagatedBuildInputs = [
        dplyr
        ggplot2
        janitor
        purrr
        readxl
        rlang
        rvest
        stringr
        tidyr
        ];
      })
    ];
  };
in
mkShell {
  buildInputs = [my-pkgs];
}</code></pre>
<p>
So the file above defines an environment that contains all the required packages to run a pipeline that you can find on <a href="https://github.com/b-rodrigues/nix_targets_pipeline">this Github repository</a>. What’s interesting is that I need to install a package that’s only been released on Github, the <code>{housing}</code> package that I wrote for the <a href="https://raps-with-r.dev/packages.html">purposes of my book</a>, and I can do so in that file as well, using the <code>fetchgit()</code> function. Nix has many such functions, called <em>fetchers</em> that simplify the process of downloading files from the internet, see <a href="https://ryantm.github.io/nixpkgs/builders/fetchers/">here</a>. This function takes some self-explanatory inputs as arguments, and two other arguments that might not be that self-explanatory: <code>rev</code> and <code>sha256</code>. <code>rev</code> is actually the commit on the Github repository. This commit is the one that I want to use for this particular project. So if I keep working on this package, then building an environment with this <code>default.nix</code> will always pull the source code as it was at that particular commit. <code>sha256</code> is the hash of the downloaded repository. It makes sure that the files weren’t tampered with. How did I obtain that? Well, the simplest way is to set it to the empty string <code>““</code> and then try to build the environment. This error message will pop-up:
</p>
<pre><code>error: hash mismatch in fixed-output derivation '/nix/store/449zx4p6x0yijym14q3jslg55kihzw66-housing-1c86095.drv':
         specified: sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=
            got:    sha256-s4KGtfKQ7hL0sfDhGb4BpBpspfefBN6hf+XlslqyEn4=</code></pre>
<p>
So simply copy the hash from the last line, and rebuild! Then if in the future something happens to the files, you’ll know. Another interesting input is <code>propagatedBuildInputs</code>. These are simply the dependencies of the <code>{housing}</code> package. To find them, see the <code>Imports:</code> section of the <a href="https://github.com/rap4all/housing/blob/fusen/DESCRIPTION">DESCRIPTION</a> file. There’s also the <code>fetchFromGithub</code> fetcher that I could have used, but unlike <code>fetchgit</code>, it is not possible to specify the branch name we want to use. Since here I wanted to get the code from the branch called <code>fusen</code>, I had to use <code>fetchgit</code>. The last thing I want to explain is the very first line:
</p>
<pre><code>{ pkgs ? import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8.tar.gz") {} }:</code></pre>
<p>
In particular the url. This url points to a specific release of <code>nixpkgs</code>, that ships the required version of R for this project, R version 4.2.2. How did I find this release of <code>nixpkgs</code>? There’s a handy service for that <a href="https://lazamar.co.uk/nix-versions/?channel=nixpkgs-unstable&amp;package=r">here</a>. So using this service, I get the right commit hash for the release that install R version 4.2.2.
</p>
<p>
Ok, but before building the environment defined by this file, let me just say that I know what you’re thinking. Probably something along the lines of: <em>damn it Bruno, this looks complicated and why should I care? Let me just use {renv}!!</em> and I’m not going to lie, writing the above file from scratch didn’t take me long in typing, but it took me long in reading. I had to read quite a lot (look at <a href="../posts/2023-07-13-nix_for_r_part1.html">part 1</a> for some nice references) before being comfortable enough to write it. But I’ll just say this:
</p>
<ul>
<li>
continue reading, because I hope to convince you that Nix is really worth the effort
</li>
<li>
I’m working on a package that will help R users generate <code>default.nix</code> files like the one from above with minimal effort (more on this at the end of the blog post)
</li>
</ul>
<p>
If you’re following along, instead of typing this file, you can clone this <a href="https://github.com/b-rodrigues/nix_targets_pipeline">repository</a>. This repository contains the <code>default.nix</code> file from above, and a <code>{targets}</code> pipeline that I will run in that environment.
</p>
<p>
Ok, so now let’s build the environment by running <code>nix-build</code> inside a terminal in the folder that contains this file. It should take a bit of time, because many of the packages will need to be built from source. But they <strong>will</strong> get built. Then, you can drop into a Nix shell using <code>nix-shell</code> and then type R, which will start the R session in that environment. You can then simply run <code>targets::tar_make()</code>, and you’ll see the file <code>analyse.html</code> appear, which is the output of the <code>{targets}</code> pipeline.
</p>
<p>
Before continuing, let me just make you realize three things:
</p>
<ul>
<li>
we just ran a targets pipeline with all the needed dependencies which include not only package dependencies, but the right version of R (version 4.2.2) as well, and all required system dependencies;
</li>
<li>
we did so WITHOUT using any containerization tool like Docker;
</li>
<li>
the whole thing is <strong>completely</strong> reproducible; the exact same packages will forever be installed, regardless of <em>when</em> we build this environment, because I’m using a particular release of <code>nixpkgs</code> (8ad5e8132c5dcf977e308e7bf5517cc6cc0bf7d8) so each piece of software this release of Nix installs is going to stay constant.
</li>
</ul>
<p>
And I need to stress <em>completely reproducible</em>. Because using {renv}+Docker, while providing a very nice solution, still has some issues. First of all, with Docker, the underlying operating system (often Ubuntu) evolves and changes through time. So lower level dependencies might change. And at some point in the future, that version of Ubuntu will not be supported anymore. So it won’t be possible to rebuild the image, because it won’t be possible to download any software into it. So either we build our Docker image and really need to make sure to keep it forever, or we need to port our pipeline to newer versions of Ubuntu, without any guarantee that it’s going to work exactly the same. Also, by defining <code>Dockerfile</code>s that build upon <code>Dockerfile</code>s that build upon <code>Dockerfile</code>s, it’s difficult to know what is actually installed in a particular image. This situation can of course be avoided by writing <code>Dockerfile</code>s in such a way that it doesn’t rely on any other <code>Dockerfile</code>, but that’s also a lot of effort. Now don’t get me wrong: I’m not saying Docker should be canceled. I still think that it has its place and that its perfectly fine to use it (I’ll take a project that uses <code>{renv}</code>+Docker any day over one that doesn’t!). But you should be aware of alternative ways of running pipelines in a reproducible way, and Nix is such a way.
</p>
<p>
Going back to our pipeline, we could also run the pipeline with this command:
</p>
<pre><code>nix-shell /path/to/default.nix --run "Rscript -e 'setwd(\"/path/to\");targets::tar_make()'"</code></pre>
<p>
but it’s a bit of a mouthful. What you could do instead is running the pipeline each time you drop into the nix shell by adding a so-called <code>shellHook</code>. For this, we need to change the <code>default.nix</code> file again. Add these lines in the <code>mkShell</code> function:
</p>
<pre><code>...
mkShell {
  buildInputs = [my-pkgs];
  shellHook = ''
     Rscript -e "targets::tar_make()"
  '';
}</code></pre>
<p>
Now, each time you drop into the Nix shell in the folder containing that <code>default.nix</code> file, <code>targets::tar_make()</code> get automatically executed. You can then inspect the results.
</p>
<p>
In the next blog post, I’ll show how we can use that environment with IDEs like RStudio, VS Code and Emacs to work interactively. But first, let me quickly talk about a package I’ve been working on to ease the process of writing <code>default.nix</code> files.
</p>
</section>
<section id="rix-reproducible-environments-with-nix" class="level2">
<h2 class="anchored" data-anchor-id="rix-reproducible-environments-with-nix">
Rix: Reproducible Environments with Nix
</h2>
<p>
I wrote a very early, experimental package called <code>{rix}</code> which will help write these <code>default.nix</code> files for us. <code>{rix}</code> is an R package that hopefully will make R users want to try out Nix for their development purposes. It aims to mimic the workflow of <code>{renv}</code>, or to be more exact, the workflow of what Python users do when starting a new project. Usually what they do is create a completely fresh environment using <code>pyenv</code> (or another similar tool). Using <code>pyenv</code>, Python developers can install a per project version of Python and Python packages, but unlike Nix, won’t install system-level dependencies as well.
</p>
<p>
If you want to install <code>{rix}</code>, run the following line in an R session:
</p>
<pre class="r"><code>devtools::install_github("b-rodrigues/rix")</code></pre>
<p>
You can then using the <code>rix()</code> function to create a <code>default.nix</code> file like so:
</p>
<pre class="r"><code>rix::rix(r_ver = "current",
         pkgs = c("dplyr", "janitor"),
         ide = "rstudio",
         path = ".")</code></pre>
<p>
This will create a <code>default.nix</code> file that Nix can use to build an environment that includes the current versions of R, <code>{dplyr}</code> and <code>{janitor}</code>, and RStudio as well. Yes you read that right: you need to have a per-project RStudio installation. The reason is that RStudio modifies environment variables and so your “locally” installed RStudio would not find the R version installed with Nix. This is not the case with other IDEs like VS Code or Emacs. If you want to have an environment with another version of R, simply run:
</p>
<pre class="r"><code>rix::rix(r_ver = "4.2.1",
         pkgs = c("dplyr", "janitor"),
         ide = "rstudio",
         path = ".")</code></pre>
<p>
and you’ll get an environment with R version 4.2.1. To see which versions are available, you can run <code>rix::available_r()</code>. Learn more about <code>{rix}</code> on its <a href="https://b-rodrigues.github.io/rix/">website</a>. It’s in very early stages, and doesn’t handle packages that have only been released on Github, yet. And the interface might change. I’m thinking of making it possible to list the packages in a yaml file and then have <code>rix()</code> generate the <code>default.nix</code> file from the yaml file. This might be cleaner. There is already something like this called <a href="https://github.com/luispedro/nixml/tree/main">Nixml</a>, so maybe I don’t even need to rewrite anything!
</p>
<p>
But I’ll discuss this is more detail next time, where I’ll explain how you can use development environments built with Nix using an IDE.
</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">
References
</h2>
<ul>
<li>
The great <a href="https://nix.dev/tutorials/install-nix">Nix.dev</a> tutorials.
</li>
<li>
This <a href="https://rgoswami.me/posts/rethinking-r-nix/">blog post: Statistical Rethinking and Nix</a> I referenced in part 1 as well, it helped me install my <code>{housing}</code> package from Github.
</li>
<li>
<a href="https://github.com/luispedro/nixml/tree/main">Nixml</a>.
</li>
</ul>


</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2023-07-19-nix_for_r_part2.html</guid>
  <pubDate>Wed, 19 Jul 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Reproducible data science with Nix, part 1 – what is Nix</title>
  <link>https://b-rodrigues.github.io/posts/2023-07-13-nix_for_r_part1.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/nix.jpg" width="100%">
</p>
</div>
<p>
This is the first of a (hopefully) series of posts about Nix. Disclaimer: I’m a super beginner with Nix. So this series of blog posts is more akin to notes that I’m taking while learning than a super detailed tutorial. So if you’re a Nix expert and read something stupid in here, that’s normal. This post is going to focus on R (obviously) but the ideas are applicable to any programming language.
</p>
<p>
To ensure that a project is reproducible you need to deal with at least four things:
</p>
<ul>
<li>
Make sure that the required/correct version of R (or any other language) is installed;
</li>
<li>
Make sure that the required versions of packages are installed;
</li>
<li>
Make sure that system dependencies are installed (for example, you’d need a working Java installation to install the <code>{rJava}</code> R package on Linux);
</li>
<li>
Make sure that you can install all of this for the hardware you have on hand.
</li>
</ul>
<p>
For the three first bullet points, the consensus seems to be a mixture of Docker to deal with system dependencies, <code>{renv}</code> for the packages (or <code>{groundhog}</code>, or a fixed CRAN snapshot like those <a href="https://packagemanager.posit.co/__docs__/user/get-repo-url/#ui-frozen-urls">Posit provides</a>) and the <a href="https://github.com/r-lib/rig">R installation manager</a> to install the correct version of R (unless you use a Docker image as base that already ships the required version by default). As for the last point, the only way out is to be able to compile the software for the target architecture. There’s a lot of moving pieces, and knowledge that you need to know and I even wrote a whole 522 pages <a href="https://raps-with-r.dev/">book about all of this</a>.
</p>
<p>
But it turns out that this is not the only solution. Docker + <code>{renv}</code> (or some other way to deal with packages) is likely the most popular way to ensure reproducibility of your projects, but there are other tools to achieve this. One such tool is called Nix.
</p>
<p>
Nix is a package manager for Linux distributions, macOS and apparently it even works on Windows if you enable WSL2. What’s a package manager? If you’re not a Linux user, you may not be aware. Let me explain it this way: in R, if you want to install a package to provide some functionality not included with a vanilla installation of R, you’d run this:
</p>
<pre><code>install.packages("dplyr")</code></pre>
<p>
It turns out that Linux distributions, like Ubuntu for example, work in a similar way, but for software that you’d usually install using an installer (at least on Windows). For example you could install Firefox on Ubuntu using:
</p>
<pre><code>sudo apt-get install firefox</code></pre>
<p>
(there’s also graphical interfaces that make this process “more user-friendly”). In Linux jargon, <code>packages</code> are simply what normies call software (or I guess it’s all “apps” these days). These packages get downloaded from so-called repositories (think of CRAN, the repository of R packages) but for any type of software that you might need to make your computer work: web browsers, office suites, multimedia software and so on.
</p>
<p>
So Nix is just another package manager that you can use to install software.
</p>
<p>
But what interests us is not using Nix to install Firefox, but instead to install R and the R packages that we require for our analysis (or any other programming language that we need). But why use Nix instead of the usual ways to install software on our operating systems?
</p>
<p>
The first thing that you should know is that Nix’s repository, <code>nixpkgs</code>, is huge. Humongously huge. As I’m writing these lines, <a href="https://search.nixos.org/packages">there’s more than 80’000 pieces of software available</a>, and the <em>entirety of CRAN</em> is also available through <code>nixpkgs</code>. So instead of installing R as you usually do and then use <code>install.packages()</code> to install packages, you could use Nix to handle everything. But still, why use Nix at all?
</p>
<p>
Nix has an interesting feature: using Nix, it is possible to install software in (relatively) isolated environments. So using Nix, you can install as many versions of R and R packages that you need. Suppose that you start working on a new project. As you start the project, with Nix, you would install a project-specific version of R and R packages that you would only use for that particular project. If you switch projects, you’d switch versions of R and R packages. If you are familiar with <code>{renv}</code>, you should see that this is exactly the same thing: the difference is that not only will you have a project-specific library of R packages, you will also have a project-specific R version. So if you start a project now, you’d have R version 4.2.3 installed (the latest version available in <code>nixpkgs</code> but not the latest version available, more on this later), with the accompagnying versions of R packages, for as long as the project lives (which can be a long time). If you start a project next year, then that project will have its own R, maybe R version 4.4.2 or something like that, and the set of required R packages that would be current at that time. This is because Nix always installs the software that you need in separate, (isolated) environments on your computer. So you can define an environment for one specific project.
</p>
<p>
But Nix even goes even further: not only can you install R and R packages using Nix (in isolated) project-specific environments, Nix even installs the required system dependencies. So for example if I need <code>{rJava}</code>, Nix will make sure to install the correct version of Java as well, always in that project-specific environment (so if you already some Java version installed on your system, there won’t be any interference).
</p>
<p>
What’s also pretty awesome, is that you can use a specific version of <code>nixpkgs</code> to <em>always</em> get <em>exactly</em> the same versions of <strong>all</strong> the software whenever you build that environment to run your project’s code. The environment gets defined in a simple plain-text file, and anyone using that file to build the environment will get exactly, byte by byte, the same environment as you when you initially started the project. And this also regardless of the operating system that is used.
</p>
<p>
So let me illustrate this. After <a href="https://nix.dev/tutorials/install-nix">installing Nix</a>, I can define an environment by writing a file called <code>default.nix</code> that looks like this:
</p>
<pre><code>{ pkgs ? import (fetchTarball "https://github.com/NixOS/nixpkgs/archive/e11142026e2cef35ea52c9205703823df225c947.tar.gz") {} }:

with pkgs;

let
  my-pkgs = rWrapper.override {
    packages = with rPackages; [ dplyr ggplot2 R];
  };
in
mkShell {
  buildInputs = [my-pkgs];
}</code></pre>
<p>
Now this certainly looks complicated! And it is. The entry cost to Nix is quite high, because, actually, Nix is more than a package manager. It is also a programming language, and this programming language gets used to configure environments. I won’t go too much into detail, but you’ll see in the first line that I’m using a specific version of <code>nixpkgs</code> that gets downloaded directly from Github. This means that all the software that I will install with that specific version of <code>nixpkgs</code> will always install the same software. This is what ensures that R and R packages are versioned. Basically, by using a specific version of <code>nixpkgs</code>, I pin all the versions of all the software that this particular version of Nix will <em>ever</em> install. I then define a variable called <code>my-pkgs</code> which lists the packages I want to install (<code>{dplyr}</code>, <code>{ggplot2}</code> and <code>R</code>).
</p>
<p>
By the way, this may look like it would take a lot of time to install because, after all, you need to install R, R packages and underlying system dependencies, but thankfully there is an online cache of binaries that gets automatically used by Nix (<a href="https://cache.nixos.org/">cache.nixos.org</a>) for fast installations. If binaries are not available, sources get compiled.
</p>
<p>
I can now create an environment with these exact specifications using (in the directory where <code>default.nix</code> is):
</p>
<pre><code>nix-build</code></pre>
<p>
or I could use the R version from this environment to run some arbitrary code:
</p>
<pre><code>nix-shell /home/renv/default.nix --run "Rscript -e 'sessionInfo()'" &gt;&gt; /home/renv/sessionInfo.txt</code></pre>
<p>
(assuming my <code>default.nix</code> file is available in the <code>/home/renv/</code> directory). This would build the environment on the fly and run <code>sessionInfo()</code> inside of it. Here are the contents of this <code>sessionInfo.txt</code> file:
</p>
<pre><code>R version 4.2.3 (2023-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)

Matrix products: default
BLAS/LAPACK: /nix/store/pbfs53rcnrzgjiaajf7xvwrfqq385ykv-blas-3/lib/libblas.so.3

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_4.2.3</code></pre>
<p>
This looks like any other output of the <code>sessionInfo()</code> function, but there is something quite unusual: the <code>BLAS/LAPACK</code> line:
</p>
<pre><code>BLAS/LAPACK: /nix/store/pbfs53rcnrzgjiaajf7xvwrfqq385ykv-blas-3/lib/libblas.so.3</code></pre>
<p>
BLAS is a library that R uses for linear algebra, matrix multiplication and vector operations. R usually ships with its own version of BLAS and LAPACK, but it’s also possible to use external ones. Here, we see that the path to the shared object <code>libblas.so.3</code> is somewhere in <code>/nix/store/….</code>. <code>/nix/store/</code> is where all the software gets installed. The long chain of seemingly random characters is a hash, essentially the unique identifier of that particular version of BLAS. This means that unlike Docker, if you’re using Nix you are also certain than these types of dependencies, that may have an impact on your results, also get handled properly, and that the exact same version you used will keep getting installed in the future. Docker images also evolve, and even if you use an LTS release of Ubuntu as a base, the underlying system packages will evolve through time as well. And there will be a point in time where this release will be abandoned (LTS releases receive 5 years of support), so if you need to rebuild a Docker images based on an LTS that doesn’t get supported anymore, you’re out of luck.
</p>
<p>
If you don’t want to install Nix just yet on your computer, you should know that there’s also a complete operating system called NixOS, that uses Nix as its package manager, and that there are Docker images that use NixOS as a base. So this means that you could use such an image and then build the environment (that is 100% completely reproducible) inside and run a container that will always produce the same output. To see an example of this, check out this <a href="https://github.com/b-rodrigues/nix_experiments/tree/master">Github repo</a>. I’m writing a Dockerfile as I usually do, but actually I could even use Nix to define the Docker image for me, it’s that powerful!
</p>
<p>
Nix seems like a very powerful tool to me. But there are some “issues”:
</p>
<ul>
<li>
As I stated above, the entry cost is quite high, because Nix is not “just a tool”, it’s a complete programming language that can even run pipelines, so you could technically even replace something like <code>{targets}</code> with it;
</li>
<li>
If you need to install specific versions of R packages, that are not pinned to dates, then Nix is not for you. Nix will always create a coherent environment with R and R packages that go together for a particular release of <code>nixpkgs</code>. If for some reason you need a very old version of <code>{ggplot2}</code> but a much more recent version of <code>{dplyr}</code>, using Nix won’t make this any easier than other methods;
</li>
<li>
There is no easy way (afaik) to find the version of <code>nixpkgs</code> that you need to download to find the version of R that you may need; <strong>UPDATE</strong>: turns out that there is such a <a href="https://lazamar.co.uk/nix-versions/?channel=nixpkgs-unstable&amp;package=r">simple tool</a>, thanks to <span class="citation"><span class="citation" data-cites="shane">@shane</span></span><span class="citation"><span class="citation" data-cites="hachyderm.io">@hachyderm.io</span></span> for the telling me!
</li>
<li>
R packages (and I guess others for other programming languages as well) that are available on the stable channel of <code>nixpkgs</code> lag a bit behind their counterparts on CRAN. These usually all get updated whenever there’s a new release of R. Currently however, R is at version 4.2.3, but R should be at version 4.3.1 on the stable branch of <code>nixpkgs</code>. This can sometimes happen due to various reasons (there are actual human beings behind this that volunteer their time and they also have a life). There is however an “unstable” <code>nixpkgs</code> channel that contains bleeding edge versions of R packages (and R itself) if you really need the latest versions of packages (don’t worry about the “unstable” label, from my understanding this simply means that package have not been thoroughly tested yet, but is still pretty much rock-solid);
</li>
<li>
If you need something that is not on CRAN (or Bioconductor) then it’s still possible to use Nix to install these packages, but you’ll have to perform some manual configuration.
</li>
</ul>
<p>
I will keep exploring Nix, and this is essentially my todo:
</p>
<ul>
<li>
using my environment that I installed with Nix to work interactively;
</li>
<li>
write some tool that lets me specify an R version, a list of packages and it generates a <code>default.nix</code> file automagically (ideally it should also deal with packages only available on Github);
</li>
<li>
????
</li>
<li>
Profit!
</li>
</ul>
<section id="resources" class="level3">
<h3 class="anchored" data-anchor-id="resources">
Resources
</h3>
<p>
Here are some of the resources I’ve been using:
</p>
<ul>
<li>
<a href="https://nix.dev/tutorials/first-steps/towards-reproducibility-pinning-nixpkgs#pinning-nixpkgs">nix.dev tutorials</a>
</li>
<li>
<a href="https://nix-tutorial.gitlabpages.inria.fr/nix-tutorial/installation.html">INRIA’s Nix tutorial</a>
</li>
<li>
<a href="https://nixos.org/guides/nix-pills/">Nix pills</a>
</li>
<li>
<a href="https://github.com/nix-community/nix-data-science">Nix for Data Science</a>
</li>
<li>
<a href="https://christitus.com/nixos-explained/">NixOS explained</a>: NixOS is an entire Linux distribution that uses Nix as its package manager.
</li>
<li>
<a href="https://rgoswami.me/posts/nix-r-devtools/">Blog post: Nix with R and devtools</a>
</li>
<li>
<a href="https://rgoswami.me/posts/rethinking-r-nix/">Blog post: Statistical Rethinking and Nix</a>
</li>
<li>
<a href="https://lazamar.github.io/download-specific-package-version-with-nix/">Blog post: Searching and installing old versions of Nix packages</a>
</li>
</ul>
</section>
<section id="thanks" class="level3">
<h3 class="anchored" data-anchor-id="thanks">
Thanks
</h3>
<p>
Many thanks to <a href="https://github.com/jbedo">Justin Bedő</a>, maintainer of the R package for Nix, for answering all my questions on Nix!
</p>
<p>
</p>

</section>

 ]]></description>
  <category>R</category>
  <category>nix</category>
  <guid>https://b-rodrigues.github.io/posts/2023-07-13-nix_for_r_part1.html</guid>
  <pubDate>Thu, 13 Jul 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How to self-publish a technical book on Leanpub and Amazon using Quarto</title>
  <link>https://b-rodrigues.github.io/posts/2023-06-29-book_quarto.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/gosling.jpg" width="100%">
</p>
</div>
<p>
UPDATE: I’ve update this blog post on the 30 of June 2023. I corrected a statement where I said that the <code>_quarto.yml</code> file is where you can choose the version of R to compile the book. That’s wrong, choosing the version of R to compile the book is done on the Github Actions workflow. I’ve also added some answers to questions I got on social media.
</p>
<p>
So I’ve recently self-published a book on both <a href="https://leanpub.com/raps-with-r/">Leanpub</a> as an Ebook and <a href="https://www.amazon.com/dp/B0C87H6MGF">Amazon</a> as a <em>physical</em> book and thought that it would be worth it to write down how to do it. I’ve wasted some time getting everything to work flawlessly so if you’re looking for a guide on how to create both an ebook and a print-ready PDF for Amazon’s Kindle Direct Publishing service using Quarto, you’ve come to the right place.
</p>
<p>
If you don’t want to waste time reading, <a href="https://github.com/b-rodrigues/kdp_quarto">just fork this repo</a> and use that as a starting point. Each time you push a change to the repo, a website, Epub and PDF get generated using Github Actions. If you want to understand the details, read on.
</p>
<section id="your-books-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="your-books-dependencies">
Your book’s dependencies
</h2>
<p>
You should start by creating an <code>renv.lock</code> file. This file will list all the dependencies of your book. For example, if you’re using <code>{ggplot2}</code> to make graphs or <code>{flextable}</code> for tables, the <code>renv.lock</code> file will list them and then this file will be used to download the required packages by Github Actions (more on Github Actions later) to create the book. The template comes with one such <code>renv.lock</code> file, but you should generate one specific to your project. Simply install <code>{renv}</code> and run:
</p>
<pre class="r"><code>renv::init()</code></pre>
<p>
Answer “Y” to the question and wait a little. The <code>renv.lock</code> file should appear alongside the source of your book now. If you need to install more packages to keep writing your book, install them as usual (using <code>install.packages(“package”)</code>) but then don’t forget to create a new <code>renv.lock</code> file using <code>renv::snapshot()</code>.
</p>
</section>
<section id="quarto.yml" class="level2">
<h2 class="anchored" data-anchor-id="quarto.yml">
_quarto.yml
</h2>
<p>
Whatever output format, everything gets defined in the <code>_quarto.yml</code> file in the root directory of your book. This file is where you can choose which themes to use for your website for example, which output formats you want to compile your book into, etc. I’ll discuss each option for each format below.
</p>
</section>
<section id="generating-the-website" class="level2">
<h2 class="anchored" data-anchor-id="generating-the-website">
Generating the website
</h2>
<p>
I’m using Github Actions to generate each format of the book. Github Actions is essentially a computer hosted by Github that you can use to run arbitrary commands. These commands must be written in a specific file which must be put in a specific place in your repository. <a href="https://github.com/b-rodrigues/kdp_quarto/blob/main/.github/workflows/build_book.yml">Here</a> is that file for the repo I linked above. I won’t go into details because I’ve explained how Github Actions works <a href="../posts/2022-11-19-raps.html">here</a> already, but you’ll notice that you can choose a version of R to compile your document and also a different version of Quarto. This can be useful for reproducibility.
</p>
<p>
Create a new branch called <code>gh-pages</code> and then go to settings, then on the side-bar on the left choose “Actions”, and scroll down. Then, in “Workflow persmissions”, check “Read and Write permissions” and “Allow Github Actions to create and approve pull requests”. Then go to “Pages” which you can find on the side-bar on the left, and choose “Deploy from a branch” under “Build and deployment” and choose “gh-pages” and “root”:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/github_pages.png" width="100%">
</p>
</div>
<p>
Each time you push, the website to your book will get updated. Here are the options I chose for my website, which you can find in the <code>_quarto.yml</code> file:
</p>
<pre><code>html:
   theme:
     light: flatly
     dark: solar
   css:
     epub.css</code></pre>
<p>
So my website is available in two themes, a dark and light one. I highly recommend you also provide two themes. You can also provide a <code>.css</code> file to customize the appearance of you website, and of your ebook (that’s because an Epub is actually a bunch of html files). The <code>.css</code> I’m using is quite simple, the only thing it’s doing is making sure that images won’t be wider than the web-page. You can view the website of this template book <a href="https://b-rodrigues.github.io/kdp_quarto/">here</a>.
</p>
</section>
<section id="generating-an-ebook" class="level2">
<h2 class="anchored" data-anchor-id="generating-an-ebook">
Generating an Ebook
</h2>
<p>
Let’s continue with the <code>.epub</code> format. This is an Ebook format that can be read on E-readers such as the Kindle from Amazon. If you want to sell an Ebook on Leanpub (or send it to your Kindle), it needs to pass a tool called <code>epubcheck</code>.
</p>
<p>
I’ve already written about generating ebooks in the past (<a href="../posts/2023-03-03-quarto_books.html">here</a>). However, the advice in that blog post was only valid because there were bugs in the version of Quarto that was current at the time and so I showed some workarounds. With the current version, no workarounds are needed anymore, Epubs generated by Quarto now pass <code>epubcheck</code>. Check the source, specifically <code>index.qmd</code> to see how I include graphics.
</p>
</section>
<section id="generating-a-print-ready-pdf" class="level2">
<h2 class="anchored" data-anchor-id="generating-a-print-ready-pdf">
Generating a print-ready PDF
</h2>
<p>
This was the hardest part: I’m using Amazon’s KDP service to sell physical copies of the book and the PDF needs to be in a specific format. I’m using the 6 x 9 format without bleed, which seems to be the most common. If you look again at the <code>_quarto.yml</code> file, you should see this:
</p>
<pre><code>  pdf:
    keep-tex: true
    documentclass: scrbook
    classoption: [paper=6in:9in,pagesize=pdftex,headinclude=on,footinclude=on,12pt]
    include-in-header:
      text: |
        \usepackage{fvextra}
        \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
        \areaset[0.50in]{4.5in}{8in}
    include-before-body:
      text: |
        \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
           showspaces = false,
           showtabs = false,
           breaksymbolleft={},
           breaklines
           % Note: setting commandchars=\\\{\} here will cause an error 
        }
    fig-pos: 'H'</code></pre>
<p>
What’s important is ‘classoption’:
</p>
<pre><code>classoption: [paper=6in:9in,pagesize=pdftex,headinclude=on,footinclude=on,12pt]</code></pre>
<p>
This is where I can choose the dimensions of the book (6 x 9) and the size of the font (12pt). Then:
</p>
<pre><code>include-in-header:
  text: |
    \usepackage{fvextra}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
    \areaset[0.50in]{4.5in}{8in}</code></pre>
<p>
With <code>fvextra</code> and the call to <code></code> I make sure that long lines of code get wrapped in the PDF. Without this, long lines of code would simply continue outside the margins of the PDF, and Amazon’s KDP doesn’t accept a PDF like this.
</p>
<p>
<code></code>: this is the area that well be used for writing. These are the correct dimensions for a 6 by 9 book without bleed. Then, I keep customizing the <code>verbatim</code> environment:
</p>
<pre><code>include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
       showspaces = false,
       showtabs = false,
       breaksymbolleft={},
       breaklines
       % Note: setting commandchars=\\\{\} here will cause an error 
    }</code></pre>
<p>
Finally, the last option:
</p>
<pre><code>fig-pos: 'H'</code></pre>
<p>
This ensures that the figures are placed EXACTLY where you say they should be in the final PDF. For those of you that use LaTeX, you know that LaTeX sometimes takes some liberties with figure placement. I’ve been told the lie that LaTeX knows where to place the figures perfectly well many times but I don’t buy it. So use <code>fig-pos: ‘H’</code> to avoid lots of frustration.
</p>
<p>
That’s it! You should now be able to generate a book that is print-ready, and an Epub that passes <code>epubcheck</code> as well as website. You can now just focus on writing. Also check the source of <code>index.qmd</code> for to see how to include text in the PDF only (or not show text in the PDF).
</p>
</section>
<section id="my-personal-experience-and-some-faq" class="level2">
<h2 class="anchored" data-anchor-id="my-personal-experience-and-some-faq">
My personal experience and some FAQ
</h2>
<p>
Overall, I enjoyed using both Leanpub and Amazon to publish my book. Leanpub is really nice, because they really offer a very nice deal: you get 80% of the sales price as royalties, which is the highest share I’ve seen. Also the people working there are really nice, I’ve had the chance to discuss with Len Epp, Leanpub’s cofounder, in his <a href="https://youtu.be/aXfjhf2cDo0">Frontmatter podcast</a> and would definitely continue using their platform in the future. Regarding Amazon I must say that the experience was quite good as well; the only friction I had was getting the PDF in the right format for printing, but that’s hardly something that Amazon can be blamed for. After all if the PDF’s formatting is bad, the books will look like crap as well. One thing you should know though is that you need to get a VAT number to sell books on Amazon. I live in Luxembourg and getting one is trivial, but in other countries this may be more complex. You should know as well that Leanpub can sell the physical copies of your book, through Amazon, for you. They essentially act as a publisher then. This way, you don’t need to get a VAT number, if that’s difficult for you. But you’ll need to share the Amazon royalties with Leanpub.
</p>
<p>
When publishing a book through Amazon’s KDP service, you also get access to a basic book cover editor that you can use to create a cover for your book. You can provide an image and then use the editor to create the cover, but you can also provide a ready-made cover if you have the talent to make one using an image editing software. Once you’re done, and click “Publish” on Amazon, the book will get reviewed by a human. This process can take up to three days, but in my case it took only 4 to 6 hours. However, my book was rejected, twice. One time was because one of the images I used in the book had colour bars in the bottom right corner, that I needed to remove, and the other time was because the “g” in my name, “Rodrigues” was cut by the cover editor and it was hard to tell if it was a “g” or a “q”. Once I corrected both issues, the book was available for order on Amazon.com within the day. The other marketplaces, like France and Germany took one day more, and the UK marketplace took 4 days.
</p>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">
References
</h3>
<p>
I’m sorry, I have no idea where I found all of this stuff. I looked for it for some time, and if memory serves most of this came from stackoverflow.
</p>


</section>
</section>

 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2023-06-29-book_quarto.html</guid>
  <pubDate>Thu, 29 Jun 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Why you should consider working on a dockerized development environment</title>
  <link>https://b-rodrigues.github.io/posts/2023-05-08-dock_dev_env.html</link>
  <description><![CDATA[ 




<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/ship_pc.png" width="100%">
</p>
</div>
<p>
Last year I wrote a post about dockerizing <code>{targets}</code>’s pipelines (<a href="../posts/2022-11-19-raps.html">link to post</a>) and between that blog post and this one, I’ve written a whole book on building reproducible analytical pipelines that you can read <a href="https://raps-with-r.dev/">here</a> (for free!). In the book I explain how you can build projects that will stay reproducible thanks to Docker. With Docker, you don’t only ship the code to your project, but ship <em>a whole computer</em> with it, and your project will be executed inside that computer. By <em>whole computer</em> I mean the whole computational environment: so a version of R, the required packages your project depends on, all of it running on a Linux distribution (usually Ubuntu). The whole project can then be executed like any program from your computer (whether you’re running Windows, macOS or Linux) or even on the cloud with a single command.
</p>
<p>
In this blog post, I’ll discuss something that I’ve been trying for some time now: working directly from a dockerized environment. The idea is to have a Docker image that comes with R, all the usual packages I use for development, Quarto, a LaTeX distribution (that I installed with <code>{tinytex}</code>) and finally, my IDE of choice, Spacemacs (if you use RStudio, just read on, I’ll explain how you can achieve the same thing but with RStudio instead). Why do this? Well because this way I can deploy the exact same environment anywhere. If I get a new computer, I’m only one command line away from a functioning environment. If I want to dockerize a <code>{targets}</code> pipeline, I can write a new Dockerfile that builds upon this image which ensures that there are no discrepancies between the development environment and the production environment. And because I’m building the image on top of a Rocker image, everything just work. If I need to install a package that might be tricky to install (for example, a package that depends on <code>{rJava}</code>, using Docker might be the simplest way to get it to work.
</p>
<p>
So, here’s the Dockerfile:
</p>
<pre><code># This builds upon the Rocker project's versioned image for R version 4.3
FROM rocker/r-ver:4.3

# install `gpg-agent` and `software-properties-common` which are needed to add an Ubuntu ppa to install Emacs
RUN apt-get update \
    &amp;&amp; apt-get install -y --no-install-recommends \
    gpg-agent software-properties-common

# add the ppa which includes the latest version of Emacs
RUN add-apt-repository ppa:kelleyk/emacs

# Install `git`, `wget` and the latest `Emacs`
RUN apt-get update \
    &amp;&amp; apt-get install -y --no-install-recommends \
    git \
    wget \
    emacs28-nox

# Install spacemacs by cloning its repository
RUN git clone -b develop https://github.com/syl20bnr/spacemacs ~/.emacs.d

# Download my .spacemacs config file
RUN wget https://raw.githubusercontent.com/b-rodrigues/dotfiles/master/dotfiles/.spacemacs -O ~/.spacemacs

# This launches emacs in daemon mode. This is needed to initialize spacemacs.
# Running it in daemon mode is required because a Dockerfile must be setup non-interactively
RUN emacs --daemon

# Install a bunch of Ubuntu dependencies. These are typical dependencies required to use some
# R packages on Linux.
RUN apt-get update \
   &amp;&amp; apt-get install -y --no-install-recommends \
   aspell \
   aspell-en \
   aspell-fr \
   aspell-pt-pt \
   libfontconfig1-dev \
   libglpk-dev \
   libxml2-dev \
   libcairo2-dev \
   libgit2-dev \
   default-libmysqlclient-dev \
   libpq-dev \
   libsasl2-dev \
   libsqlite3-dev \
   libssh2-1-dev \
   libxtst6 \
   libcurl4-openssl-dev \
   libharfbuzz-dev \
   libfribidi-dev \
   libfreetype6-dev \
   libpng-dev \
   libtiff5-dev \
   libjpeg-dev \
   libxt-dev \
   unixodbc-dev \
   pandoc

# Download the latest version of Quarto
RUN wget https://github.com/quarto-dev/quarto-cli/releases/download/v1.3.340/quarto-1.3.340-linux-amd64.deb -O ~/quarto.deb

# Install the latest version of Quarto
RUN apt-get install --yes ~/quarto.deb

# Remove the installer
RUN rm ~/quarto.deb

# Create a directory to host my projects
RUN mkdir /root/projects/

# Write a bunch of lines to the .Rprofile
# This makes sure that the httpgd server runs on localhost and on the port 8888
RUN echo 'options(httpgd.host = "0.0.0.0", httpgd.port = 8888, httpgd.token = "aaaaaaaa")' &gt;&gt; /root/.Rprofile

# This option clones renv cache folders inside the root folder of the projects. This makes
# sure that they stay persistent across reboots.
RUN echo 'options(renv.config.cache.symlinks = FALSE)' &gt;&gt; /root/.Rprofile

# Serve shiny apps through localhost and port 8888
RUN echo 'options(shiny.host = "0.0.0.0", shiny.port = 8888)' &gt;&gt; /root/.Rprofile

# Set the CRAN package repositories to the PPPM at the 28th of April
RUN echo 'options(repos = c(REPO_NAME = "https://packagemanager.rstudio.com/cran/__linux__/jammy/2023-04-28"))' &gt;&gt; /root/.Rprofile

# Install the usual packages I use
RUN R -e "install.packages(c('quarto', 'remotes', 'tinytex', 'tidyverse', 'arrow', 'chronicler', 'janitor', 'targets', 'tarchetypes', 'openxlsx', 'shiny', 'flexdashboard', 'data.table', 'httpgd', 'blogdown', 'bookdown'))" 

# Install the g2r package (not yet available on CRAN)
RUN R -e "remotes::install_github('devOpifex/g2r')"

# Install a LaTeX distro using tinytex
RUN R -e "tinytex::install_tinytex()"

# Install hugo for blogging
RUN R -e "blogdown::install_hugo()"

# Expose port 8888
EXPOSE 8888</code></pre>
<p>
(and <a href="https://github.com/b-rodrigues/ess_dev_env">here’s</a> the repository where you can find it).
</p>
<p>
I’ve explained each line of the Dockerfile using comments in the Dockerfile itself. But before explaining it in more detail, here’s a word from this blog post’s sponsor: me, I’m this post’s sponsor.
</p>
<p>
If you have read until here dear reader, let me express my gratitude by offering you a <a href="https://leanpub.com/raps-with-r/c/blog_reader">discount code</a> to purchase a DRM-free Epub and PDF version of my book, Building reproducible analytical pipelines with R (that you can also read for free <a href="https://raps-with-r.dev/">here</a> by the way). Using the <a href="https://leanpub.com/raps-with-r/c/blog_reader">discount code</a> you can get a DRM-free epub and PDF version of the book for 14.99 instead of 19.99! If you want a good old physical book instead, you’ll need to wait some more, I still need to get the formatting right before making it available through Amazon self-publishing service.
</p>
<p>
Now back to our Dockerfile. There are several decisions that I took that I need explain: first, why use a versioned image, and why use the PPPM at a specific date? I did this so that it doesn’t matter <em>when</em> I build the image, I always know which version of R and packages I get. Then, what’s with all the options that I write to the <code>.Rprofile</code>? Well, don’t forget that when I will be running the Docker container defined by this image, I will be using Emacs inside a terminal. So if I want to see plots for example, I need to use the <code>{httpgd}</code> package. This package provides a graphics device that runs on a web server, so if I tell <code>{httpgd}</code> to serve the images over port <code>8888</code>, and then expose this port in the Dockerfile, I can access <code>{httpgd}</code> from my web browser by pointing it to <code>http://localhost:8888</code>. Here’s how this looks like:
</p>
<div style="text-align:center;">
<p>
<img src="https://b-rodrigues.github.io/assets/img/dev_env_httpgd.png" width="100%">
</p>
</div>
<p>
The terminal on top of the image is running my dockerized environment, and below you see my web browser on to the <code>http://localhost:8888/live?token=aaaaaaaa</code> url to access the <code>{httpgd}</code> web server <em>that is running inside the Docker container</em>. And it’s the same logic with Shiny: if I’m working on a Shiny app from inside the container, I can access it by going to <code>http://localhost:8888/</code>. Now, I have to do all of this because I’m running Emacs, but if you’re developing with RStudio, you could instead run RStudio server, access it on <code>http://localhost:8888/</code>, and then no need to think about configuring on which ports <code>{httpgd}</code> serves images, or on which port Shiny apps should run. Everything will be directly visible from within RStudio. <a href="https://github.com/rocker-org/rocker-versioned2/blob/master/dockerfiles/rstudio_4.3.0.Dockerfile">Here is the Dockerfile</a> to run R version 4.3 with RStudio as the IDE. If you want to use this, you could simply start from the above Dockerfile and then add the stuff you need, for example:
</p>
<pre><code>FROM rocker/rstudio:4.3.0

# and add what you want below like installing R packages and whatnot</code></pre>
<p>
There is still one important thing that you should know before using a dockerized development environment: a running Docker container can be changed (for example, you could install new R packages), but once you shut it down and restart it, any change will be lost. So how do you save your work? Well, you need to run the Docker image with a volume. A volume is nothing more than a folder on your computer that is linked to a folder inside the Docker container. Anything that gets saved there from the Docker container will be available on your computer, and vice-versa. Here is the command that I use to run my container:
</p>
<pre><code>docker run --rm -it --name ess_dev_env -p 8888:8888 -v /home/path_to_volume/folder:/root/projects:rw brodriguesco/ess_dev_env:main-cdcb1719d emacs</code></pre>
<p>
Take note of the <code>-v</code> flag, especially what comes after: <code>/home/path_to_volume/folder:/root/projects:rw</code>. <code>/home/path_to_volume/folder</code> is the folder on my computer, and it is linked to the <code>/root/projects</code> folder inside the Docker container. When I run the above command inside a terminal, Spacemacs starts and I can get to work! If you build a development environment based on RStudio, you would essentially use the same command, you would only need to set a password to login first (read the instructions <a href="https://rocker-project.org/images/versioned/rstudio.html#how-to-use">here</a>).
</p>
<p>
Also, if you forgot to add a package and want to install it and make this change permanent, the best way is to add it to the Dockerfile and rebuild the image. I’ve streamlined this process by using Github Actions to build images and push them to Docker Hub. Take a look at the <a href="https://github.com/b-rodrigues/ess_dev_env">Github repository where my Dockerfile is hosted</a>, and if you are familiar with Github Actions, take a look at my workflow file. You’ll see that I’ve set up Github Actions to build the Docker image and push it to Docker Hub each time I commit, and name the Docker image <code>ess_dev_env:main-xxxxx</code> where <code>xxxxx</code> is the corresponding commit hash on Github (so I can easily know which image was built with which commit).
</p>
<p>
I’ll be using this dockerized image for some time, and see how it feels. For now, it works quite well!
</p>



 ]]></description>
  <category>R</category>
  <category>proramming</category>
  <guid>https://b-rodrigues.github.io/posts/2023-05-08-dock_dev_env.html</guid>
  <pubDate>Mon, 08 May 2023 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
