{
  "hash": "e68805d7d3ff7011859cd3bd243c32f6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ndate: 2025-03-20\ntitle: Announcing rixpress\ncategories:\n  - R\n  - nix\ntoc: true\nexecute:\n  freeze: auto\n---\n\n\n\n\n<div style=\"text-align: center;\">\n  <p>\n    <a>\n      <img src=\"../assets/img/announcing_rixpress.png\" style=\"width: 50%; height: auto;\">\n    </a>\n  </p>\n</div>\n\nAs I’ve already discussed in <a\nhref=\"https://docs.ropensci.org/rix/articles/z-advanced-topic-reproducible-analytical-pipelines-with-nix.html\">this\nvignette of my {rix} package</a>, it is very easy to run a `{targets}` pipeline\ninside of a Nix environment for increased reproduciblity. The main drawback of\n`{targets}` though, is that it is not possible to compute one particular object\nin one particular environment, and another object in another environment. It is\nalso not possible to compute a target using Python for instance, unless you\nuse `{reticulate}`.\n\nBut we can go a step further: you see, Nix is a very versatile tool, and the Nix\nprogramming language is a domain-specific language made to package software. If\nyou assume that, say, a statistical or machine learning model is just software,\nthen why not use Nix to build it? This thought is what made me want to write\n`{rixpress}`.\n\n## rixpress, a package to define reproducible analytical pipelines\n\nThe Nix programming language is a domain specific language used to package and\nbuild software, and \"software\" can have a very broad definition. As I explored\nin <a href=\"2024-08-28-nix_for_r_part_12.qmd\">this blog post</a>, Nix (the\nprogramming language) can be used to define a polyglot pipeline to build, for\nexample, a Quarto report using R and Python. I have now built a package called\n`{rixpress}` which is heavily inspired by `{targets}` (if you are not familiar\nwith `{targets}`, I introduce it at the end of this blog post) to generate such\npipelines and build them using Nix. Below is a complete example which starts by\nusing Python and the Polars library to load a dataset, then transforms it a bit,\nand converts the data to a Pandas dataframe then passes it to R (conversion is\ndone via `reticulate::py_load_object()` under the hood, also why I had to\nconvert the Polars dataframe to a Pandas dataframe) and finally compiles a\nQuarto document (you can find the code\n[here](https://github.com/b-rodrigues/rixpress_pipeline_demo)):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rixpress)\n\nd0 <- rxp_py_file(\n  name = mtcars_pl,\n  path = 'data/mtcars.csv',\n  read_function = \"lambda x: polars.read_csv(x, separator='|')\",\n  nix_env = \"py-env.nix\"\n)\n\nd1 <- rxp_py(\n  # reticulate doesn't support polars DFs yet, so need to convert\n  # first to pandas DF\n  name = mtcars_pl_am,\n  py_expr = \"mtcars_pl.filter(polars.col('am') == 1).to_pandas()\",\n  nix_env = \"py-env.nix\"\n)\n\nd2 <- rxp_py2r(\n  name = mtcars_am,\n  expr = mtcars_pl_am\n)\n\nd3 <- rxp_r(\n  name = mtcars_head,\n  expr = my_head(mtcars_am),\n  additional_files = \"functions.R\"\n)\n\nd4 <- rxp_r(\n  name = mtcars_tail,\n  expr = tail(mtcars_head)\n)\n\nd5 <- rxp_r(\n  name = mtcars_mpg,\n  expr = dplyr::select(mtcars_tail, mpg)\n)\n\ndoc <- rxp_quarto(\n  name = page,\n  qmd_file = \"page.qmd\",\n  additional_files = c(\"content.qmd\", \"images\"),\n  nix_env = \"quarto-env.nix\"\n)\n\nrxp_list <- list(d0, d1, d2, d3, d4, d5, doc)\n\nrixpress(rxp_list, project_path = \".\")\n\nplot_dag()\n```\n:::\n\n\n\n\nLet's go through this code:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd0 <- rxp_py_file(\n  name = mtcars_pl,\n  path = 'data/mtcars.csv',\n  read_function = \"lambda x: polars.read_csv(x, separator='|')\",\n  nix_env = \"py-env.nix\"\n)\n```\n:::\n\n\n\n\n`rxp_py_file()` uses Python to load a local file. In this case, it's the\n`mtcars.csv` dataset under the `data/` folder. The read function must be a\nfunction of only one parameter, the path to the data, so I use an anonymous\nfunction wrapping `polars.read_csv` which allows me to set the separator to the\nunix pipe `|`. Also, this code is executed inside the environment defined by the\n`py-env.nix` file. This file can be generated by my other package, `{rix}` and\nlists the Python packages needed (you'll find it in the repo).\n\nThen:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd1 <- rxp_py(\n  # reticulate doesn't support polars DFs yet, so need to convert\n  # first to pandas DF\n  name = mtcars_pl_am,\n  py_expr = \"mtcars_pl.filter(polars.col('am') == 1).to_pandas()\",\n  nix_env = \"py-env.nix\"\n)\n```\n:::\n\n\n\n\n`rxp_py()` executes Python code, and saves the output into the `name` argument.\nIn this case, I filter the Polars dataframe and convert it to a Pandas\ndataframe. This again happens inside the environment defined by `py-env.nix`,\nit's a pure Python env, no `{reticulate}` needed at this stage.\n\nThen:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd2 <- rxp_py2r(\n  name = mtcars_am,\n  expr = mtcars_pl_am\n)\n```\n:::\n\n\n\n\n`rxp_py2r()` calls `reticulate::py_load_object()` to convert the Pandas\ndataframe to an R dataframe. We can now continue using it using R! You'll notice\nthat no `nix_env` argument is passed to this function. When no argument is\nprovided to `nix_env`, the default environment, `default.nix` gets used. This\none must always be present and in this case contains the required R packages for\nthe pipeline.\n\nThen:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd3 <- rxp_r(\n  name = mtcars_head,\n  expr = my_head(mtcars_am),\n  additional_files = \"functions.R\"\n)\n```\n:::\n\n\n\n\nThis one uses an argument we don't know yet, `additional_files`. It allows you\nto pass R scripts that define functions. In this case, `functions.R` contains\nthe definition of `my_head()` which is used on `mtcars_am`.\n\n`d4` and `d5` are self-explanatory, so now let's take a look at `rxp_quarto()`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoc <- rxp_quarto(\n  name = page,\n  qmd_file = \"page.qmd\",\n  additional_files = c(\"content.qmd\", \"images\"),\n  nix_env = \"quarto-env.nix\"\n)\n```\n:::\n\n\n\n\nThis compiles the `page.qmd` document, which requires additional files:\n`content.qmd` which gets included into `page.qmd` and the `images/` folder, that\ncontains images required to compile the document. This file is compiled using\nthe `quarto-env.nix` environment.\n\nPutting all these derivations into a list and passing it to `rixpress()` doesn't\nbuild the pipeline just yet, but generates a `pipeline.nix` file which is the\nNix expression that will build the output, in this case our Quarto document. You\ncan also take a look at the DAG using `plot_dag()`:\n\n<div style=\"text-align:center;\">\n<p><img src=\"../assets/img/rixpress_dag.png\" width=\"100%\"></p>\n</div>\n\nand it’s also possible to retrieve objects in an interactive sessions using\n`rxp_read()` (to read them) or `rxp_load()` (to load them in the global\nenvironment). When reading or loading Python objects, this will get converted\nusing `{reticulate}` on the fly.\n\nTo build the pipeline, run `rxp_make()`. Subsequent runs don't build everything,\nas intermediary outputs are cached in the *Nix store*. So if you change only the\nQuarto document, only this one derivation gets built anew. It is also possible\nto export and import the outputs using `export_nix_archive()` and\n`import_nix_archive()`, pretty useful for CI!\n\n## Caveats\n\nThis package is still in the prototype stage, so don't use it for anything\nserious. There are still some things I need to work on, for now debugging a\nfaulty pipeline is really hard because intermediary outputs are difficult to\nfind if the pipeline wasn't completely built.\n\nAlso, due to how Nix works, every computation happens in a completely isolated\nsandbox. This is why the `rxp_*()` functions have that `additional_files`\nargument, because in case something external is required, Nix needs to copy it\nover into the sandbox. This means also that functions that require Internet\naccess to work will fail. But I was able to work around that for `rxp_file()`:\nso if a resource is online, the function that reads it should be able to get to\nit.\n\nNow, let me introduce `{targets}`, my main source of inspiration for this\npackage\n\n## The targets package, my source of inspiration for rixpress\n\nI’m a huge fan of the `{targets}` package and think that it’s truly one of the\nbest packages ever made. No other build/pipeline automation tool comes close in\nmy opinion. Most of these tools require you to define your pipeline in another\nlanguage (such as yaml) or force you to use some very specific syntax where you\nexplicitely need to define the objects to compute, their inputs and outputs. But\n`{targets}` allows you to define your pipeline as a series of R calls:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# _targets.R file\nlibrary(targets)\nlibrary(tarchetypes)\ntar_source()\ntar_option_set(packages = c(\"readr\", \"dplyr\", \"ggplot2\"))\nlist(\n  tar_target(file, \"data.csv\", format = \"file\"),\n  tar_target(data, get_data(file)),\n  tar_target(model, fit_model(data)),\n  tar_target(plot, plot_model(model, data))\n)\n```\n:::\n\n\n\n\nThis may look foreign to many R users, but if you look closely, you’ll realise\nthat most of this code is boilerplate:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# _targets.R file\nlibrary(targets)\nlibrary(tarchetypes)\ntar_source()\ntar_option_set(packages = c(\"readr\", \"dplyr\", \"ggplot2\"))\nlist(\n  tar_target(....),\n  tar_target(....),\n  tar_target(....),\n  tar_target(....)\n)\n```\n:::\n\n\n\n\nand what matters is defined inside the `tar_target()` functions. Remove the\nboilerplate, and you end up with essentially correct R code, after a few\nadjustments:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile <- \"data.csv\"\ndata <- get_data(file)\nmodel <- fit_model(data)\nplot <- plot_model(model, data)\n```\n:::\n\n\n\n\nbut why go through the trouble of using `{targets}`? Well, the biggest reason is\nthat `{targets}` figures out the dependencies between the objects you want to\ncompute, and caches them. So in the example above, if you only change the code\nof the `fit_model()` function, only `model` and `plot` are re-computed. But if\nyou change `file` and point the path to an updated `data.csv` file, then\neverything gets computed anew. Watch the [intro\nvideo](https://books.ropensci.org/targets/walkthrough.html) from the official\nwalkthrough for a visual explanation: but trust me, `{targets}` is in this class\nof tools that make you wonder how you could possibly have gotten anything done\nbefore using it.\n\n## Conclusion\n\nI think that `{rixpress}` can become quite an useful package, so I will likely\nsubmit it for rOpenSci peer review in due time.\n\nAnd thanks to [Grant McDermott](https://grantmcdermott.com/) for suggesting the name \"rixpress\"!\n",
    "supporting": [
      "2025-03-20-announcing_rixpress_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}